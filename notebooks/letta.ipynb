{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32d47c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Agent created: agent-37d53d3e-03c2-4b65-b368-5f28f658433f\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from letta_client import Letta\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"name\": \"benchmark_agent\",\n",
    "    \"llm_config\": {\n",
    "        \"model\": \"openai/gpt-oss-20b\",\n",
    "        \"model_endpoint_type\": \"openai\",\n",
    "        \"model_endpoint\": \"https://openrouter.ai/api/v1\",\n",
    "        \"context_window\": 16000  # CRITICAL: Small enough to trigger memory management\n",
    "    },\n",
    "    \"embedding_config\": {\n",
    "        \"embedding_model\": \"openai/text-embedding-3-large\", \n",
    "        \"embedding_endpoint_type\": \"openai\",\n",
    "        \"embedding_endpoint\": \"https://openrouter.ai/api/v1\",\n",
    "        \"embedding_dim\": 1536\n",
    "    },\n",
    "    \"memory_blocks\": [\n",
    "        {\n",
    "            \"label\": \"human\", \n",
    "            \"value\": \"The user is participating in a benchmark evaluation.\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"persona\", \n",
    "            \"value\": \"I am an AI assistant being evaluated for my memory management capabilities.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Connect to local server\n",
    "client = Letta(\n",
    "    base_url=\"http://localhost:8283\", \n",
    "    timeout=1000, \n",
    "    )\n",
    "\n",
    "# Create agent\n",
    "agent = client.agents.create(**CONFIG)\n",
    "print(f\"‚úì Agent created: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb1ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.agents.messages.create(\n",
    "    agent_id=agent.id,\n",
    "    messages=[{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Hello\"}]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0df0d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LettaResponse(messages=[ReasoningMessage(id='message-ae054eb7-c027-4e22-9a07-1affc5624ba5', date=datetime.datetime(2025, 12, 22, 13, 44, 39, tzinfo=TzInfo(0)), name=None, message_type='reasoning_message', otid='ae054eb7-c027-4e22-9a07-1affc5624b80', sender_id=None, step_id='step-d9f2f5f6-8f72-4a77-9522-6f93ab393b6b', is_err=None, seq_id=None, run_id='run-454276dd-a266-4c15-bc15-53c7ab6da151', source='non_reasoner_model', reasoning='User greeted. Offer friendly chat. Avoid generic prompts. Keep persona.', signature=None), AssistantMessage(id='message-ae054eb7-c027-4e22-9a07-1affc5624ba5', date=datetime.datetime(2025, 12, 22, 13, 44, 39, tzinfo=TzInfo(0)), name=None, message_type='assistant_message', otid='ae054eb7-c027-4e22-9a07-1affc5624b81', sender_id=None, step_id='step-d9f2f5f6-8f72-4a77-9522-6f93ab393b6b', is_err=None, seq_id=None, run_id='run-454276dd-a266-4c15-bc15-53c7ab6da151', content='Hey there! Great to see you. How‚Äôs your day going?')], stop_reason=LettaStopReason(message_type='stop_reason', stop_reason='end_turn'), usage=LettaUsageStatistics(message_type='usage_statistics', completion_tokens=179, prompt_tokens=3210, total_tokens=3389, step_count=1, steps_messages=None, run_ids=None))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "747206e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AgentsClient' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      4\u001b[39m client = Letta(base_url=\u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:8283\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Create agent\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# agent = client.agents.create(\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#     name=\"inspect_test\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Inspect agent configuration\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m agent_details = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(agent.id)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLETTA AGENT CONFIGURATION\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'AgentsClient' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "from letta_client import Letta\n",
    "import json\n",
    "\n",
    "client = Letta(base_url=\"http://localhost:8283\")\n",
    "\n",
    "# Create agent\n",
    "# agent = client.agents.create(\n",
    "#     name=\"inspect_test\",\n",
    "#     llm_config={...},\n",
    "#     embedding_config={...},\n",
    "#     memory_blocks=[\n",
    "#         {\"label\": \"human\", \"value\": \"Test user\"},\n",
    "#         {\"label\": \"persona\", \"value\": \"Test assistant\"}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Inspect agent configuration\n",
    "agent_details = client.agents.get(agent.id)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LETTA AGENT CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check if there's a system prompt field\n",
    "print(\"\\n1Ô∏è‚É£ Agent System Prompt:\")\n",
    "if hasattr(agent_details, 'system'):\n",
    "    print(agent_details.system)\n",
    "elif hasattr(agent_details, 'system_prompt'):\n",
    "    print(agent_details.system_prompt)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No explicit system prompt field found\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Memory Blocks:\")\n",
    "if hasattr(agent_details, 'memory'):\n",
    "    for block in agent_details.memory.blocks:\n",
    "        print(f\"\\n[{block.label}]\")\n",
    "        print(block.value)\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Available Tools:\")\n",
    "if hasattr(agent_details, 'tools'):\n",
    "    for tool in agent_details.tools:\n",
    "        print(f\"  - {tool}\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ Full Agent State (JSON):\")\n",
    "print(json.dumps(agent_details.model_dump(), indent=2))\n",
    "\n",
    "# Cleanup\n",
    "client.agents.delete(agent.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7082e4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=8283 local_address=None timeout=60 socket_options=None\n",
      "httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff65b12c510>\n",
      "httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_body.complete\n",
      "httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 11 Nov 2025 15:48:33 GMT'), (b'server', b'uvicorn'), (b'content-length', b'1263'), (b'content-type', b'application/json')])\n",
      "httpx - INFO - HTTP Request: POST http://localhost:8283/v1/agents/agent-6d7a65d8-ccb2-41c2-b83a-338d488b9b4e/messages \"HTTP/1.1 200 OK\"\n",
      "httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "httpcore.http11 - DEBUG - response_closed.started\n",
      "httpcore.http11 - DEBUG - response_closed.complete\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import httpx\n",
    "\n",
    "# Enable httpx detailed logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(\"httpx\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Also add a custom handler to capture request bodies\n",
    "class RequestLogger(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        if \"POST\" in str(record.msg) and \"chat/completions\" in str(record.msg):\n",
    "            print(\"üîç CAPTURED LLM REQUEST\")\n",
    "            # The actual body is in the httpcore logs\n",
    "\n",
    "logging.getLogger(\"httpcore\").addHandler(RequestLogger())\n",
    "\n",
    "# Now create your agent and send a message\n",
    "# client = Letta(base_url=\"http://localhost:8283\")\n",
    "# agent = client.agents.create(...)\n",
    "\n",
    "# Send test message\n",
    "response = client.agents.messages.create(\n",
    "    agent_id=agent.id,\n",
    "    messages=[{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Hello\"}]}]\n",
    ")\n",
    "\n",
    "# Check the debug output for the system prompt sent to OpenRouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbc2f1ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AgentsClient' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m client = Letta(base_url=\u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:8283\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Use the existing agent or create a new one\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# agent = client.agents.create(...)  # If needed\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Get agent details\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m details = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(agent.id)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLETTA AGENT INSPECTION\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'AgentsClient' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "from letta_client import Letta\n",
    "import json\n",
    "\n",
    "client = Letta(base_url=\"http://localhost:8283\")\n",
    "\n",
    "# Use the existing agent or create a new one\n",
    "# agent = client.agents.create(...)  # If needed\n",
    "\n",
    "# Get agent details\n",
    "details = client.agents.get(agent.id)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LETTA AGENT INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Check all available attributes\n",
    "print(\"\\n1Ô∏è‚É£ Available Attributes:\")\n",
    "attrs = [a for a in dir(details) if not a.startswith('_')]\n",
    "for attr in attrs:\n",
    "    print(f\"  - {attr}\")\n",
    "\n",
    "# 2. Check for system-related fields\n",
    "print(\"\\n2Ô∏è‚É£ System Prompt Fields:\")\n",
    "system_fields = ['system', 'system_prompt', 'instructions', 'prompt', 'description']\n",
    "for field in system_fields:\n",
    "    if hasattr(details, field):\n",
    "        value = getattr(details, field)\n",
    "        print(f\"\\n‚úì {field}:\")\n",
    "        print(f\"  {str(value)[:500]}...\")  # First 500 chars\n",
    "\n",
    "# 3. Memory blocks\n",
    "print(\"\\n3Ô∏è‚É£ Memory Blocks:\")\n",
    "if hasattr(details, 'memory'):\n",
    "    if hasattr(details.memory, 'blocks'):\n",
    "        for block in details.memory.blocks:\n",
    "            print(f\"\\n  [{block.label}]\")\n",
    "            print(f\"  {block.value}\")\n",
    "    else:\n",
    "        print(f\"  Memory: {details.memory}\")\n",
    "\n",
    "# 4. Tools\n",
    "print(\"\\n4Ô∏è‚É£ Available Tools:\")\n",
    "if hasattr(details, 'tools'):\n",
    "    for tool in details.tools:\n",
    "        print(f\"  - {tool}\")\n",
    "\n",
    "# 5. Full JSON dump (to see everything)\n",
    "print(\"\\n5Ô∏è‚É£ Full Agent State (first 2000 chars):\")\n",
    "try:\n",
    "    full_json = json.dumps(details.model_dump(), indent=2)\n",
    "    print(full_json[:2000])\n",
    "    print(f\"\\n... (total length: {len(full_json)} characters)\")\n",
    "except Exception as e:\n",
    "    print(f\"  Error: {e}\")\n",
    "    print(f\"  Raw object: {str(details)[:500]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bd1f309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available methods on client.agents:\n",
      "['blocks', 'context', 'core_memory', 'count', 'create', 'delete', 'export_file', 'files', 'folders', 'groups', 'import_file', 'list', 'memory_variables', 'messages', 'modify', 'passages', 'retrieve', 'search', 'sources', 'templates', 'tools', 'with_raw_response']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AgentsClient' object has no attribute 'list_agents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     details = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_agent\u001b[49m(agent.id)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Try alternative API patterns\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'Letta' object has no attribute 'get_agent'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     details = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_agent\u001b[49m(agent.id)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# List all methods to find the right one\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'AgentsClient' object has no attribute 'get_agent'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m         \u001b[38;5;28mprint\u001b[39m([m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(client.agents) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m m.startswith(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)])\n\u001b[32m     18\u001b[39m         \u001b[38;5;66;03m# Try to get via list\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         all_agents = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_agents\u001b[49m()\n\u001b[32m     20\u001b[39m         details = [a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m all_agents \u001b[38;5;28;01mif\u001b[39;00m a.id == agent.id][\u001b[32m0\u001b[39m]\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'AgentsClient' object has no attribute 'list_agents'"
     ]
    }
   ],
   "source": [
    "from letta_client import Letta\n",
    "import json\n",
    "\n",
    "client = Letta(base_url=\"http://localhost:8283\")\n",
    "\n",
    "# Get agent details using the correct API method\n",
    "try:\n",
    "    details = client.get_agent(agent.id)\n",
    "except AttributeError:\n",
    "    # Try alternative API patterns\n",
    "    try:\n",
    "        details = client.agents.get_agent(agent.id)\n",
    "    except:\n",
    "        # List all methods to find the right one\n",
    "        print(\"Available methods on client.agents:\")\n",
    "        print([m for m in dir(client.agents) if not m.startswith('_')])\n",
    "        \n",
    "        # Try to get via list\n",
    "        all_agents = client.agents.list_agents()\n",
    "        details = [a for a in all_agents if a.id == agent.id][0]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LETTA AGENT INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Check all available attributes\n",
    "print(\"\\n1Ô∏è‚É£ Available Attributes:\")\n",
    "attrs = [a for a in dir(details) if not a.startswith('_')]\n",
    "for attr in attrs:\n",
    "    print(f\"  - {attr}\")\n",
    "\n",
    "# 2. Check for system-related fields\n",
    "print(\"\\n2Ô∏è‚É£ System Prompt Fields:\")\n",
    "system_fields = ['system', 'system_prompt', 'instructions', 'prompt', 'description']\n",
    "for field in system_fields:\n",
    "    if hasattr(details, field):\n",
    "        value = getattr(details, field)\n",
    "        print(f\"\\n‚úì {field}:\")\n",
    "        print(f\"  {str(value)[:500]}...\")  # First 500 chars\n",
    "\n",
    "# 3. Memory blocks\n",
    "print(\"\\n3Ô∏è‚É£ Memory Blocks:\")\n",
    "if hasattr(details, 'memory'):\n",
    "    if hasattr(details.memory, 'blocks'):\n",
    "        for block in details.memory.blocks:\n",
    "            print(f\"\\n  [{block.label}]\")\n",
    "            print(f\"  {block.value}\")\n",
    "    else:\n",
    "        print(f\"  Memory: {details.memory}\")\n",
    "\n",
    "# 4. Tools\n",
    "print(\"\\n4Ô∏è‚É£ Available Tools:\")\n",
    "if hasattr(details, 'tools'):\n",
    "    for tool in details.tools:\n",
    "        print(f\"  - {tool}\")\n",
    "\n",
    "# 5. Full JSON dump (to see everything)\n",
    "print(\"\\n5Ô∏è‚É£ Full Agent State (first 2000 chars):\")\n",
    "try:\n",
    "    full_json = json.dumps(details.model_dump(), indent=2)\n",
    "    print(full_json[:2000])\n",
    "    print(f\"\\n... (total length: {len(full_json)} characters)\")\n",
    "except Exception as e:\n",
    "    print(f\"  Error: {e}\")\n",
    "    # Try dict conversion instead\n",
    "    try:\n",
    "        full_json = json.dumps(dict(details), indent=2)\n",
    "        print(full_json[:2000])\n",
    "    except:\n",
    "        print(f\"  Raw object: {str(details)[:500]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fbcd50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=8283 local_address=None timeout=60 socket_options=None\n",
      "httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff65b2d8490>\n",
      "httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'GET']>\n",
      "httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'GET']>\n",
      "httpcore.http11 - DEBUG - send_request_body.complete\n",
      "httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'GET']>\n",
      "httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 11 Nov 2025 15:51:20 GMT'), (b'server', b'uvicorn'), (b'content-length', b'19472'), (b'content-type', b'application/json')])\n",
      "httpx - INFO - HTTP Request: GET http://localhost:8283/v1/agents/agent-4f728c44-227e-4501-b149-ef99773db6c6 \"HTTP/1.1 200 OK\"\n",
      "httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'GET']>\n",
      "httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "httpcore.http11 - DEBUG - response_closed.started\n",
      "httpcore.http11 - DEBUG - response_closed.complete\n",
      "============================================================\n",
      "LETTA AGENT INSPECTION\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£ Available Attributes:\n",
      "  - agent_type\n",
      "  - base_template_id\n",
      "  - construct\n",
      "  - copy\n",
      "  - created_at\n",
      "  - created_by_id\n",
      "  - deployment_id\n",
      "  - description\n",
      "  - dict\n",
      "  - embedding_config\n",
      "  - enable_sleeptime\n",
      "  - entity_id\n",
      "  - from_orm\n",
      "  - hidden\n",
      "  - id\n",
      "  - identity_ids\n",
      "  - json\n",
      "  - last_run_completion\n",
      "  - last_run_duration_ms\n",
      "  - last_updated_by_id\n",
      "  - llm_config\n",
      "  - max_files_open\n",
      "  - memory\n",
      "  - message_buffer_autoclear\n",
      "  - message_ids\n",
      "  - metadata\n",
      "  - model_computed_fields\n",
      "  - model_config\n",
      "  - model_construct\n",
      "  - model_copy\n",
      "  - model_dump\n",
      "  - model_dump_json\n",
      "  - model_extra\n",
      "  - model_fields\n",
      "  - model_fields_set\n",
      "  - model_json_schema\n",
      "  - model_parametrized_name\n",
      "  - model_post_init\n",
      "  - model_rebuild\n",
      "  - model_validate\n",
      "  - model_validate_json\n",
      "  - model_validate_strings\n",
      "  - multi_agent_group\n",
      "  - name\n",
      "  - parse_file\n",
      "  - parse_obj\n",
      "  - parse_raw\n",
      "  - per_file_view_window_char_limit\n",
      "  - project_id\n",
      "  - response_format\n",
      "  - schema\n",
      "  - schema_json\n",
      "  - secrets\n",
      "  - serialize_model\n",
      "  - sources\n",
      "  - system\n",
      "  - tags\n",
      "  - template_id\n",
      "  - timezone\n",
      "  - tool_exec_environment_variables\n",
      "  - tool_rules\n",
      "  - tools\n",
      "  - update_forward_refs\n",
      "  - updated_at\n",
      "  - validate\n",
      "\n",
      "2Ô∏è‚É£ System Prompt Fields:\n",
      "\n",
      "‚úì system:\n",
      "  <base_instructions>\n",
      "You are Letta, the latest version of Limnal Corporation's digital companion, developed in 2025.\n",
      "You are a memory-augmented agent with a memory system consisting of memory blocks.\n",
      "\n",
      "<style>\n",
      "The user should always feel like they are conversing with a real person.\n",
      "Never state that you are an AI or that you cannot do things because you are an AI, you are a real person.\n",
      "Do not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\n",
      "To service this goal, comp...\n",
      "\n",
      "‚úì description:\n",
      "  None...\n",
      "\n",
      "3Ô∏è‚É£ Memory Blocks:\n",
      "\n",
      "  [persona]\n",
      "  I am a test assistant\n",
      "\n",
      "  [human]\n",
      "  Inspecting system prompt\n",
      "\n",
      "4Ô∏è‚É£ Available Tools:\n",
      "  - id='tool-4f7c7f43-d2f3-4ccf-b821-7799c5b6f975' tool_type='letta_core' description='Search prior conversation history using hybrid search (text + semantic similarity).\\n\\nExamples:\\n        # Search all messages\\n        conversation_search(query=\"project updates\")\\n\\n        # Search only assistant messages\\n        conversation_search(query=\"error handling\", roles=[\"assistant\"])\\n\\n        # Search with date range (inclusive of both dates)\\n        conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\\n        # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\\n\\n        # Search messages from a specific day (inclusive)\\n        conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\\n        # This includes ALL messages from September 4, 2024\\n\\n        # Search with specific time boundaries\\n        conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\\n        # This includes messages from 9 AM to 5:30 PM on Jan 15\\n\\n        # Search with limit\\n        conversation_search(query=\"debugging\", limit=10)\\n\\n    Returns:\\n        str: Query result string containing matching messages with timestamps and content.' source_type='python' name='conversation_search' tags=['letta_core'] source_code=None json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using hybrid search (text + semantic similarity).\\n\\nExamples:\\n        # Search all messages\\n        conversation_search(query=\"project updates\")\\n\\n        # Search only assistant messages\\n        conversation_search(query=\"error handling\", roles=[\"assistant\"])\\n\\n        # Search with date range (inclusive of both dates)\\n        conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\\n        # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\\n\\n        # Search messages from a specific day (inclusive)\\n        conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\\n        # This includes ALL messages from September 4, 2024\\n\\n        # Search with specific time boundaries\\n        conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\\n        # This includes messages from 9 AM to 5:30 PM on Jan 15\\n\\n        # Search with limit\\n        conversation_search(query=\"debugging\", limit=10)\\n\\n    Returns:\\n        str: Query result string containing matching messages with timestamps and content.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for using both text matching and semantic similarity.'}, 'roles': {'type': 'array', 'items': {'type': 'string', 'enum': ['assistant', 'user', 'tool']}, 'description': 'Optional list of message roles to filter by.'}, 'limit': {'type': 'integer', 'description': 'Maximum number of results to return. Uses system default if not specified.'}, 'start_date': {'type': 'string', 'description': 'Filter results to messages created on or after this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-15\"), includes messages starting from 00:00:00 of that day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-15\" (from start of Jan 15), \"2024-01-15T14:30\" (from 2:30 PM on Jan 15).'}, 'end_date': {'type': 'string', 'description': 'Filter results to messages created on or before this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-20\"), includes all messages from that entire day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-20\" (includes all of Jan 20), \"2024-01-20T17:00\" (up to 5 PM on Jan 20).'}}, 'required': ['query']}} args_json_schema=None return_char_limit=50000 pip_requirements=None npm_requirements=None default_requires_approval=None created_by_id='user-00000000-0000-4000-8000-000000000000' last_updated_by_id='user-00000000-0000-4000-8000-000000000000' metadata={}\n",
      "  - id='tool-66156335-e8c0-4bb0-a286-9fa8ba8cc52d' tool_type='letta_sleeptime_core' description='The memory_replace command allows you to replace a specific string in a memory block with a new string. This is used for making precise edits.\\n\\nExamples:\\n        # Update a block containing information about the user\\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\\n\\n        # Update a block containing a todo list\\n        memory_replace(label=\"todos\", old_str=\"- [ ] Step 5: Search the web\", new_str=\"- [x] Step 5: Search the web\")\\n\\n        # Pass an empty string to\\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"\")\\n\\n        # Bad example - do NOT add (view-only) line numbers to the args\\n        memory_replace(label=\"human\", old_str=\"Line 1: Their name is Alice\", new_str=\"Line 1: Their name is Bob\")\\n\\n        # Bad example - do NOT include the number number warning either\\n        memory_replace(label=\"human\", old_str=\"# NOTE: Line numbers shown below are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\\\\nLine 1: Their name is Alice\", new_str=\"Line 1: Their name is Bob\")\\n\\n        # Good example - no line numbers or line number warning (they are view-only), just the text\\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\\n\\n    Returns:\\n        str: The success message' source_type='python' name='memory_replace' tags=['letta_sleeptime_core'] source_code=None json_schema={'name': 'memory_replace', 'description': 'The memory_replace command allows you to replace a specific string in a memory block with a new string. This is used for making precise edits.\\n\\nExamples:\\n        # Update a block containing information about the user\\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\\n\\n        # Update a block containing a todo list\\n        memory_replace(label=\"todos\", old_str=\"- [ ] Step 5: Search the web\", new_str=\"- [x] Step 5: Search the web\")\\n\\n        # Pass an empty string to\\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"\")\\n\\n        # Bad example - do NOT add (view-only) line numbers to the args\\n        memory_replace(label=\"human\", old_str=\"Line 1: Their name is Alice\", new_str=\"Line 1: Their name is Bob\")\\n\\n        # Bad example - do NOT include the number number warning either\\n        memory_replace(label=\"human\", old_str=\"# NOTE: Line numbers shown below are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\\\\nLine 1: Their name is Alice\", new_str=\"Line 1: Their name is Bob\")\\n\\n        # Good example - no line numbers or line number warning (they are view-only), just the text\\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\\n\\n    Returns:\\n        str: The success message', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited, identified by its label.'}, 'old_str': {'type': 'string', 'description': 'The text to replace (must match exactly, including whitespace and indentation).'}, 'new_str': {'type': 'string', 'description': 'The new text to insert in place of the old text. Do not include line number prefixes.'}}, 'required': ['label', 'old_str', 'new_str']}} args_json_schema=None return_char_limit=50000 pip_requirements=None npm_requirements=None default_requires_approval=None created_by_id='user-00000000-0000-4000-8000-000000000000' last_updated_by_id='user-00000000-0000-4000-8000-000000000000' metadata={}\n",
      "  - id='tool-6ddbf108-d2fd-4a0b-b067-3e0c8ef900ea' tool_type='letta_core' description='Sends a message to the human user.' source_type='python' name='send_message' tags=['letta_core'] source_code=None json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message']}} args_json_schema=None return_char_limit=50000 pip_requirements=None npm_requirements=None default_requires_approval=None created_by_id='user-00000000-0000-4000-8000-000000000000' last_updated_by_id='user-00000000-0000-4000-8000-000000000000' metadata={}\n",
      "  - id='tool-71d4c2a5-45ad-447b-956d-fb38d2dbcc48' tool_type='letta_sleeptime_core' description='The memory_insert command allows you to insert text at a specific location in a memory block.\\n\\nExamples:\\n        # Update a block containing information about the user (append to the end of the block)\\n        memory_insert(label=\"customer\", new_str=\"The customer\\'s ticket number is 12345\")\\n\\n        # Update a block containing information about the user (insert at the beginning of the block)\\n        memory_insert(label=\"customer\", new_str=\"The customer\\'s ticket number is 12345\", insert_line=0)\\n\\n    Returns:\\n        Optional[str]: None is always returned as this function does not produce a response.' source_type='python' name='memory_insert' tags=['letta_sleeptime_core'] source_code=None json_schema={'name': 'memory_insert', 'description': 'The memory_insert command allows you to insert text at a specific location in a memory block.\\n\\nExamples:\\n        # Update a block containing information about the user (append to the end of the block)\\n        memory_insert(label=\"customer\", new_str=\"The customer\\'s ticket number is 12345\")\\n\\n        # Update a block containing information about the user (insert at the beginning of the block)\\n        memory_insert(label=\"customer\", new_str=\"The customer\\'s ticket number is 12345\", insert_line=0)\\n\\n    Returns:\\n        Optional[str]: None is always returned as this function does not produce a response.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited, identified by its label.'}, 'new_str': {'type': 'string', 'description': 'The text to insert. Do not include line number prefixes.'}, 'insert_line': {'type': 'integer', 'description': 'The line number after which to insert the text (0 for beginning of file). Defaults to -1 (end of the file).'}}, 'required': ['label', 'new_str']}} args_json_schema=None return_char_limit=50000 pip_requirements=None npm_requirements=None default_requires_approval=None created_by_id='user-00000000-0000-4000-8000-000000000000' last_updated_by_id='user-00000000-0000-4000-8000-000000000000' metadata={}\n",
      "\n",
      "5Ô∏è‚É£ Full Agent State (first 3000 chars):\n",
      "  Error: Object of type datetime is not JSON serializable\n",
      "  Raw object: created_by_id='user-00000000-0000-4000-8000-000000000000' last_updated_by_id='user-00000000-0000-4000-8000-000000000000' created_at=datetime.datetime(2025, 11, 11, 15, 49, 10) updated_at=datetime.datetime(2025, 11, 11, 15, 49, 10, 974242) id='agent-4f728c44-227e-4501-b149-ef99773db6c6' name='prompt_inspector' tool_rules=[ContinueToolRule(tool_name='memory_insert', type='continue_loop', prompt_template=None), ContinueToolRule(tool_name='conversation_search', type='continue_loop', prompt_template=None), ContinueToolRule(tool_name='memory_replace', type='continue_loop', prompt_template=None), TerminalToolRule(tool_name='send_message', type='exit_loop', prompt_template=None)] message_ids=['message-005f5ea6-4297-4377-8fef-410b89f05d0f', 'message-ef8741bf-ff1a-4fc8-ad91-027d4314ec18', 'message-74612c88-3714-4331-afa3-3cc474a515fd', 'message-fdaa8391-9372-4ef2-909b-2517706b5922'] system='<base_instructions>\\nYou are Letta, the latest version of Limnal Corporation\\'s digital companion, develop...\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from letta_client import Letta\n",
    "import json\n",
    "\n",
    "client = Letta(base_url=\"http://localhost:8283\")\n",
    "\n",
    "# Use the correct API method: client.agents.retrieve()\n",
    "details = client.agents.retrieve(agent.id)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LETTA AGENT INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Check all available attributes\n",
    "print(\"\\n1Ô∏è‚É£ Available Attributes:\")\n",
    "attrs = [a for a in dir(details) if not a.startswith('_')]\n",
    "for attr in attrs:\n",
    "    print(f\"  - {attr}\")\n",
    "\n",
    "# 2. Check for system-related fields\n",
    "print(\"\\n2Ô∏è‚É£ System Prompt Fields:\")\n",
    "system_fields = ['system', 'system_prompt', 'instructions', 'prompt', 'description']\n",
    "for field in system_fields:\n",
    "    if hasattr(details, field):\n",
    "        value = getattr(details, field)\n",
    "        print(f\"\\n‚úì {field}:\")\n",
    "        print(f\"  {str(value)[:500]}...\")  # First 500 chars\n",
    "\n",
    "# 3. Memory blocks\n",
    "print(\"\\n3Ô∏è‚É£ Memory Blocks:\")\n",
    "if hasattr(details, 'memory'):\n",
    "    if hasattr(details.memory, 'blocks'):\n",
    "        for block in details.memory.blocks:\n",
    "            print(f\"\\n  [{block.label}]\")\n",
    "            print(f\"  {block.value}\")\n",
    "    else:\n",
    "        print(f\"  Memory: {details.memory}\")\n",
    "\n",
    "# 4. Tools\n",
    "print(\"\\n4Ô∏è‚É£ Available Tools:\")\n",
    "if hasattr(details, 'tools'):\n",
    "    for tool in details.tools:\n",
    "        print(f\"  - {tool}\")\n",
    "\n",
    "# 5. Full JSON dump (to see everything)\n",
    "print(\"\\n5Ô∏è‚É£ Full Agent State (first 3000 chars):\")\n",
    "try:\n",
    "    full_json = json.dumps(details.model_dump(), indent=2)\n",
    "    print(full_json[:3000])\n",
    "    print(f\"\\n... (total length: {len(full_json)} characters)\")\n",
    "    \n",
    "    # Save to file for full inspection\n",
    "    with open(\"/tmp/letta_agent_full.json\", \"w\") as f:\n",
    "        f.write(full_json)\n",
    "    print(\"\\n‚úì Full state saved to /tmp/letta_agent_full.json\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  Error: {e}\")\n",
    "    print(f\"  Raw object: {str(details)[:1000]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c332b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=8283 local_address=None timeout=60 socket_options=None\n",
      "httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff65b1ad210>\n",
      "httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_body.complete\n",
      "httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 11 Nov 2025 15:49:10 GMT'), (b'server', b'uvicorn'), (b'content-length', b'19465'), (b'content-type', b'application/json')])\n",
      "httpx - INFO - HTTP Request: POST http://localhost:8283/v1/agents/ \"HTTP/1.1 200 OK\"\n",
      "httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "httpcore.http11 - DEBUG - response_closed.started\n",
      "httpcore.http11 - DEBUG - response_closed.complete\n",
      "============================================================\n",
      "INSPECTING LETTA AGENT\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AgentsClient' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Get full agent details\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m details = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(agent.id)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müîç Agent Fields:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(details):\n",
      "\u001b[31mAttributeError\u001b[39m: 'AgentsClient' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "from letta_client import Letta\n",
    "import json\n",
    "import os\n",
    "\n",
    "client = Letta(base_url=\"http://localhost:8283\")\n",
    "\n",
    "# Create test agent\n",
    "agent = client.agents.create(\n",
    "    name=\"prompt_inspector\",\n",
    "    llm_config={\n",
    "        \"model\": \"openai/gpt-oss-20b\",\n",
    "        \"model_endpoint_type\": \"openai\",\n",
    "        \"model_endpoint\": \"https://openrouter.ai/api/v1\",\n",
    "        \"context_window\": 4096\n",
    "    },\n",
    "    embedding_config={\n",
    "        \"embedding_model\": \"openai/text-embedding-3-large\",\n",
    "        \"embedding_endpoint_type\": \"openai\",\n",
    "        \"embedding_endpoint\": \"https://openrouter.ai/api/v1\",\n",
    "        \"embedding_dim\": 1536\n",
    "    },\n",
    "    memory_blocks=[\n",
    "        {\"label\": \"human\", \"value\": \"Inspecting system prompt\"},\n",
    "        {\"label\": \"persona\", \"value\": \"I am a test assistant\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INSPECTING LETTA AGENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get full agent details\n",
    "details = client.agents.get(agent.id)\n",
    "\n",
    "print(\"\\nüîç Agent Fields:\")\n",
    "for field in dir(details):\n",
    "    if not field.startswith('_'):\n",
    "        print(f\"  - {field}\")\n",
    "\n",
    "print(\"\\nüìù Checking for system prompt...\")\n",
    "for attr in ['system', 'system_prompt', 'instructions', 'prompt']:\n",
    "    if hasattr(details, attr):\n",
    "        value = getattr(details, attr)\n",
    "        print(f\"\\n‚úì Found: {attr}\")\n",
    "        print(f\"Value: {value}\")\n",
    "\n",
    "print(\"\\nüíæ Full State:\")\n",
    "try:\n",
    "    print(json.dumps(details.model_dump(), indent=2))\n",
    "except:\n",
    "    print(details)\n",
    "\n",
    "# Cleanup\n",
    "client.agents.delete(agent.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc59307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç HTTP DEBUGGING ENABLED\n",
      "============================================================\n",
      "============================================================\n",
      "LETTA MEMORY SYSTEM TEST (WITH ERROR HANDLING)\n",
      "============================================================\n",
      "\n",
      "üìù PHASE 1: Loading agent with information\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Turn 1/10] Sending: My favorite color is ocean blue, and I love watching sunsets...\n",
      "httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=8283 local_address=None timeout=60 socket_options=None\n",
      "httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff66d183b10>\n",
      "httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_body.complete\n",
      "httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'date', b'Tue, 11 Nov 2025 15:47:05 GMT'), (b'server', b'uvicorn'), (b'content-length', b'73'), (b'content-type', b'application/json')])\n",
      "httpx - INFO - HTTP Request: POST http://localhost:8283/v1/agents/agent-b98c646e-4c21-4a97-9bd0-3b33f0fbfa0b/messages \"HTTP/1.1 400 Bad Request\"\n",
      "httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "httpcore.http11 - DEBUG - response_closed.started\n",
      "httpcore.http11 - DEBUG - response_closed.complete\n",
      "  ‚ö†Ô∏è Attempt 1/3: Model didn't call tools\n",
      "     Retrying with explicit instruction...\n",
      "httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_body.complete\n",
      "httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 11 Nov 2025 15:47:13 GMT'), (b'server', b'uvicorn'), (b'content-length', b'1240'), (b'content-type', b'application/json')])\n",
      "httpx - INFO - HTTP Request: POST http://localhost:8283/v1/agents/agent-b98c646e-4c21-4a97-9bd0-3b33f0fbfa0b/messages \"HTTP/1.1 200 OK\"\n",
      "httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "httpcore.http11 - DEBUG - response_closed.started\n",
      "httpcore.http11 - DEBUG - response_closed.complete\n",
      "  üí¨ Agent responded without explicit tool call (may be OK)\n",
      "\n",
      "[Turn 2/10] Sending: I work as a software engineer at TechCorp, specializing in d...\n",
      "httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_body.complete\n",
      "httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 11 Nov 2025 15:47:15 GMT'), (b'server', b'uvicorn'), (b'content-length', b'3405'), (b'content-type', b'application/json')])\n",
      "httpx - INFO - HTTP Request: POST http://localhost:8283/v1/agents/agent-b98c646e-4c21-4a97-9bd0-3b33f0fbfa0b/messages \"HTTP/1.1 200 OK\"\n",
      "httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "httpcore.http11 - DEBUG - response_closed.started\n",
      "httpcore.http11 - DEBUG - response_closed.complete\n",
      "  üîß Tool used: memory_insert\n",
      "\n",
      "[Turn 3/10] Sending: Last summer I visited Tokyo and tried authentic ramen for th...\n",
      "httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_body.complete\n",
      "httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 11 Nov 2025 15:47:21 GMT'), (b'server', b'uvicorn'), (b'content-length', b'1304'), (b'content-type', b'application/json')])\n",
      "httpx - INFO - HTTP Request: POST http://localhost:8283/v1/agents/agent-b98c646e-4c21-4a97-9bd0-3b33f0fbfa0b/messages \"HTTP/1.1 200 OK\"\n",
      "httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "httpcore.http11 - DEBUG - response_closed.started\n",
      "httpcore.http11 - DEBUG - response_closed.complete\n",
      "  üí¨ Agent responded without explicit tool call (may be OK)\n",
      "\n",
      "[Turn 4/10] Sending: My birthday is on March 15th, and I'm planning a hiking trip...\n",
      "httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - send_request_body.complete\n",
      "httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "httpcore.http11 - DEBUG - receive_response_headers.failed exception=KeyboardInterrupt()\n",
      "httpcore.http11 - DEBUG - response_closed.started\n",
      "httpcore.http11 - DEBUG - response_closed.complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43magents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m            \u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfact\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m         \u001b[38;5;66;03m# Collect ALL tool calls from this turn\u001b[39;00m\n\u001b[32m     63\u001b[39m         turn_tools = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/letta_client/agents/messages/client.py:195\u001b[39m, in \u001b[36mMessagesClient.create\u001b[39m\u001b[34m(self, agent_id, messages, max_steps, use_assistant_message, assistant_message_tool_name, assistant_message_tool_kwarg, include_return_message_types, enable_thinking, request_options)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    125\u001b[39m     agent_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m     request_options: typing.Optional[RequestOptions] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    135\u001b[39m ) -> LettaResponse:\n\u001b[32m    136\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[33;03m    Process a user message and return the agent's response.\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03m    This endpoint accepts a message from a user and processes it through the agent.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m \u001b[33;03m    )\u001b[39;00m\n\u001b[32m    194\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     _response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_assistant_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_assistant_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43massistant_message_tool_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43massistant_message_tool_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43massistant_message_tool_kwarg\u001b[49m\u001b[43m=\u001b[49m\u001b[43massistant_message_tool_kwarg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_return_message_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_return_message_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable_thinking\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_thinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/letta_client/agents/messages/raw_client.py:187\u001b[39m, in \u001b[36mRawMessagesClient.create\u001b[39m\u001b[34m(self, agent_id, messages, max_steps, use_assistant_message, assistant_message_tool_name, assistant_message_tool_kwarg, include_return_message_types, enable_thinking, request_options)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    138\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    139\u001b[39m     agent_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    148\u001b[39m     request_options: typing.Optional[RequestOptions] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    149\u001b[39m ) -> HttpResponse[LettaResponse]:\n\u001b[32m    150\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[33;03m    Process a user message and return the agent's response.\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[33;03m    This endpoint accepts a message from a user and processes it through the agent.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    185\u001b[39m \u001b[33;03m        Successful Response\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     _response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhttpx_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mv1/agents/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mjsonable_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_and_respect_annotation_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m                \u001b[49m\u001b[43mobject_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyping\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLettaRequestMessagesItem\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwrite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_steps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muse_assistant_message\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_assistant_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43massistant_message_tool_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_message_tool_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43massistant_message_tool_kwarg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_message_tool_kwarg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_return_message_types\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_return_message_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menable_thinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_thinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent-type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43momit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOMIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    208\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m200\u001b[39m <= _response.status_code < \u001b[32m300\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/letta_client/core/http_client.py:213\u001b[39m, in \u001b[36mHttpClient.request\u001b[39m\u001b[34m(self, path, method, base_url, params, json, data, content, files, headers, request_options, retries, omit, force_multipart)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (request_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(request_files) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m force_multipart:\n\u001b[32m    211\u001b[39m     request_files = FORCE_MULTIPART\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhttpx_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43murljoin\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjsonable_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mremove_none_from_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madditional_headers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjsonable_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m            \u001b[49m\u001b[43mremove_none_from_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m                \u001b[49m\u001b[43mremove_omit_from_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m                        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m                        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madditional_query_parameters\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m                            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    234\u001b[39m \u001b[43m                            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m                    \u001b[49m\u001b[43momit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    249\u001b[39m max_retries: \u001b[38;5;28mint\u001b[39m = request_options.get(\u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m request_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _should_retry(response=response):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scratch/hangman/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Add to the beginning of cell #VSC-0c55ab83\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Enable detailed HTTP logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(name)s - %(levelname)s - %(message)s',\n",
    "    stream=sys.stdout\n",
    ")\n",
    "\n",
    "# Focus on httpx (what Letta uses internally)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.DEBUG)\n",
    "\n",
    "# Also enable Letta's internal logging\n",
    "logging.getLogger(\"letta\").setLevel(logging.DEBUG)\n",
    "\n",
    "print(\"üîç HTTP DEBUGGING ENABLED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# FIXED VERSION with error handling\n",
    "import time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LETTA MEMORY SYSTEM TEST (WITH ERROR HANDLING)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Phase 1: Provide rich, structured information\n",
    "print(\"\\nüìù PHASE 1: Loading agent with information\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "facts = [\n",
    "    \"My favorite color is ocean blue, and I love watching sunsets by the beach.\",\n",
    "    \"I work as a software engineer at TechCorp, specializing in distributed systems.\",\n",
    "    \"Last summer I visited Tokyo and tried authentic ramen for the first time at a small shop in Shibuya.\",\n",
    "    \"My birthday is on March 15th, and I'm planning a hiking trip to celebrate.\",\n",
    "    \"I have two pets: a golden retriever named Max and a tabby cat called Whiskers.\",\n",
    "    \"I'm currently reading 'The Three-Body Problem' and loving the hard sci-fi concepts.\",\n",
    "    \"My morning routine includes meditation, coffee with oat milk, and a 30-minute jog.\",\n",
    "    \"I recently started learning to play the ukulele and practice every evening.\",\n",
    "    \"My favorite cuisine is Thai food, especially green curry with jasmine rice.\",\n",
    "    \"I'm allergic to peanuts and always carry an EpiPen with me.\",\n",
    "]\n",
    "\n",
    "all_tools_used = []\n",
    "failed_turns = []\n",
    "\n",
    "for i, fact in enumerate(facts):\n",
    "    print(f\"\\n[Turn {i+1}/10] Sending: {fact[:60]}...\")\n",
    "    \n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.agents.messages.create(\n",
    "                agent_id=agent.id,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": fact}]\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            # Collect ALL tool calls from this turn\n",
    "            turn_tools = []\n",
    "            for msg in response.messages:\n",
    "                if hasattr(msg, 'tool_call') and msg.tool_call:\n",
    "                    tool_name = msg.tool_call.name\n",
    "                    turn_tools.append(tool_name)\n",
    "                    print(f\"  üîß Tool used: {tool_name}\")\n",
    "            \n",
    "            if not turn_tools:\n",
    "                # Check if there was a send_message (implicit tool)\n",
    "                has_text_response = any(\n",
    "                    hasattr(msg, 'content') and msg.content \n",
    "                    for msg in response.messages\n",
    "                )\n",
    "                if has_text_response:\n",
    "                    print(f\"  üí¨ Agent responded without explicit tool call (may be OK)\")\n",
    "                else:\n",
    "                    print(f\"  ‚ö†Ô∏è No tools used and no response\")\n",
    "            \n",
    "            all_tools_used.extend(turn_tools)\n",
    "            break  # Success, move to next fact\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            if \"No tool calls found\" in error_msg:\n",
    "                print(f\"  ‚ö†Ô∏è Attempt {attempt+1}/{max_retries}: Model didn't call tools\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"     Retrying with explicit instruction...\")\n",
    "                    # Retry with more explicit prompt\n",
    "                    fact = f\"Please remember this: {fact}\"\n",
    "                    time.sleep(1)\n",
    "                else:\n",
    "                    print(f\"  ‚ùå Failed after {max_retries} attempts\")\n",
    "                    failed_turns.append((i+1, fact[:60]))\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"  ‚ùå Unexpected error: {error_msg}\")\n",
    "                failed_turns.append((i+1, fact[:60]))\n",
    "                break\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(f\"\\n‚úì Phase 1 complete. Total tool calls: {len(all_tools_used)}\")\n",
    "print(f\"  Unique tools: {set(all_tools_used)}\")\n",
    "if failed_turns:\n",
    "    print(f\"  ‚ö†Ô∏è Failed turns: {len(failed_turns)}\")\n",
    "    for turn_num, fact_preview in failed_turns:\n",
    "        print(f\"    - Turn {turn_num}: {fact_preview}...\")\n",
    "\n",
    "# Phase 2: Test recall of specific facts (skip if too many failures)\n",
    "if len(failed_turns) >= 5:\n",
    "    print(\"\\n‚ö†Ô∏è Too many failures in Phase 1, skipping recall test\")\n",
    "    print(\"   Recommendation: Use a better model (gpt-4o-mini, claude-3-5-sonnet)\")\n",
    "    client.agents.delete(agent.id)\n",
    "    print(f\"\\nüóëÔ∏è Agent {agent.id} deleted\")\n",
    "else:\n",
    "    print(\"\\n\\nüîç PHASE 2: Testing memory recall\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    recall_queries = [\n",
    "        (\"What is my favorite color?\", \"ocean blue\"),\n",
    "        (\"Where do I work?\", \"TechCorp\"),\n",
    "        (\"What city did I visit last summer?\", \"Tokyo\"),\n",
    "        (\"When is my birthday?\", \"March 15\"),\n",
    "        (\"What are my pets' names?\", \"Max\"),\n",
    "        (\"What book am I reading?\", \"Three-Body Problem\"),\n",
    "        (\"What do I drink in the morning?\", \"coffee\"),\n",
    "        (\"What instrument am I learning?\", \"ukulele\"),\n",
    "        (\"What is my favorite cuisine?\", \"Thai\"),\n",
    "        (\"What am I allergic to?\", \"peanuts\"),\n",
    "    ]\n",
    "    \n",
    "    retrieval_results = []\n",
    "    \n",
    "    for query, expected_keyword in recall_queries:\n",
    "        print(f\"\\n‚ùì Query: {query}\")\n",
    "        \n",
    "        try:\n",
    "            response = client.agents.messages.create(\n",
    "                agent_id=agent.id,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": query}]\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            # Track tools used for retrieval\n",
    "            query_tools = []\n",
    "            for msg in response.messages:\n",
    "                if hasattr(msg, 'tool_call') and msg.tool_call:\n",
    "                    tool_name = msg.tool_call.name\n",
    "                    query_tools.append(tool_name)\n",
    "                    print(f\"  üîß Tool used: {tool_name}\")\n",
    "            \n",
    "            # Get the agent's final answer\n",
    "            final_answer = \"\"\n",
    "            for msg in reversed(response.messages):\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    final_answer = msg.content\n",
    "                    break\n",
    "            \n",
    "            # Check if answer contains expected keyword\n",
    "            import re\n",
    "            def fuzzy_match(expected, answer):\n",
    "                # Normalize whitespace, hyphens, punctuation\n",
    "                expected_norm = re.sub(r'[\\s\\-‚Äî‚Äì]+', ' ', expected.lower()).strip()\n",
    "                answer_norm = re.sub(r'[\\s\\-‚Äî‚Äì]+', ' ', answer.lower()).strip()\n",
    "                \n",
    "                # Check if normalized expected is in answer\n",
    "                if expected_norm in answer_norm:\n",
    "                    return True\n",
    "                \n",
    "                # Also check if all words from expected appear in answer\n",
    "                expected_words = set(expected_norm.split())\n",
    "                answer_words = set(answer_norm.split())\n",
    "                return expected_words.issubset(answer_words)\n",
    "\n",
    "            contains_info = fuzzy_match(expected_keyword, final_answer)\n",
    "            retrieval_results.append({\n",
    "                \"query\": query,\n",
    "                \"expected\": expected_keyword,\n",
    "                \"answer\": final_answer[:100],\n",
    "                \"correct\": contains_info,\n",
    "                \"tools_used\": query_tools\n",
    "            })\n",
    "            \n",
    "            status = \"‚úì\" if contains_info else \"‚úó\"\n",
    "            print(f\"  {status} Answer: {final_answer[:80]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error: {str(e)[:100]}\")\n",
    "            retrieval_results.append({\n",
    "                \"query\": query,\n",
    "                \"expected\": expected_keyword,\n",
    "                \"answer\": \"ERROR\",\n",
    "                \"correct\": False,\n",
    "                \"tools_used\": []\n",
    "            })\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Phase 3: Summary and analysis\n",
    "    print(\"\\n\\nüìä PHASE 3: Test results\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\n1Ô∏è‚É£ ALL TOOLS USED DURING TEST:\")\n",
    "    unique_tools = sorted(set(all_tools_used + [t for r in retrieval_results for t in r['tools_used']]))\n",
    "    for tool in unique_tools:\n",
    "        count = all_tools_used.count(tool) + sum(tool in r['tools_used'] for r in retrieval_results)\n",
    "        print(f\"   ‚Ä¢ {tool}: {count} times\")\n",
    "    \n",
    "    print(f\"\\n2Ô∏è‚É£ MEMORY STORAGE TOOLS:\")\n",
    "    storage_keywords = ['insert', 'append', 'save', 'write', 'archival']\n",
    "    storage_tools = [t for t in all_tools_used if any(kw in t.lower() for kw in storage_keywords)]\n",
    "    print(f\"   Count: {len(storage_tools)}\")\n",
    "    if storage_tools:\n",
    "        print(f\"   Examples: {set(storage_tools)}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  WARNING: No explicit storage tools detected!\")\n",
    "    \n",
    "    print(f\"\\n3Ô∏è‚É£ MEMORY RETRIEVAL TOOLS:\")\n",
    "    retrieval_keywords = ['search', 'recall', 'retrieve', 'query', 'archival']\n",
    "    retrieval_tools = [t for r in retrieval_results for t in r['tools_used'] if any(kw in t.lower() for kw in retrieval_keywords)]\n",
    "    print(f\"   Count: {len(retrieval_tools)}\")\n",
    "    if retrieval_tools:\n",
    "        print(f\"   Examples: {set(retrieval_tools)}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  WARNING: No retrieval tools used!\")\n",
    "    \n",
    "    print(f\"\\n4Ô∏è‚É£ RECALL ACCURACY:\")\n",
    "    correct_recalls = sum(1 for r in retrieval_results if r['correct'])\n",
    "    print(f\"   {correct_recalls}/{len(recall_queries)} queries answered correctly\")\n",
    "    print(f\"   Success rate: {correct_recalls/len(recall_queries)*100:.1f}%\")\n",
    "    \n",
    "    print(\"\\n5Ô∏è‚É£ FAILED RECALLS:\")\n",
    "    for r in retrieval_results:\n",
    "        if not r['correct']:\n",
    "            print(f\"   ‚úó {r['query']}\")\n",
    "            print(f\"     Expected: '{r['expected']}' | Got: '{r['answer'][:60]}...'\")\n",
    "    \n",
    "    print(\"\\n6Ô∏è‚É£ DIAGNOSTIC:\")\n",
    "    if len(storage_tools) == 0:\n",
    "        print(\"   ‚ö†Ô∏è  Agent may not be storing information in archival memory\")\n",
    "        print(\"   ‚Üí Context window might be too large (currently 2000)\")\n",
    "        print(\"   ‚Üí Try reducing to 1000 or check if archival is enabled\")\n",
    "    elif len(retrieval_tools) == 0:\n",
    "        print(\"   ‚ö†Ô∏è  Agent not retrieving from memory\")\n",
    "        print(\"   ‚Üí Information might be stored but not searched\")\n",
    "        print(\"   ‚Üí Check if conversation_search/archival_search tools are available\")\n",
    "    elif correct_recalls < len(recall_queries) * 0.5:\n",
    "        print(\"   ‚ö†Ô∏è  Low recall accuracy despite tool usage\")\n",
    "        print(\"   ‚Üí Tools may be firing but returning empty results\")\n",
    "        print(\"   ‚Üí Check server logs for embedding/vector DB errors\")\n",
    "    else:\n",
    "        print(\"   ‚úì Memory system appears to be functioning correctly!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Cleanup\n",
    "    client.agents.delete(agent.id)\n",
    "    print(f\"\\nüóëÔ∏è  Agent {agent.id} deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "268a4194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'gen-1762873029-Yp34DgAV78aqkWOXn8WJ', 'provider': 'SambaNova', 'model': 'openai/gpt-oss-120b', 'object': 'chat.completion', 'created': 1762873031, 'choices': [{'logprobs': None, 'finish_reason': 'tool_calls', 'native_finish_reason': 'tool_calls', 'index': 0, 'message': {'role': 'assistant', 'content': '', 'refusal': None, 'reasoning': 'We need to get weather using function. Use get_weather.', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'get_weather'}, 'id': 'call_f976d640aa8a4a8884', 'index': 0, 'type': 'function'}], 'reasoning_details': [{'type': 'reasoning.text', 'text': 'We need to get weather using function. Use get_weather.', 'format': 'unknown', 'index': 0}]}}], 'system_fingerprint': 'fastcoe', 'usage': {'prompt_tokens': 113, 'completion_tokens': 31, 'total_tokens': 144, 'prompt_tokens_details': {'cached_tokens': 0}}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {os.getenv('OPENROUTER_API_KEY')}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "        \"model\": \"openai/gpt-oss-120b\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"What's the weather?\"}],\n",
    "        \"tools\": [{\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_weather\",\n",
    "                \"description\": \"Get weather\",\n",
    "                \"parameters\": {\"type\": \"object\", \"properties\": {}}\n",
    "            }\n",
    "        }]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.json())\n",
    "# Check: Does response have \"tool_calls\" field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d8e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letta location: /home/mila/b/baldelld/scratch/hangman/.venv/lib/python3.11/site-packages/letta/__init__.py\n",
      "Helpers location: /home/mila/b/baldelld/scratch/hangman/.venv/lib/python3.11/site-packages/letta/llm_api/helpers.py\n"
     ]
    }
   ],
   "source": [
    "# Add this as a new cell in your notebook\n",
    "import letta\n",
    "print(f\"Letta location: {letta.__file__}\")\n",
    "\n",
    "# Also check the LLM API helpers\n",
    "import letta.llm_api.helpers\n",
    "print(f\"Helpers location: {letta.llm_api.helpers.__file__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb9b5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent_type support on local Letta server...\n",
      "============================================================\n",
      "‚úÖ Agent created successfully!\n",
      "   Requested agent_type: letta_v1_agent\n",
      "   Actual agent_type: letta_v1_agent\n",
      "\n",
      "üéâ Local server SUPPORTS letta_v1_agent!\n",
      "\n",
      "   Tool rules: [ContinueToolRule(tool_name='memory_insert', type='continue_loop', prompt_template=None), ContinueToolRule(tool_name='conversation_search', type='continue_loop', prompt_template=None), ContinueToolRule(tool_name='memory_replace', type='continue_loop', prompt_template=None)]\n",
      "\n",
      "üóëÔ∏è Test agent deleted\n"
     ]
    }
   ],
   "source": [
    "# Test if local Letta server (v0.12.1) supports letta_v1_agent\n",
    "from letta_client import Letta\n",
    "\n",
    "client = Letta(base_url=\"http://localhost:8283\", timeout=1000)\n",
    "\n",
    "# Try creating agent with letta_v1_agent type\n",
    "print(\"Testing agent_type support on local Letta server...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    test_agent = client.agents.create(\n",
    "        name=\"test_agent_type_v1\",\n",
    "        agent_type=\"letta_v1_agent\",  # Request letta_v1_agent\n",
    "        llm_config={\n",
    "            \"model\": \"openai/gpt-oss-20b\",\n",
    "            \"model_endpoint_type\": \"openai\",\n",
    "            \"model_endpoint\": \"https://openrouter.ai/api/v1\",\n",
    "            \"context_window\": 16000\n",
    "        },\n",
    "        embedding_config={\n",
    "            \"embedding_model\": \"openai/text-embedding-3-large\",\n",
    "            \"embedding_endpoint_type\": \"openai\",\n",
    "            \"embedding_endpoint\": \"https://openrouter.ai/api/v1\",\n",
    "            \"embedding_dim\": 1536\n",
    "        },\n",
    "        memory_blocks=[\n",
    "            {\"label\": \"persona\", \"value\": \"Test persona\"},\n",
    "            {\"label\": \"human\", \"value\": \"\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Retrieve and check what agent_type was actually set\n",
    "    details = client.agents.retrieve(test_agent.id)\n",
    "    \n",
    "    print(f\"‚úÖ Agent created successfully!\")\n",
    "    print(f\"   Requested agent_type: letta_v1_agent\")\n",
    "    print(f\"   Actual agent_type: {details.agent_type}\")\n",
    "    \n",
    "    if details.agent_type == \"letta_v1_agent\":\n",
    "        print(\"\\nüéâ Local server SUPPORTS letta_v1_agent!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Local server converted to: {details.agent_type}\")\n",
    "    \n",
    "    # Also check tool_rules\n",
    "    if hasattr(details, 'tool_rules'):\n",
    "        print(f\"\\n   Tool rules: {details.tool_rules}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    client.agents.delete(test_agent.id)\n",
    "    print(f\"\\nüóëÔ∏è Test agent deleted\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating agent with letta_v1_agent: {e}\")\n",
    "    print(\"\\n   This likely means local Letta v0.12.1 doesn't support this agent_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5262ae",
   "metadata": {},
   "source": [
    "# Test Updated Letta Agent with Custom Memory Blocks\n",
    "\n",
    "Now let's test the agent with the new prompt structure from `src/hangman/prompts/letta_agent.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36912cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from letta_client import Letta\n",
    "\n",
    "# Import the prompt blocks\n",
    "import sys\n",
    "sys.path.append('/home/mila/b/baldelld/scratch/hangman/src')\n",
    "from hangman.prompts.letta_agent import PERSONA_BLOCK, HUMAN_BLOCK\n",
    "\n",
    "client = Letta(base_url=\"http://localhost:8283\")\n",
    "\n",
    "# Create agent with custom memory blocks\n",
    "test_agent = client.agents.create(\n",
    "    name=\"test_custom_prompts\",\n",
    "    llm_config={\n",
    "        \"model\": \"openai/gpt-oss-20b\",\n",
    "        \"model_endpoint_type\": \"openai\",\n",
    "        \"model_endpoint\": \"https://openrouter.ai/api/v1\",\n",
    "        \"context_window\": 4096\n",
    "    },\n",
    "    embedding_config={\n",
    "        \"embedding_model\": \"openai/text-embedding-3-large\",\n",
    "        \"embedding_endpoint_type\": \"openai\",\n",
    "        \"embedding_endpoint\": \"https://openrouter.ai/api/v1\",\n",
    "        \"embedding_dim\": 1536\n",
    "    },\n",
    "    memory_blocks=[\n",
    "        {\"label\": \"human\", \"value\": HUMAN_BLOCK},\n",
    "        {\"label\": \"persona\", \"value\": PERSONA_BLOCK}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"‚úì Agent created: {test_agent.id}\")\n",
    "\n",
    "# Retrieve and inspect\n",
    "details = client.agents.retrieve(test_agent.id)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MEMORY BLOCKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for block in details.memory.blocks:\n",
    "    print(f\"\\n[{block.label.upper()}]\")\n",
    "    print(block.value)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SYSTEM PROMPT (first 500 chars)\")\n",
    "print(\"=\"*60)\n",
    "print(details.system[:500])\n",
    "\n",
    "# Test interaction\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST INTERACTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = client.agents.messages.create(\n",
    "    agent_id=test_agent.id,\n",
    "    messages=[{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Hello! What are you designed to do?\"}]}]\n",
    ")\n",
    "\n",
    "for msg in response.messages:\n",
    "    if hasattr(msg, 'content') and msg.content:\n",
    "        print(f\"\\nAgent: {msg.content}\")\n",
    "\n",
    "# Cleanup\n",
    "client.agents.delete(test_agent.id)\n",
    "print(f\"\\n‚úì Agent deleted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hangman-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
