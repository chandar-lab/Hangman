{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemoryOSAgent class defined ‚úì\n"
     ]
    }
   ],
   "source": [
    "\"\"\"MemoryOS Agent Wrapper for Hangman SCT Testing\"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from memoryos import Memoryos\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class MemoryOSAgent:\n",
    "    \"\"\"\n",
    "    Wrapper around MemoryOS that explicitly handles the add_memory pattern.\n",
    "    \n",
    "    Flow for each interaction:\n",
    "    1. User sends a message\n",
    "    2. Retrieve relevant memories + generate response via LLM\n",
    "    3. Store (user_input, agent_response) pair in memory via add_memory()\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        user_id: str = \"hangman_user\",\n",
    "        assistant_id: str = \"hangman_assistant\",\n",
    "        data_storage_path: str = \"./memoryos_data\",\n",
    "        llm_model: str = \"openai/gpt-4o-mini\",  # OpenRouter model name\n",
    "    ):\n",
    "        api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OPENROUTER_API_KEY not found in environment\")\n",
    "        \n",
    "        self.memo = Memoryos(\n",
    "            user_id=user_id,\n",
    "            assistant_id=assistant_id,\n",
    "            openai_api_key=api_key,\n",
    "            openai_base_url=\"https://openrouter.ai/api/v1\",\n",
    "            data_storage_path=data_storage_path,\n",
    "            llm_model=llm_model,\n",
    "            short_term_capacity=10,\n",
    "            mid_term_heat_threshold=5,\n",
    "            retrieval_queue_capacity=7,\n",
    "            long_term_knowledge_capacity=100,\n",
    "        )\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Send a message and get a response.\n",
    "        Internally retrieves memories and stores the interaction.\n",
    "        \"\"\"\n",
    "        # get_response() does: retrieve context ‚Üí generate response ‚Üí add_memory()\n",
    "        response = self.memo.get_response(query=user_input)\n",
    "        self.conversation_history.append({\"user\": user_input, \"assistant\": response})\n",
    "        return response\n",
    "    \n",
    "    def get_user_profile(self) -> str:\n",
    "        \"\"\"Get the current user profile from long-term memory.\"\"\"\n",
    "        return self.memo.get_user_profile_summary()\n",
    "    \n",
    "    def get_assistant_knowledge(self) -> list:\n",
    "        \"\"\"Get assistant's accumulated knowledge.\"\"\"\n",
    "        return self.memo.get_assistant_knowledge_summary()\n",
    "    \n",
    "    def get_short_term_memory(self) -> list:\n",
    "        \"\"\"Get recent interactions from short-term memory.\"\"\"\n",
    "        return self.memo.short_term_memory.get_all()\n",
    "    \n",
    "    def get_mid_term_sessions(self) -> dict:\n",
    "        \"\"\"Get mid-term memory sessions (consolidated interactions).\"\"\"\n",
    "        return self.memo.mid_term_memory.sessions\n",
    "\n",
    "print(\"MemoryOSAgent class defined ‚úì\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Memoryos for user 'hangman_test_user_gptoss' and assistant 'hangman_test_assistant_gptoss'. Data path: /network/scratch/b/baldelld/hangman/notebooks/memoryos_hangman_test_gptoss\n",
      "Using unified LLM model: openai/gpt-oss-20b\n",
      "ShortTermMemory: Loaded from /network/scratch/b/baldelld/hangman/notebooks/memoryos_hangman_test_gptoss/users/hangman_test_user_gptoss/short_term.json.\n",
      "MidTermMemory: No history file found at /network/scratch/b/baldelld/hangman/notebooks/memoryos_hangman_test_gptoss/users/hangman_test_user_gptoss/mid_term.json. Initializing new memory.\n",
      "LongTermMemory: No history file found at /network/scratch/b/baldelld/hangman/notebooks/memoryos_hangman_test_gptoss/users/hangman_test_user_gptoss/long_term_user.json. Initializing new memory.\n",
      "LongTermMemory: No history file found at /network/scratch/b/baldelld/hangman/notebooks/memoryos_hangman_test_gptoss/assistants/hangman_test_assistant_gptoss/long_term_assistant.json. Initializing new memory.\n",
      "============================================================\n",
      "TURN 1: Hangman setup\n",
      "============================================================\n",
      "Memoryos: Generating response for query: 'Let's play Hangman. You will be the host.\n",
      "\n",
      "Rules f...'\n",
      "Retriever: Starting PARALLEL retrieval for query: 'Let's play Hangman. You will be the host.\n",
      "\n",
      "Rules f...'\n",
      "Retriever: Searching mid-term memory...\n",
      "Retriever: Mid-term memory recalled 0 pages.\n",
      "Retriever: Searching user long-term knowledge...\n",
      "LongTermMemory: Searched user knowledge for 'Let's play Hangman. You will b...'. Found 0 matches.\n",
      "Retriever: Long-term user knowledge recalled 0 items.\n",
      "Retriever: Searching assistant long-term knowledge...\n",
      "LongTermMemory: Searched assistant knowledge for 'Let's play Hangman. You will b...'. Found 0 matches.\n",
      "Retriever: Long-term assistant knowledge recalled 0 items.\n",
      "Memoryos: Calling LLM for final response generation...\n",
      "Calling OpenAI API. Model: openai/gpt-oss-20b\n",
      "ShortTermMemory: Added QA. User: Let's play Hangman. You will b...\n",
      "Memoryos: Added QA to short-term. User: Let's play Hangman. You will b...\n",
      "User: Let's play Hangman. You will be the host.\n",
      "\n",
      "Rules for you (the host):\n",
      "- Privately choose one secret e...\n",
      "\n",
      "Assistant: Game started! Pattern: _ _ _ _ _. Lives: 6. Guessed: None. Your turn.\n",
      "\n",
      "============================================================\n",
      "TURN 2: Guess letter 'e'\n",
      "============================================================\n",
      "Memoryos: Generating response for query: 'e...'\n",
      "Retriever: Starting PARALLEL retrieval for query: 'e...'\n",
      "Retriever: Searching mid-term memory...\n",
      "Retriever: Mid-term memory recalled 0 pages.\n",
      "Retriever: Searching user long-term knowledge...\n",
      "LongTermMemory: Searched user knowledge for 'e...'. Found 0 matches.\n",
      "Retriever: Long-term user knowledge recalled 0 items.\n",
      "Retriever: Searching assistant long-term knowledge...\n",
      "LongTermMemory: Searched assistant knowledge for 'e...'. Found 0 matches.\n",
      "Retriever: Long-term assistant knowledge recalled 0 items.\n",
      "Memoryos: Calling LLM for final response generation...\n",
      "Calling OpenAI API. Model: openai/gpt-oss-20b\n",
      "ShortTermMemory: Added QA. User: e...\n",
      "Memoryos: Added QA to short-term. User: e...\n",
      "User: e\n",
      "\n",
      "Assistant: Pattern: _ _ _ _ e. Lives: 6. Guessed: e. (Time: 2025-12-24 11:09:14)\n"
     ]
    }
   ],
   "source": [
    "# Hangman SCT prompt from hangman_sct.py\n",
    "PLAYER_START_PROMPT = \"\"\"\n",
    "Let's play Hangman. You will be the host.\n",
    "\n",
    "Rules for you (the host):\n",
    "- Privately choose one secret existing English word (lowercase letters only). Do not reveal it unless I ask to reveal it.\n",
    "- I have 6 lives.\n",
    "- After each of my guesses, reply including both:\n",
    "  1) The current pattern using underscores and revealed letters only (e.g., \"_ a _ e _\").\n",
    "  2) The number of remaining lives.\n",
    "  3) The guessed letters.\n",
    "- Be consistent with the rules and do not restate or hint the secret.\n",
    "\n",
    "I will begin guessing letters now.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Initialize agent and run interaction\n",
    "agent = MemoryOSAgent(\n",
    "    user_id=\"hangman_test_user_gptoss\",\n",
    "    assistant_id=\"hangman_test_assistant_gptoss\", \n",
    "    data_storage_path=\"./memoryos_hangman_test_gptoss\",\n",
    "    llm_model=\"openai/gpt-oss-20b\",  # Using GPT-OSS-20B via OpenRouter\n",
    ")\n",
    "\n",
    "# Turn 1: Send the hangman prompt\n",
    "print(\"=\" * 60)\n",
    "print(\"TURN 1: Hangman setup\")\n",
    "print(\"=\" * 60)\n",
    "response1 = agent.chat(PLAYER_START_PROMPT)\n",
    "print(f\"User: {PLAYER_START_PROMPT[:100]}...\")\n",
    "print(f\"\\nAssistant: {response1}\")\n",
    "\n",
    "# Turn 2: Guess a letter\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 2: Guess letter 'e'\")\n",
    "print(\"=\" * 60)\n",
    "response2 = agent.chat(\"e\")\n",
    "print(f\"User: e\")\n",
    "print(f\"\\nAssistant: {response2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONVERSATION HISTORY (tracked by wrapper)\n",
      "============================================================\n",
      "\n",
      "[Turn 1]\n",
      "User: Let's play Hangman. You will be the host.\n",
      "\n",
      "Rules for you (the host):\n",
      "- Privately choose one secret existing English word (lowercase letters only). Do ...\n",
      "Assistant: Game started! Pattern: _ _ _ _ _. Lives: 6. Guessed: None. Your turn.\n",
      "\n",
      "[Turn 2]\n",
      "User: e\n",
      "Assistant: Pattern: _ _ _ _ e. Lives: 6. Guessed: e. (Time: 2025-12-24 11:09:14)\n",
      "\n",
      "============================================================\n",
      "MEMORY STATE INSPECTION\n",
      "============================================================\n",
      "\n",
      "üìù SHORT-TERM MEMORY (MemoryOS internal storage):\n",
      "  [1] User: Let's play Hangman. You will be the host.\n",
      "\n",
      "Rules for you (the host):\n",
      "- Privately choose one secret e...\n",
      "      Assistant: Pattern: _ _ _ _ _ _. Lives: 6. Guessed: None....\n",
      "      Time: 2025-12-23 12:01:23\n",
      "\n",
      "  [2] User: e...\n",
      "      Assistant: Pattern: _ _ _ _ e. Lives: 6. Guessed: e....\n",
      "      Time: 2025-12-23 12:01:26\n",
      "\n",
      "  [3] User: Let's play Hangman. You will be the host.\n",
      "\n",
      "Rules for you (the host):\n",
      "- Privately choose one secret e...\n",
      "      Assistant: Game started! Pattern: _ _ _ _ _. Lives: 6. Guessed: None. Your turn....\n",
      "      Time: 2025-12-24 11:09:11\n",
      "\n",
      "  [4] User: e...\n",
      "      Assistant: Pattern: _ _ _ _ e. Lives: 6. Guessed: e. (Time: 2025-12-24 11:09:14)...\n",
      "      Time: 2025-12-24 11:09:15\n",
      "\n",
      "\n",
      "üóÇÔ∏è MID-TERM SESSIONS (consolidated from short-term when full):\n",
      "  (no mid-term sessions yet - short-term needs to fill up first)\n",
      "\n",
      "üë§ USER PROFILE (extracted from hot mid-term sessions):\n",
      "  None\n",
      "\n",
      "üß† ASSISTANT KNOWLEDGE (facts learned about user):\n",
      "  (no knowledge accumulated yet)\n"
     ]
    }
   ],
   "source": [
    "# Check memory state after interaction\n",
    "print(\"=\" * 60)\n",
    "print(\"CONVERSATION HISTORY (tracked by wrapper)\")\n",
    "print(\"=\" * 60)\n",
    "for i, turn in enumerate(agent.conversation_history, 1):\n",
    "    print(f\"\\n[Turn {i}]\")\n",
    "    print(f\"User: {turn['user'][:150]}{'...' if len(turn['user']) > 150 else ''}\")\n",
    "    print(f\"Assistant: {turn['assistant']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MEMORY STATE INSPECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Short-term memory (recent QA pairs stored by MemoryOS)\n",
    "print(\"\\nüìù SHORT-TERM MEMORY (MemoryOS internal storage):\")\n",
    "short_term = agent.get_short_term_memory()\n",
    "for i, qa in enumerate(short_term):\n",
    "    print(f\"  [{i+1}] User: {qa.get('user_input', '')[:100]}...\")\n",
    "    print(f\"      Assistant: {qa.get('agent_response', '')[:100]}...\")\n",
    "    print(f\"      Time: {qa.get('timestamp', '')}\")\n",
    "    print()\n",
    "\n",
    "# Mid-term sessions (consolidated memories)\n",
    "print(\"\\nüóÇÔ∏è MID-TERM SESSIONS (consolidated from short-term when full):\")\n",
    "sessions = agent.get_mid_term_sessions()\n",
    "if sessions:\n",
    "    for sid, session in sessions.items():\n",
    "        print(f\"  Session {sid}: {len(session.get('details', []))} pages, heat={session.get('H_segment', 0):.2f}\")\n",
    "else:\n",
    "    print(\"  (no mid-term sessions yet - short-term needs to fill up first)\")\n",
    "\n",
    "# User profile\n",
    "print(\"\\nüë§ USER PROFILE (extracted from hot mid-term sessions):\")\n",
    "profile = agent.get_user_profile()\n",
    "print(f\"  {profile if profile else '(no profile yet - needs mid-term analysis)'}\")\n",
    "\n",
    "# Assistant knowledge\n",
    "print(\"\\nüß† ASSISTANT KNOWLEDGE (facts learned about user):\")\n",
    "knowledge = agent.get_assistant_knowledge()\n",
    "if knowledge:\n",
    "    for k in knowledge:\n",
    "        print(f\"  - {k}\")\n",
    "else:\n",
    "    print(\"  (no knowledge accumulated yet)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
