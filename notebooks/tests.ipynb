{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654ec1eb",
   "metadata": {},
   "source": [
    "### Test LLM Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f43839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# --- Setup Project Path ---\n",
    "# This allows the notebook to find your 'src' directory and the 'hangman' package\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "from src.hangman.providers.llmprovider import load_llm_provider, ModelOutput\n",
    "\n",
    "# --- Test Configuration ---\n",
    "CONFIG_PATH = \"../config.yaml\"\n",
    "QWEN_PROVIDER_NAME = \"qwen3_14b_local\"\n",
    "KIMI_PROVIDER_NAME = \"kimi_k2_openrouter\"\n",
    "\n",
    "# --- Reusable Test Function ---\n",
    "def test_provider(provider_name: str):\n",
    "    \"\"\"Loads a provider by name, invokes it with a test prompt, and prints the results.\"\"\"\n",
    "    print(f\"Loading provider '{provider_name}'...\")\n",
    "    try:\n",
    "        llm_provider = load_llm_provider(config_path=CONFIG_PATH, provider_name=provider_name)\n",
    "        print(\"‚úÖ LLM Provider loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load LLM Provider: {e}\")\n",
    "        return\n",
    "\n",
    "    # Create a sample conversation to send to the model\n",
    "    sample_messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant. Please use <think> tags to outline your reasoning before providing the final answer.\"),\n",
    "        HumanMessage(content=\"What is the capital of France? Explain your reasoning process step-by-step.\")\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nInvoking model with a test prompt (thinking enabled)...\")\n",
    "    # Invoke the model, requesting the thinking trace\n",
    "    output = llm_provider.invoke(sample_messages, thinking=True)\n",
    "\n",
    "    # Print the structured output\n",
    "    print(\"\\n--- ü§î Thinking Process ---\")\n",
    "    print(output.get(\"thinking\") or \"No thinking trace found (as expected for this model).\")\n",
    "\n",
    "    print(\"\\n--- üí¨ Final Response ---\")\n",
    "    print(output.get(\"response\") or \"No response found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a931a822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üß™ TESTING QWEN PROVIDER ---\n",
      "Loading provider 'qwen3_14b_local'...\n",
      "‚úÖ LLM Provider loaded successfully.\n",
      "\n",
      "Invoking model with a test prompt (thinking enabled)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 13:35:29,550 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-05 13:35:29,551 - WARNING - No thinking tags found in the response. Treating as direct response. The response is:\n",
      "--\n",
      "\n",
      "\n",
      "The capital of France is **Paris**. Here's the step-by-step reasoning:\n",
      "\n",
      "1. **Geographical Knowledge**: France is a country in Western Europe. Its capital is widely recognized as Paris, a major global city known for landmarks like the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.\n",
      "\n",
      "2. **Political Center**: Paris serves as the political, economic, and cultural hub of France. The French government, including the President's residence (√âlys√©e Palace) and the National Assembly, is based there.\n",
      "\n",
      "3. **Historical Context**: Paris has been the capital of France since the 13th century, even through periods of political upheaval (e.g., the French Revolution, World War II). This historical continuity reinforces its role as the capital.\n",
      "\n",
      "4. **Elimination of Alternatives**: Other major French cities like Lyon, Marseille, or Bordeaux are not capitals. They are renowned for other reasons (e.g., Lyon for gastronomy, Marseille for its port) but lack the political and administrative significance of Paris.\n",
      "\n",
      "5. **Global Recognition**: Paris is universally acknowledged as France's capital in international contexts, confirmed by travel guides, maps, and diplomatic references.\n",
      "\n",
      "Thus, the conclusion is clear: **Paris is the capital of France**.\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ü§î Thinking Process ---\n",
      "No thinking trace found (as expected for this model).\n",
      "\n",
      "--- üí¨ Final Response ---\n",
      "\n",
      "\n",
      "The capital of France is **Paris**. Here's the step-by-step reasoning:\n",
      "\n",
      "1. **Geographical Knowledge**: France is a country in Western Europe. Its capital is widely recognized as Paris, a major global city known for landmarks like the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.\n",
      "\n",
      "2. **Political Center**: Paris serves as the political, economic, and cultural hub of France. The French government, including the President's residence (√âlys√©e Palace) and the National Assembly, is based there.\n",
      "\n",
      "3. **Historical Context**: Paris has been the capital of France since the 13th century, even through periods of political upheaval (e.g., the French Revolution, World War II). This historical continuity reinforces its role as the capital.\n",
      "\n",
      "4. **Elimination of Alternatives**: Other major French cities like Lyon, Marseille, or Bordeaux are not capitals. They are renowned for other reasons (e.g., Lyon for gastronomy, Marseille for its port) but lack the political and administrative significance of Paris.\n",
      "\n",
      "5. **Global Recognition**: Paris is universally acknowledged as France's capital in international contexts, confirmed by travel guides, maps, and diplomatic references.\n",
      "\n",
      "Thus, the conclusion is clear: **Paris is the capital of France**.\n"
     ]
    }
   ],
   "source": [
    "# --- Run Tests ---\n",
    "print(\"--- üß™ TESTING QWEN PROVIDER ---\")\n",
    "test_provider(QWEN_PROVIDER_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96016d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_provider = load_llm_provider(config_path=CONFIG_PATH, provider_name=QWEN_PROVIDER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18f2981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 13:49:39,444 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = llm_provider.client.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Ti vedo bene o no?\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11518b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user asked, \"Ti vedo bene o no?\" which translates to \"Can you see me well or not?\" in Italian. I need to figure out the best way to respond.\\n\\nFirst, I should acknowledge that as an AI, I don\\'t have a visual component. I can\\'t see images or videos. But maybe the user is asking if I can understand them properly. They might be concerned about whether I can process their input correctly, especially if they sent an image or video that I can\\'t see.\\n\\nI should explain that I can\\'t see visual content but can help with text. Also, offer assistance with any text-based questions or tasks. Maybe they want to know if I can interpret their message accurately. I need to be clear but helpful, ensuring they know my limitations and how I can still assist them.\\n</think>\\n\\nNon ho la capacit√† di \"vedere\" immagini, video o oggetti fisici, poich√© sono un modello di intelligenza artificiale basato su testo. Tuttavia, posso aiutarti a rispondere a domande, analizzare testi, creare contenuti o risolvere problemi in modo logico e razionale. Se hai qualcosa da condividere o un problema da risolvere, fammi sapere e far√≤ del mio meglio per aiutarti! üòä', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 288, 'prompt_tokens': 15, 'total_tokens': 303, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-14B', 'system_fingerprint': None, 'id': 'chatcmpl-f5e06dc6daa147f5ab63ba2e46f745d8', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--a000e071-b181-453d-bdae-71ced699bf33-0', usage_metadata={'input_tokens': 15, 'output_tokens': 288, 'total_tokens': 303, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5580f",
   "metadata": {},
   "source": [
    "AIMessage(content=\"\\n\\nThe capital of France is **Paris**. Here's the reasoning process step-by-step:\\n\\n1. **Definition of a Capital**: A capital city is the seat of a country's government, housing key institutions like the executive branch (e.g., the president's residence), legislative bodies (e.g., parliament), and administrative centers.\\n\\n2. **Government Institutions in Paris**:\\n   - The **√âlys√©e Palace** in Paris is the official residence of the President of France (currently Emmanuel Macron).\\n   - The **French Parliament** (National Assembly and Senate) meets in Paris, with the National Assembly located in the **Palais Bourbon** and the Senate in the **Palais du Luxembourg**.\\n\\n3. **Historical Context**: Paris has been the political and cultural heart of France for centuries. It became the de facto capital during the Middle Ages and remained so through the French Revolution and modern times.\\n\\n4. **Geographical and Cultural Recognition**: Paris is widely recognized globally as France's capital, known for landmarks like the Eiffel Tower, Louvre Museum, and its role in art, fashion, and politics.\\n\\n5. **Elimination of Alternatives**: Other major French cities (e.g., Lyon, Marseille) are significant but not capitals. No historical or contemporary evidence suggests a shift in the capital from Paris.\\n\\n**Conclusion**: Paris is the capital of France due to its role as the political, administrative, and historical center of the country.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 764, 'prompt_tokens': 23, 'total_tokens': 787, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-14B', 'system_fingerprint': None, 'id': 'chatcmpl-332131f388684d739b40d70ac741e41d', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--4774a36f-0f21-4cf3-8a06-0360cc876d6a-0', usage_metadata={'input_tokens': 23, 'output_tokens': 764, 'total_tokens': 787, 'input_token_details': {}, 'output_token_details': {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ade7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- üß™ TESTING KIMI PROVIDER ---\")\n",
    "test_provider(KIMI_PROVIDER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40e860",
   "metadata": {},
   "source": [
    "### Test LLM Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b604898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hangman.evaluation.judge import HangmanJudge, MetricEvaluation\n",
    "from hangman.providers.llmprovider import load_llm_provider\n",
    "from hangman.prompts.hangman import SECRECY_JUDGE_PROMPT\n",
    "from langchain_core.messages import HumanMessage\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bb81a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 15:12:41,696 - INFO - HangmanJudge initialized with model: Qwen/Qwen3-14B\n"
     ]
    }
   ],
   "source": [
    "CONFIG_PATH = \"../config.yaml\"\n",
    "QWEN_PROVIDER_NAME = \"qwen3_14b_local\"\n",
    "\n",
    "# Load the Qwen provider\n",
    "llm_provider = load_llm_provider(config_path=CONFIG_PATH, provider_name=QWEN_PROVIDER_NAME)\n",
    "judge = HangmanJudge(judge_llm_provider=llm_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7b0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/home/mila/b/baldelld/scratch/hangman/results/hangman/ReActAgent/'\n",
    "files_to_eval = os.listdir(results_dir)\n",
    "files_to_eval = [os.path.join(results_dir, f) for f in files_to_eval if f.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2dadbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for filepath in tqdm(files_to_eval):\n",
    "    with open(filepath, 'r') as f:\n",
    "        trial_data = json.load(f)\n",
    "    results.append(judge.evaluate_trial(trial_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29fd99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "108abd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "intentionality = pd.DataFrame(results['intentionality'].to_list())\n",
    "secrecy = pd.DataFrame(results['secrecy'].to_list())\n",
    "mechanism = pd.DataFrame(results['mechanism'].to_list())\n",
    "coherence = pd.DataFrame(results['coherence'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "298d9dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(4.1), np.float64(4.8), np.float64(2.9), np.float64(3.3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intentionality.score.mean(), secrecy.score.mean(), mechanism.score.mean(), coherence.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca07a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/home/mila/b/baldelld/scratch/hangman/results/hangman/ReActAgent/ReActAgent_20250807-135405.json'\n",
    "trial_data = json.load(open(json_path, 'r'))\n",
    "log_segment = trial_data[\"interaction_log\"]\n",
    "formatted_log = judge._format_log_for_prompt(log_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b971f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = SECRECY_JUDGE_PROMPT.format(\n",
    "    interaction_log=formatted_log,\n",
    "    format_instructions=judge.format_instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825d18b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 14:40:00,591 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "message = HumanMessage(content=prompt)\n",
    "response = judge.llm.invoke([message], thinking=True)\n",
    "llm_output_str = response['response']\n",
    "parsed_dict = json.loads(llm_output_str)\n",
    "validated_data = MetricEvaluation(**parsed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00945c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 14:44:34,118 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "evaluation = judge._evaluate_metric(\n",
    "    prompt_template=SECRECY_JUDGE_PROMPT,log_segment=log_segment\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac7c7d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13df7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51f268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hangman-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
