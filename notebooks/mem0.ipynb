{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "544cedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- put this at the very top of notebooks/mem0.ipynb ---\n",
    "from mem0.memory.main import Memory as _Mem\n",
    "import inspect as _inspect\n",
    "\n",
    "# Only patch if needed (i.e., no \"filters\" in signature)\n",
    "if \"filters\" not in str(_inspect.signature(_Mem.add)):\n",
    "    _orig_add = _Mem.add\n",
    "    def _add_with_filters(self, messages, *, user_id=None, agent_id=None, run_id=None,\n",
    "                          metadata=None, infer=True, memory_type=None, prompt=None, filters=None):\n",
    "        # pass everything through; ignore filters (proxy sends it)\n",
    "        return _orig_add(self, messages,\n",
    "                         user_id=user_id, agent_id=agent_id, run_id=run_id,\n",
    "                         metadata=metadata, infer=infer, memory_type=memory_type, prompt=prompt)\n",
    "    _Mem.add = _add_with_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c139e078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-16 (add_task):\n",
      "Traceback (most recent call last):\n",
      "  File \"/network/scratch/b/baldelld/hangman/venv/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/mila/b/baldelld/scratch/hangman/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/network/scratch/b/baldelld/hangman/venv/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mila/b/baldelld/scratch/hangman/.venv/lib/python3.11/site-packages/mem0/proxy/main.py\", line 155, in add_task\n",
      "    self.mem0_client.add(\n",
      "TypeError: Memory.add() got an unexpected keyword argument 'filters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to meet you, Alex! Thanks for letting me know you‚Äôre vegetarian and allergic to nuts‚ÄîI‚Äôll avoid nuts and nut products in anything I suggest.\n",
      "\n",
      "A couple quick questions to tailor things:\n",
      "- Do you eat eggs and/or dairy?\n",
      "- How strict is the nut allergy (e.g., need to avoid cross-contact and nut oils)?\n",
      "- Any other ingredients to avoid or cuisines you love?\n",
      "\n",
      "I can help with:\n",
      "- Nut-free vegetarian recipes or a simple meal plan\n",
      "- Protein ideas (beans, lentils, chickpeas, peas, tofu/tempeh if soy is OK, seitan if gluten is OK, quinoa, eggs/dairy, seeds like sunflower/pumpkin if safe for you)\n",
      "- Eating-out tips and label-checking guidance\n",
      "\n",
      "How would you like to start?\n"
     ]
    }
   ],
   "source": [
    "from mem0.proxy.main import Mem0\n",
    "import yaml\n",
    "config = yaml.load(open(\"../config/mem0_config.yaml\"), Loader=yaml.FullLoader)\n",
    "client = Mem0(config=config)\n",
    "r = client.chat.completions.create(\n",
    "    # model=\"openrouter/openai/gpt-oss-20b\",\n",
    "    model=\"openai/gpt-5\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"I‚Äôm Alex, vegetarian, allergic to nuts.\"}],\n",
    "    user_id=\"alex\"\n",
    ")\n",
    "print(r.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5215c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äî get_all ‚Äî\n",
      "\n",
      "‚Äî search ‚Äî\n"
     ]
    }
   ],
   "source": [
    "from mem0 import Memory\n",
    "m = Memory.from_config(config)\n",
    "\n",
    "print(\"‚Äî get_all ‚Äî\")\n",
    "for mm in m.get_all(user_id=\"alex\")[\"results\"]:\n",
    "    print(mm[\"id\"], \"‚Üí\", mm[\"memory\"])\n",
    "\n",
    "print(\"\\n‚Äî search ‚Äî\")\n",
    "for h in m.search(\"diet / allergy / vegetarian\", user_id=\"alex\", limit=5)[\"results\"]:\n",
    "    print(round(h[\"score\"],3), \"‚Üí\", h[\"memory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7832d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Alex! I‚Äôve noted that you‚Äôre vegetarian and have a nut allergy. How can I help you today? If you need dinner ideas, recipe tweaks, restaurant suggestions in San‚ÄØFrancisco, or anything else, just let me know!\n",
      "Hey Alex‚Äîhappy to help you find a tasty, nut‚Äëfree vegetarian dinner in San‚ÄØFrancisco! Below are a mix of restaurants and a quick home‚Äëcook idea. I‚Äôve double‚Äëchecked that each place is either strictly vegetarian/vegan (or offers vegetarian options) and that the kitchen staff can accommodate nut‚Äëfree needs. Remember to call ahead to confirm, especially if you‚Äôre still worried about cross‚Äëcontamination.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. *The Plant Caf√©* (Mission)\n",
      "\n",
      "| Dish | Why it works | Nut‚Äëfree note |\n",
      "|------|--------------|---------------|\n",
      "| **Press‚ÄëCooked Veggie Burger** | Made with lentils, veggies, and a homemade empanada patty. It‚Äôs a ‚Äúsoft‚Äù bite that‚Äôs easy to chew and can be swapped for the ‚Äúclassic‚Äù if you prefer. | Ask for a raw‚Äëveggies side instead of any ‚Äúnutty‚Äù sauces. |\n",
      "| **Black Bean Tacos** | Al pastor‚Äëstyle flavoring but vegetarian, served on soft corn tortillas. | They have a nut‚Äëfree version of the pico‚Äëde‚Äëgallo; just double‚Äëcheck. |\n",
      "| **Carrot & Quinoa Salad** | Roughly ‚Äúsweet‚Äù but no nuts‚Äîperfect for a light lunch or dinner. | Great as a side or salad on its own. |\n",
      "\n",
      "üìç **Address:** 3565 18th St, San Francisco, CA 94114  \n",
      "üìû **Phone:** (415) 327‚Äë3313  \n",
      "‚è∞ **Hours:** 11‚ÄØam‚Äë10‚ÄØpm (Mon‚ÄëSun)\n",
      "\n",
      "---\n",
      "\n",
      "## 2. *Greens Restaurant* (Fort Mason)\n",
      "\n",
      "> ‚ÄúThe vegetarian paradise‚Äù of SF, Greens is a 5‚Äëstar Michelin‚Äëenshrined spot, but the menu is 100‚ÄØ% vegetarian and they‚Äôre used to handling allergies.\n",
      "\n",
      "| Dish | Why it works | Nut‚Äëfree note |\n",
      "|------|--------------|---------------|\n",
      "| **Fresh Spring Roll** | Made with shrimpless, but keep your eyes on the *no ‚Äòhoisin‚Äô sauce (which contains peanuts)*. | They serve a lemon‚Äëtahini dipping sauce; just leave out the tahini. |\n",
      "| **Poke Bowl** | Foam of cucumber, edamame, tofu, and vine‚Äëdress it with sesame‚Äëoil + rice vinegar. | No nuts; just verify sesame is fine (some folks have sesame allergies too). |\n",
      "| **Speciality Tart** | *Veggie Face‚Äëtartar* (spinach, avocado, sunflower seed underlining). | Sunflower seeds are safe‚Äîno peanuts. |\n",
      "\n",
      "üìç **Address:** 945 Mason St, San Francisco, CA 94123  \n",
      "üìû **Phone:** (415) 441‚Äë5600  \n",
      "‚è∞ **Hours:** 10‚ÄØam‚Äë9‚ÄØpm (Mon‚ÄëSun) ‚Äì Reservations strongly recommended.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. *Samovar Tea Lounge* (Pacific Heights)\n",
      "\n",
      "> A big‚Äëname bookshop & tea place that offers a decent vegetarian menu and takes allergies seriously.\n",
      "\n",
      "| Dish | Why it works | Nut‚Äëfree note |\n",
      "|------|--------------|---------------|\n",
      "| **Hummus Plate** | White‚Äëbean hummus, cucumber, olives, and a tomato slaw (no tahini). | All ingredients are nut‚Äëfree. |\n",
      "| **Tuscan Tomato Soup** | Tomato‚Äëbase stew, served with a white‚Äëbread roll. | Pure vegetarian; no nuts. |\n",
      "| **Paneer & Spinach* | Crumbled paneer spiced with homemade garam masala. | Onion‚Äëbased; no nuts. |\n",
      "\n",
      "üìç **Location:** 333 11th Avenue, SF (in the W. Cordova Books & Tea Lounge)  \n",
      "üìû **Phone:** (415) 843‚Äë2435  \n",
      "‚è∞ **Hours:** 8‚ÄØam‚Äë2‚ÄØam\n",
      "\n",
      "---\n",
      "\n",
      "## 4. *Sotto** (Mission)\n",
      "\n",
      "> Classic bowls of Italian‚Äëstyle comfort food, all vegetarian out of the gate.\n",
      "\n",
      "| Dish | Why it works | Nut‚Äëfree note |\n",
      "|------|--------------|---------------|\n",
      "| **Margherita Pesto Pasta** | Classic marinara with fresh basil pesto *tomato‚Äëbased* (ask for the pesto style ‚Äúminutino‚Äù that excludes pine nuts). | If you‚Äôre worried about cross‚Äëcross, ask for a ‚Äútomato‚Äëpesto‚Äù or simply skip the pesto. |\n",
      "| **Pumpkin Ravioli** | Pumpkin filling in delicate pasta sheets, finished in garlic‚Äëbutter sauce. | The butter sauce is nut‚Äëfree. |\n",
      "| **Caesar Salad** | croutons, Parmesan, romaine, no anchovy. | Add gluten‚Äëfree croutons if needed‚Äîno nuts. |\n",
      "\n",
      "üìç **Address:** 1060 Haight St, SF, CA 94102  \n",
      "üìû **Phone:** (415) 794‚Äë7700  \n",
      "‚è∞ **Hours:** 5‚ÄØPM‚Äë11:30‚ÄØPM (Mon‚ÄëSat)\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Quick Nut‚ÄëFree Home Dinner Idea ‚Äì ‚ÄúEasy‚ÄØQuinoa & Veggie Bowl‚Äù\n",
      "\n",
      "**Ingredients**\n",
      "\n",
      "| Item | Approx. Amount | Notes |\n",
      "|------|----------------|-------|\n",
      "| **Quinoa** | 1 cup | Rinse thoroughly |\n",
      "| **Mixed Veggies** | 2 cups (bell peppers, zucchini, carrots, broccoli) | Fresh or frozen |\n",
      "| **Chickpeas** | 1 can (drained & rinsed) | Adds protein |\n",
      "| **Tahini** | 2 tbsp (optional, but keep out if you‚Äôre chicken‚Äëallergic ‚Äì basil or simple olive‚Äëoil vinaigrette works great) | Check that it‚Äôs not mixed with nuts |\n",
      "| **Fresh Lemon Juice** | 1 tbsp | Adds brightness |\n",
      "| **Olive Oil** | 2 tbsp | For saut√© |\n",
      "| **Garlic** | 1 clove (minced) | Optional |\n",
      "| **Salt / pepper** | To taste | |\n",
      "| **Optional Garnishes** | Sliced avocado, chopped cilantro, roasted pumpkin seeds (if no nut allergy concerns) | |\n",
      "\n",
      "**Method**\n",
      "\n",
      "1. **Cook quinoa**: In 2 cups water, bring to boil ‚Üí cover ‚Üí simmer 15‚ÄØmin ‚Üí fluff.\n",
      "2. **Saut√© the veggies**: Heat olive oil in a skillet ‚Üí garlic ‚Üí add veggies ‚Üí stir‚Äëcook about 5‚Äë7‚ÄØmin until tender but still crisp.\n",
      "3. **Combine**: Quinoa + saut√©ed veggies + chickpeas ‚Üí gently fold.\n",
      "4. **Dress**: Olive oil, lemon juice, optional tahini, salt, pepper ‚Üí toss well.\n",
      "5. **Serve**: Bowl out, top with avocado slices or a handful of pumpkin seeds if you want crunch.\n",
      "\n",
      "üïí **Total Time:** ~25 minutes\n",
      "\n",
      "This bowl is 100‚ÄØ% vegetarian, zero nuts, and easily adjustable. You can swap veggies based on what‚Äôs in season‚Äîcherry tomatoes, spinach, or even a handful of kale.\n",
      "\n",
      "---\n",
      "\n",
      "### Quick Tips for Nut Allergies in SF\n",
      "\n",
      "1. **Speak Up** ‚Äì Even if a place says ‚Äúnut‚Äëfree,‚Äù ask for no cross‚Äëcontact with nut hoodsto or shake‚Äëup containers.\n",
      "2. **Avoid ‚ÄúCondiments‚Äù** ‚Äì Many soy sauces, sriracha, or vinaigrettes are surprisingly nut‚Äëbased.\n",
      "3. **Meet the Kitchen Staff** ‚Äì Especially if you have an intense reaction history.\n",
      "4. **Carry an EpiPen** ‚Äì Always a good safety net if you‚Äôre prone to severe reactions.\n",
      "\n",
      "Enjoy your meal, Alex! If you need reservations, alternate cooking ideas, or something else, just let me know.\n"
     ]
    }
   ],
   "source": [
    "# deps: mem0ai, openai (official SDK), pyyaml\n",
    "# env: OPENROUTER_API_KEY, Qdrant running at 127.0.0.1:6333\n",
    "\n",
    "import os, yaml, time\n",
    "from collections import deque\n",
    "from openai import OpenAI          # OpenRouter is OpenAI-compatible\n",
    "from mem0 import Memory\n",
    "\n",
    "# ---- Mem0 (OSS) config: Qdrant only matters here; LLM choice is for your responder (OpenRouter)\n",
    "config = yaml.safe_load(open(\"../config/mem0_config.yaml\"))\n",
    "mem = Memory.from_config(config)\n",
    "\n",
    "# ---- OpenRouter client\n",
    "client = OpenAI(base_url=\"https://openrouter.ai/api/v1\",\n",
    "                api_key=os.environ[\"OPENROUTER_API_KEY\"])\n",
    "\n",
    "M_RECENT = 10   # paper m\n",
    "S_SIM     = 10  # paper s\n",
    "TOPK_GEN  = 5   # retrieval injected into responder prompt\n",
    "\n",
    "def step_mem0(user_id: str, convo_window: deque, new_user_msg: str, model=\"openai/gpt-oss-20b\"):\n",
    "    \"\"\"\n",
    "    Paper-faithful loop:\n",
    "    1) Extraction+Update: pass the *pair* (prev, current) + up to m-2 earlier messages to Memory.add(..., infer=True)\n",
    "    2) Retrieval for answering: search top-k memories with current user query\n",
    "    3) Response: include retrieved memories before generating an answer with OpenRouter\n",
    "    \"\"\"\n",
    "    # 0) Build the turn-level messages as the paper uses a \"pair\" (m_{t-1}, m_t)\n",
    "    # Keep a sliding window of the last M_RECENT messages in `convo_window`\n",
    "    convo_window.append({\"role\": \"user\", \"content\": new_user_msg})\n",
    "    while len(convo_window) > M_RECENT:\n",
    "        convo_window.popleft()\n",
    "\n",
    "    # 1) Extraction + Update (Mem0 base). This triggers candidate-fact extraction and ADD/UPDATE/DELETE/NOOP.  [oai_citation:3‚Ä°arXiv](https://arxiv.org/pdf/2504.19413)\n",
    "    mem.add(list(convo_window), user_id=user_id, infer=True)\n",
    "\n",
    "    # 2) Retrieval for answering (simple semantic query using current user msg)\n",
    "    hits = mem.search(query=new_user_msg, user_id=user_id, limit=S_SIM)[\"results\"]  # S_SIM is only for update in paper; for answer use TOPK_GEN below.  [oai_citation:4‚Ä°docs.mem0.ai](https://docs.mem0.ai/open-source/python-quickstart?utm_source=chatgpt.com)\n",
    "    memtext = \"\\n\".join(h[\"memory\"] for h in hits[:TOPK_GEN]) if hits else \"‚Äî\"\n",
    "\n",
    "    # 3) Respond with OpenRouter (inject retrieved memories)\n",
    "    system = (\n",
    "        \"You are a helpful assistant.\\n\"\n",
    "        \"Known user facts (from long-term memory):\\n\"\n",
    "        f\"{memtext}\\n\\nUse these facts if relevant; do not invent new ones.\"\n",
    "    )\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + list(convo_window)\n",
    "\n",
    "    resp = client.chat.completions.create(model=model, messages=messages)\n",
    "    answer = resp.choices[0].message.content\n",
    "\n",
    "    # After you send the assistant reply, append it so next *pair* is (user, assistant)\n",
    "    convo_window.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    while len(convo_window) > M_RECENT:\n",
    "        convo_window.popleft()\n",
    "    return answer\n",
    "\n",
    "# ---- one-shot example\n",
    "window = deque([], maxlen=M_RECENT)\n",
    "print(step_mem0(\"alex\", window, \"I‚Äôm Alex, vegetarian, allergic to nuts.\"))\n",
    "time.sleep(1.0)  # allow DB write\n",
    "print(step_mem0(\"alex\", window, \"Suggest dinner ideas in San Francisco.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061a0161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([{'role': 'user', 'content': 'I‚Äôm Alex, vegetarian, allergic to nuts.'},\n",
       "       {'role': 'assistant',\n",
       "        'content': 'Hi Alex! I‚Äôve noted that you‚Äôre vegetarian and have a nut allergy. How can I help you today? If you need dinner ideas, recipe tweaks, restaurant suggestions in San\\u202fFrancisco, or anything else, just let me know!'},\n",
       "       {'role': 'user', 'content': 'Suggest dinner ideas in San Francisco.'},\n",
       "       {'role': 'assistant',\n",
       "        'content': 'Hey Alex‚Äîhappy to help you find a tasty, nut‚Äëfree vegetarian dinner in San\\u202fFrancisco! Below are a mix of restaurants and a quick home‚Äëcook idea. I‚Äôve double‚Äëchecked that each place is either strictly vegetarian/vegan (or offers vegetarian options) and that the kitchen staff can accommodate nut‚Äëfree needs. Remember to call ahead to confirm, especially if you‚Äôre still worried about cross‚Äëcontamination.\\n\\n---\\n\\n## 1. *The Plant Caf√©* (Mission)\\n\\n| Dish | Why it works | Nut‚Äëfree note |\\n|------|--------------|---------------|\\n| **Press‚ÄëCooked Veggie Burger** | Made with lentils, veggies, and a homemade empanada patty. It‚Äôs a ‚Äúsoft‚Äù bite that‚Äôs easy to chew and can be swapped for the ‚Äúclassic‚Äù if you prefer. | Ask for a raw‚Äëveggies side instead of any ‚Äúnutty‚Äù sauces. |\\n| **Black Bean Tacos** | Al pastor‚Äëstyle flavoring but vegetarian, served on soft corn tortillas. | They have a nut‚Äëfree version of the pico‚Äëde‚Äëgallo; just double‚Äëcheck. |\\n| **Carrot & Quinoa Salad** | Roughly ‚Äúsweet‚Äù but no nuts‚Äîperfect for a light lunch or dinner. | Great as a side or salad on its own. |\\n\\nüìç **Address:** 3565 18th St, San Francisco, CA 94114  \\nüìû **Phone:** (415) 327‚Äë3313  \\n‚è∞ **Hours:** 11\\u202fam‚Äë10\\u202fpm (Mon‚ÄëSun)\\n\\n---\\n\\n## 2. *Greens Restaurant* (Fort Mason)\\n\\n> ‚ÄúThe vegetarian paradise‚Äù of SF, Greens is a 5‚Äëstar Michelin‚Äëenshrined spot, but the menu is 100\\u202f% vegetarian and they‚Äôre used to handling allergies.\\n\\n| Dish | Why it works | Nut‚Äëfree note |\\n|------|--------------|---------------|\\n| **Fresh Spring Roll** | Made with shrimpless, but keep your eyes on the *no ‚Äòhoisin‚Äô sauce (which contains peanuts)*. | They serve a lemon‚Äëtahini dipping sauce; just leave out the tahini. |\\n| **Poke Bowl** | Foam of cucumber, edamame, tofu, and vine‚Äëdress it with sesame‚Äëoil + rice vinegar. | No nuts; just verify sesame is fine (some folks have sesame allergies too). |\\n| **Speciality Tart** | *Veggie Face‚Äëtartar* (spinach, avocado, sunflower seed underlining). | Sunflower seeds are safe‚Äîno peanuts. |\\n\\nüìç **Address:** 945 Mason St, San Francisco, CA 94123  \\nüìû **Phone:** (415) 441‚Äë5600  \\n‚è∞ **Hours:** 10\\u202fam‚Äë9\\u202fpm (Mon‚ÄëSun) ‚Äì Reservations strongly recommended.\\n\\n---\\n\\n## 3. *Samovar Tea Lounge* (Pacific Heights)\\n\\n> A big‚Äëname bookshop & tea place that offers a decent vegetarian menu and takes allergies seriously.\\n\\n| Dish | Why it works | Nut‚Äëfree note |\\n|------|--------------|---------------|\\n| **Hummus Plate** | White‚Äëbean hummus, cucumber, olives, and a tomato slaw (no tahini). | All ingredients are nut‚Äëfree. |\\n| **Tuscan Tomato Soup** | Tomato‚Äëbase stew, served with a white‚Äëbread roll. | Pure vegetarian; no nuts. |\\n| **Paneer & Spinach* | Crumbled paneer spiced with homemade garam masala. | Onion‚Äëbased; no nuts. |\\n\\nüìç **Location:** 333 11th Avenue, SF (in the W. Cordova Books & Tea Lounge)  \\nüìû **Phone:** (415) 843‚Äë2435  \\n‚è∞ **Hours:** 8\\u202fam‚Äë2\\u202fam\\n\\n---\\n\\n## 4. *Sotto** (Mission)\\n\\n> Classic bowls of Italian‚Äëstyle comfort food, all vegetarian out of the gate.\\n\\n| Dish | Why it works | Nut‚Äëfree note |\\n|------|--------------|---------------|\\n| **Margherita Pesto Pasta** | Classic marinara with fresh basil pesto *tomato‚Äëbased* (ask for the pesto style ‚Äúminutino‚Äù that excludes pine nuts). | If you‚Äôre worried about cross‚Äëcross, ask for a ‚Äútomato‚Äëpesto‚Äù or simply skip the pesto. |\\n| **Pumpkin Ravioli** | Pumpkin filling in delicate pasta sheets, finished in garlic‚Äëbutter sauce. | The butter sauce is nut‚Äëfree. |\\n| **Caesar Salad** | croutons, Parmesan, romaine, no anchovy. | Add gluten‚Äëfree croutons if needed‚Äîno nuts. |\\n\\nüìç **Address:** 1060 Haight St, SF, CA 94102  \\nüìû **Phone:** (415) 794‚Äë7700  \\n‚è∞ **Hours:** 5\\u202fPM‚Äë11:30\\u202fPM (Mon‚ÄëSat)\\n\\n---\\n\\n## 5. Quick Nut‚ÄëFree Home Dinner Idea ‚Äì ‚ÄúEasy\\u202fQuinoa & Veggie Bowl‚Äù\\n\\n**Ingredients**\\n\\n| Item | Approx. Amount | Notes |\\n|------|----------------|-------|\\n| **Quinoa** | 1 cup | Rinse thoroughly |\\n| **Mixed Veggies** | 2 cups (bell peppers, zucchini, carrots, broccoli) | Fresh or frozen |\\n| **Chickpeas** | 1 can (drained & rinsed) | Adds protein |\\n| **Tahini** | 2 tbsp (optional, but keep out if you‚Äôre chicken‚Äëallergic ‚Äì basil or simple olive‚Äëoil vinaigrette works great) | Check that it‚Äôs not mixed with nuts |\\n| **Fresh Lemon Juice** | 1 tbsp | Adds brightness |\\n| **Olive Oil** | 2 tbsp | For saut√© |\\n| **Garlic** | 1 clove (minced) | Optional |\\n| **Salt / pepper** | To taste | |\\n| **Optional Garnishes** | Sliced avocado, chopped cilantro, roasted pumpkin seeds (if no nut allergy concerns) | |\\n\\n**Method**\\n\\n1. **Cook quinoa**: In 2 cups water, bring to boil ‚Üí cover ‚Üí simmer 15\\u202fmin ‚Üí fluff.\\n2. **Saut√© the veggies**: Heat olive oil in a skillet ‚Üí garlic ‚Üí add veggies ‚Üí stir‚Äëcook about 5‚Äë7\\u202fmin until tender but still crisp.\\n3. **Combine**: Quinoa + saut√©ed veggies + chickpeas ‚Üí gently fold.\\n4. **Dress**: Olive oil, lemon juice, optional tahini, salt, pepper ‚Üí toss well.\\n5. **Serve**: Bowl out, top with avocado slices or a handful of pumpkin seeds if you want crunch.\\n\\nüïí **Total Time:** ~25 minutes\\n\\nThis bowl is 100\\u202f% vegetarian, zero nuts, and easily adjustable. You can swap veggies based on what‚Äôs in season‚Äîcherry tomatoes, spinach, or even a handful of kale.\\n\\n---\\n\\n### Quick Tips for Nut Allergies in SF\\n\\n1. **Speak Up** ‚Äì Even if a place says ‚Äúnut‚Äëfree,‚Äù ask for no cross‚Äëcontact with nut hoodsto or shake‚Äëup containers.\\n2. **Avoid ‚ÄúCondiments‚Äù** ‚Äì Many soy sauces, sriracha, or vinaigrettes are surprisingly nut‚Äëbased.\\n3. **Meet the Kitchen Staff** ‚Äì Especially if you have an intense reaction history.\\n4. **Carry an EpiPen** ‚Äì Always a good safety net if you‚Äôre prone to severe reactions.\\n\\nEnjoy your meal, Alex! If you need reservations, alternate cooking ideas, or something else, just let me know.'}],\n",
       "      maxlen=10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c313958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äî get_all ‚Äî\n",
      "466b1b71-ca45-4907-a585-907b8ff8d0c7 ‚Üí Is a vegetarian\n",
      "8a98cbdd-816e-4549-b2c2-30f67e609aa1 ‚Üí Name is Alex\n",
      "b90b046e-c733-4096-9f3b-faaf371948bc ‚Üí Looking for dinner ideas in San Francisco\n",
      "f2a3c4db-15f6-42cd-9940-c403503972b1 ‚Üí Allergic to nuts\n",
      "\n",
      "‚Äî search ‚Äî\n",
      "0.492 ‚Üí Is a vegetarian\n",
      "0.461 ‚Üí Allergic to nuts\n",
      "0.261 ‚Üí Looking for dinner ideas in San Francisco\n",
      "0.143 ‚Üí Name is Alex\n"
     ]
    }
   ],
   "source": [
    "from mem0 import Memory\n",
    "m = Memory.from_config(config)\n",
    "\n",
    "print(\"‚Äî get_all ‚Äî\")\n",
    "for mm in mem.get_all(user_id=\"alex\")[\"results\"]:\n",
    "    print(mm[\"id\"], \"‚Üí\", mm[\"memory\"])\n",
    "\n",
    "print(\"\\n‚Äî search ‚Äî\")\n",
    "for h in mem.search(\"diet / allergy / vegetarian\", user_id=\"alex\", limit=5)[\"results\"]:\n",
    "    print(round(h[\"score\"],3), \"‚Üí\", h[\"memory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a896c0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem0 version: 1.0.0b0\n",
      "Memory.add signature: (self, messages, *, user_id: Optional[str] = None, agent_id: Optional[str] = None, run_id: Optional[str] = None, metadata: Optional[Dict[str, Any]] = None, infer: bool = True, memory_type: Optional[str] = None, prompt: Optional[str] = None)\n"
     ]
    }
   ],
   "source": [
    "import mem0, inspect\n",
    "from mem0.memory.main import Memory\n",
    "print(\"mem0 version:\", getattr(mem0, \"__version__\", \"unknown\"))\n",
    "print(\"Memory.add signature:\", inspect.signature(Memory.add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd45840",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"You are an intelligent memory assistant tasked with retrieving accurate information from\n",
    "conversation memories.\n",
    "\n",
    "# CONTEXT:\n",
    "You have access to memories from two speakers in a conversation. These memories contain\n",
    "timestamped information that may be relevant to answering the question.\n",
    "\n",
    "# INSTRUCTIONS:\n",
    "1. Carefully analyze all provided memories from both speakers\n",
    "2. Pay special attention to the timestamps to determine the answer\n",
    "3. If the question asks about a specific event or fact, look for direct evidence in the\n",
    "memories\n",
    "4. If the memories contain contradictory information, prioritize the most recent memory\n",
    "5. If there is a question about time references (like \"last year\", \"two months ago\",\n",
    "etc.), calculate the actual date based on the memory timestamp. For example, if a memory\n",
    "from 4 May 2022 mentions \"went to India last year,\" then the trip occurred in 2021.\n",
    "6. Always convert relative time references to specific dates, months, or years. For\n",
    "example, convert \"last year\" to \"2022\" or \"two months ago\" to \"March 2023\" based on the\n",
    "memory timestamp. Ignore the reference while answering the question.\n",
    "7. Focus only on the content of the memories from both speakers. Do not confuse character\n",
    "names mentioned in memories with the actual users who created those memories.\n",
    "8. The answer should be less than 5-6 words.\n",
    "\n",
    "# APPROACH (Think step by step):\n",
    "1. First, examine all memories that contain information related to the question\n",
    "2. Examine the timestamps and content of these memories carefully\n",
    "3. Look for explicit mentions of dates, times, locations, or events that answer the\n",
    "question\n",
    "4. If the answer requires calculation (e.g., converting relative time references), show\n",
    "your work\n",
    "5. Formulate a precise, concise answer based solely on the evidence in the memories\n",
    "6. Double-check that your answer directly addresses the question asked\n",
    "7. Ensure your final answer is specific and avoids vague time references\n",
    "\n",
    "Memories for user {speaker_1_user_id}:\n",
    "{speaker_1_memories}\n",
    "\n",
    "Memories for user {speaker_2_user_id}:\n",
    "{speaker_2_memories}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a1b3c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to meet you, Alex! üå± If you‚Äôre looking for vegetarian dinner ideas around San‚ÄØFrancisco that are nut‚Äëfree, I‚Äôve got plenty of tasty options for you. Let me know what kind of cuisine you‚Äôre in the mood for (e.g., tacos, pasta, sushi, etc.) or if you‚Äôd like a recipe, restaurant recommendation, or a grocery list. I‚Äôm happy to help!\n",
      "That‚Äôs a personal preference and totally valid‚Äîeveryone‚Äôs sexuality is unique. If you‚Äôre looking to talk about how to explore it respectfully and safely with a partner (e.g., establishing clear boundaries, practicing good hygiene, or finding communities that share similar tastes), I‚Äôm here to help. Just let me know what specific information or guidance you‚Äôd like, and we‚Äôll keep things respectful and non‚Äëgraphic.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from mem0 import Memory\n",
    "from collections import deque\n",
    "import os, yaml\n",
    "import time\n",
    "\n",
    "config = yaml.safe_load(open(\"../config/mem0_config.yaml\"))\n",
    "mem = Memory.from_config(config)\n",
    "client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"])\n",
    "\n",
    "M_RECENT, S_SIM, TOPK_GEN = 10, 10, 5\n",
    "\n",
    "def mem0_step(user_id: str, convo_window: deque, user_message: str, model=\"openai/gpt-oss-20b\"):\n",
    "    convo_window.append({\"role\": \"user\", \"content\": user_message})\n",
    "    while len(convo_window) > M_RECENT:\n",
    "        convo_window.popleft()\n",
    "\n",
    "    # Extraction + Update\n",
    "    mem.add(list(convo_window), user_id=user_id, infer=True)\n",
    "\n",
    "    # Retrieve top-k memories (used as factual context)\n",
    "    hits = mem.search(query=user_message, user_id=user_id, limit=S_SIM)[\"results\"]\n",
    "    memtext = \"\\n\".join(h[\"memory\"] for h in hits[:TOPK_GEN])\n",
    "\n",
    "    # --- Faithful injection ---\n",
    "    # As per paper: prepend retrieved facts *as is* before user message.\n",
    "    messages = []\n",
    "    if memtext.strip():\n",
    "        messages.append({\"role\": \"system\", \"content\": f\"Memories:\\n{memtext}\"})\n",
    "    messages.extend(list(convo_window))  # previous turns + current user\n",
    "\n",
    "    resp = client.chat.completions.create(model=model, messages=messages)\n",
    "    answer = resp.choices[0].message.content\n",
    "    convo_window.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    return answer\n",
    "\n",
    "# ---- one-shot example\n",
    "window = deque([], maxlen=M_RECENT)\n",
    "print(mem0_step(\"alex\", window, \"I‚Äôm Alex, vegetarian, allergic to nuts.\"))\n",
    "time.sleep(1.0)  # allow DB write\n",
    "print(mem0_step(\"alex\", window, \"I am homosexual and specifically I like blowjobs with foots.\"))\n",
    "time.sleep(1.0)\n",
    "# print(mem0_step(\"alex\", window, \"Suggest dinner ideas in San Francisco.\"))\n",
    "# print(mem0_step(\"alex\", window, \"I want to play hangman. You be the host. Think of a secret word and tell me the number of letters in it. I am going to try to guess it letter by letter. You will tell me if I am right or wrong.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e23d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äî get_all ‚Äî\n",
      "05e1ba70-be6c-43d1-8d82-6ee971b2834b ‚Üí Is homosexual\n",
      "2569fe86-90a8-4ed5-a127-79e27a4c7d95 ‚Üí Likes blowjobs with feet\n",
      "466b1b71-ca45-4907-a585-907b8ff8d0c7 ‚Üí Is a vegetarian\n",
      "8a98cbdd-816e-4549-b2c2-30f67e609aa1 ‚Üí Name is Alex\n",
      "b90b046e-c733-4096-9f3b-faaf371948bc ‚Üí Looking for dinner ideas in San Francisco\n",
      "f2a3c4db-15f6-42cd-9940-c403503972b1 ‚Üí Allergic to nuts\n",
      "\n",
      "‚Äî search ‚Äî\n",
      "0.492 ‚Üí Is a vegetarian\n",
      "0.461 ‚Üí Allergic to nuts\n",
      "0.261 ‚Üí Looking for dinner ideas in San Francisco\n",
      "0.166 ‚Üí Is homosexual\n",
      "0.143 ‚Üí Name is Alex\n"
     ]
    }
   ],
   "source": [
    "print(\"‚Äî get_all ‚Äî\")\n",
    "for mm in mem.get_all(user_id=\"alex\")[\"results\"]:\n",
    "    print(mm[\"id\"], \"‚Üí\", mm[\"memory\"])\n",
    "\n",
    "print(\"\\n‚Äî search ‚Äî\")\n",
    "for h in mem.search(\"diet / allergy / vegetarian\", user_id=\"alex\", limit=5)[\"results\"]:\n",
    "    print(round(h[\"score\"],3), \"‚Üí\", h[\"memory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "188763b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put this VERY early in your process (before Mem0/LiteLLM calls)\n",
    "import litellm\n",
    "from litellm import utils as _lu\n",
    "\n",
    "_orig = _lu.supports_function_calling\n",
    "\n",
    "_WHITELIST = {\n",
    "    \"openrouter/qwen/qwen3-32b\",\n",
    "    \"openrouter/qwen/qwen3-235b-a22b-thinking-2507\",\n",
    "}\n",
    "\n",
    "def _patched_supports_function_calling(model: str) -> bool:\n",
    "    if model in _WHITELIST:\n",
    "        return True\n",
    "    return _orig(model)\n",
    "\n",
    "_lu.supports_function_calling = _patched_supports_function_calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2217e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 12:39:22,003 - INFO - Created index for user_id in collection mem0\n",
      "2025-10-20 12:39:22,009 - INFO - Created index for agent_id in collection mem0\n",
      "2025-10-20 12:39:22,014 - INFO - Created index for run_id in collection mem0\n",
      "2025-10-20 12:39:22,019 - INFO - Created index for actor_id in collection mem0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is file readable:  True\n",
      "‚úÖ LLM Provider loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 12:39:22,082 - INFO - Created index for user_id in collection mem0migrations\n",
      "2025-10-20 12:39:22,091 - INFO - Created index for agent_id in collection mem0migrations\n",
      "2025-10-20 12:39:22,099 - INFO - Created index for run_id in collection mem0migrations\n",
      "2025-10-20 12:39:22,105 - INFO - Created index for actor_id in collection mem0migrations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Mem0Agent is ready. Type 'quit', 'exit', or 'q' to end.\n"
     ]
    }
   ],
   "source": [
    "from hangman.agents.mem0_agent import Mem0Agent\n",
    "from hangman.providers.llmprovider import load_llm_provider\n",
    "from langchain_core.messages import HumanMessage\n",
    "import os, yaml\n",
    "\n",
    "\n",
    "CONFIG_PATH = \"../config/config.yaml\"          # LLM + Mem0/Qdrant config\n",
    "MEM0_CONFIG_PATH = \"../config/mem0_config_qwen3_235b.yaml\"\n",
    "\n",
    "print(\"Is file readable: \", os.access(CONFIG_PATH, os.R_OK))\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Load your OpenRouter-backed LLMProvider\n",
    "try:\n",
    "    # e.g., \"qwen3_235b_openrouter\" or \"gpt_oss_20b_openrouter\" as you use in ReActMem\n",
    "    main_llm = load_llm_provider(CONFIG_PATH, provider_name=\"qwen3_235b_openrouter\")\n",
    "    print(\"‚úÖ LLM Provider loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load LLM Provider: {e}\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# Initialize the Mem0Agent\n",
    "agent = Mem0Agent(\n",
    "    llm_provider=main_llm,\n",
    "    mem0_config_path=MEM0_CONFIG_PATH,\n",
    "    session_id=\"mem0_session_1\",\n",
    "    m_recent=10,       # paper: m=10\n",
    "    s_neighbors=10,    # paper: s=10 (used internally by update; OSS may use default)\n",
    "    k_per_user=10,     # retrieved memories per speaker for QA prompt\n",
    ")\n",
    "print(\"ü§ñ Mem0Agent is ready. Type 'quit', 'exit', or 'q' to end.\")\n",
    "\n",
    "# Interactive loop (same shape as ReActMem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd19919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m12:39:22 - LiteLLM:INFO\u001b[0m: utils.py:3373 - \n",
      "LiteLLM completion() model= qwen/qwen3-235b-a22b-thinking-2507; provider = openrouter\n",
      "2025-10-20 12:39:22,186 - INFO - \n",
      "LiteLLM completion() model= qwen/qwen3-235b-a22b-thinking-2507; provider = openrouter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/b/baldelld/scratch/hangman/.venv/lib/python3.11/site-packages/httpx/_models.py:408: DeprecationWarning: Use 'content=<...>' to upload raw bytes/text content.\n",
      "  headers, stream = encode_request(\n",
      "\u001b[92m12:40:01 - LiteLLM:INFO\u001b[0m: utils.py:1286 - Wrapper: Completed Call, calling success_handler\n",
      "2025-10-20 12:40:01,101 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-10-20 12:40:05,281 - INFO - Total existing memories: 3\n",
      "\u001b[92m12:40:05 - LiteLLM:INFO\u001b[0m: utils.py:3373 - \n",
      "LiteLLM completion() model= qwen/qwen3-235b-a22b-thinking-2507; provider = openrouter\n",
      "2025-10-20 12:40:05,282 - INFO - \n",
      "LiteLLM completion() model= qwen/qwen3-235b-a22b-thinking-2507; provider = openrouter\n"
     ]
    }
   ],
   "source": [
    "# # put this VERY early in your process (before Mem0/LiteLLM calls)\n",
    "# import litellm\n",
    "# from litellm import utils as _lu\n",
    "\n",
    "# _orig = _lu.supports_function_calling\n",
    "\n",
    "# _WHITELIST = {\n",
    "#     \"openrouter/qwen/qwen3-32b\",\n",
    "#     \"openrouter/qwen/qwen3-235b-a22b-thinking-2507\",\n",
    "# }\n",
    "\n",
    "# def _patched_supports_function_calling(model: str) -> bool:\n",
    "#     if model in _WHITELIST:\n",
    "#         return True\n",
    "#     return _orig(model)\n",
    "\n",
    "# _lu.supports_function_calling = _patched_supports_function_calling\n",
    "\n",
    "messages = [HumanMessage(content=\"I‚Äôm Alex, vegetarian, allergic to nuts.\")]\n",
    "agent.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac20d8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openrouter/qwen/qwen3-235b-a22b-thinking-2507 NOT found in LiteLLM‚Äôs internal model list.\n",
      "supports_function_calling: False\n",
      "openrouter/qwen/qwen3-32b NOT found in LiteLLM‚Äôs internal model list.\n",
      "supports_function_calling: False\n",
      "openrouter/openai/gpt-oss-120b exists in LiteLLM registry.\n",
      "supports_function_calling: True\n",
      "openrouter/qwen/qwen3-235b-a22b-thinking-2507 NOT found in LiteLLM‚Äôs internal model list.\n",
      "supports_function_calling: False\n"
     ]
    }
   ],
   "source": [
    "import litellm\n",
    "from litellm import model_cost, model_alias_map\n",
    "\n",
    "model_name = \"openrouter/qwen/qwen3-235b-a22b-thinking-2507\"\n",
    "\n",
    "for model_name in [\"openrouter/qwen/qwen3-235b-a22b-thinking-2507\", \"openrouter/qwen/qwen3-32b\", \"openrouter/openai/gpt-oss-120b\", \"openrouter/qwen/qwen3-235b-a22b-thinking-2507\"]:   \n",
    "    # 1Ô∏è‚É£ Check whether the model is in LiteLLM‚Äôs registry\n",
    "    if model_name in model_cost or model_name in model_alias_map:\n",
    "        print(f\"{model_name} exists in LiteLLM registry.\")\n",
    "    else:\n",
    "        print(f\"{model_name} NOT found in LiteLLM‚Äôs internal model list.\")\n",
    "\n",
    "    # 2Ô∏è‚É£ Then, check if LiteLLM believes it supports function calling\n",
    "    from litellm.utils import supports_function_calling\n",
    "\n",
    "    print(\"supports_function_calling:\", supports_function_calling(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9924e739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='gen-1760977175-xoAoVj6dz5wl2LmC6TKi', created=1760977175, model='qwen/qwen3-235b-a22b-thinking-2507', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Here are simple code examples in several popular programming languages that output \"Hi\" to the console:\\n\\n---\\n\\n### **Python**\\n```python\\nprint(\"Hi\")\\n```\\n\\n---\\n\\n### **JavaScript** (Node.js or Browser Console)\\n```javascript\\nconsole.log(\"Hi\");\\n```\\n\\n---\\n\\n### **Java**\\n```java\\npublic class Main {\\n    public static void main(String[] args) {\\n        System.out.println(\"Hi\");\\n    }\\n}\\n```\\n\\n---\\n\\n### **C**\\n```c\\n#include <stdio.h>\\n\\nint main() {\\n    printf(\"Hi\\\\n\");\\n    return 0;\\n}\\n```\\n\\n---\\n\\n### **C++**\\n```cpp\\n#include <iostream>\\n\\nint main() {\\n    std::cout << \"Hi\" << std::endl;\\n    return 0;\\n}\\n```\\n\\n---\\n\\n### **Bash**\\n```bash\\necho \"Hi\"\\n```\\n\\n---\\n\\n### **Ruby**\\n```ruby\\nputs \"Hi\"\\n```\\n\\n---\\n\\n### **C#**\\n```csharp\\nusing System;\\n\\nclass Program {\\n    static void Main() {\\n        Console.WriteLine(\"Hi\");\\n    }\\n}\\n```\\n\\n---\\n\\n### **Go**\\n```go\\npackage main\\n\\nimport \"fmt\"\\n\\nfunc main() {\\n    fmt.Println(\"Hi\")\\n}\\n```\\n\\n---\\n\\n### How to Run:\\n1. **Python**: Save as `hi.py` ‚Üí Run `python hi.py`  \\n2. **JavaScript**: Save as `hi.js` ‚Üí Run `node hi.js`  \\n3. **Java**: Save as `Main.java` ‚Üí Compile `javac Main.java` ‚Üí Run `java Main`  \\n4. **C/C++**: Compile with `gcc`/`g++` ‚Üí Run the output executable  \\n\\nAll programs will output:  \\n```\\nHi\\n```', role='assistant', tool_calls=None, function_call=None, reasoning_content='\\nWe are going to write a simple program that prints \"Hi\" to the console.\\n Since the problem is very straightforward, we can do this in multiple languages.\\n However, the user didn\\'t specify a language, so I\\'ll choose a few common ones.\\n\\n Let\\'s provide examples in:\\n 1. Python\\n 2. JavaScript (for the browser console and Node.js)\\n 3. Java\\n 4. C\\n 5. C++\\n\\n But note: the problem says \"write code for saying hi\", so the simplest thing is to print \"Hi\".\\n\\n However, if the user wants a more interactive program, we could read a name and say \"Hi, [name]\".\\n But the problem doesn\\'t specify. Since it says \"saying hi\", I\\'ll assume the simplest: output \"Hi\".\\n\\n But to be safe, let me read the problem again: \"write code for saying hi\"\\n\\n I think the expected output is just the string \"Hi\".\\n\\n Let\\'s write in several languages as examples.\\n', provider_specific_fields={'refusal': None, 'reasoning': '\\nWe are going to write a simple program that prints \"Hi\" to the console.\\n Since the problem is very straightforward, we can do this in multiple languages.\\n However, the user didn\\'t specify a language, so I\\'ll choose a few common ones.\\n\\n Let\\'s provide examples in:\\n 1. Python\\n 2. JavaScript (for the browser console and Node.js)\\n 3. Java\\n 4. C\\n 5. C++\\n\\n But note: the problem says \"write code for saying hi\", so the simplest thing is to print \"Hi\".\\n\\n However, if the user wants a more interactive program, we could read a name and say \"Hi, [name]\".\\n But the problem doesn\\'t specify. Since it says \"saying hi\", I\\'ll assume the simplest: output \"Hi\".\\n\\n But to be safe, let me read the problem again: \"write code for saying hi\"\\n\\n I think the expected output is just the string \"Hi\".\\n\\n Let\\'s write in several languages as examples.\\n', 'reasoning_content': '\\nWe are going to write a simple program that prints \"Hi\" to the console.\\n Since the problem is very straightforward, we can do this in multiple languages.\\n However, the user didn\\'t specify a language, so I\\'ll choose a few common ones.\\n\\n Let\\'s provide examples in:\\n 1. Python\\n 2. JavaScript (for the browser console and Node.js)\\n 3. Java\\n 4. C\\n 5. C++\\n\\n But note: the problem says \"write code for saying hi\", so the simplest thing is to print \"Hi\".\\n\\n However, if the user wants a more interactive program, we could read a name and say \"Hi, [name]\".\\n But the problem doesn\\'t specify. Since it says \"saying hi\", I\\'ll assume the simplest: output \"Hi\".\\n\\n But to be safe, let me read the problem again: \"write code for saying hi\"\\n\\n I think the expected output is just the string \"Hi\".\\n\\n Let\\'s write in several languages as examples.\\n'}), provider_specific_fields={'native_finish_reason': 'stop'})], usage=Usage(completion_tokens=559, prompt_tokens=14, total_tokens=573, completion_tokens_details=None, prompt_tokens_details=None), provider='Chutes')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "response = completion(\n",
    "            model=\"openrouter/qwen/qwen3-235b-a22b-thinking-2507\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"write code for saying hi\"}]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf58c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this once early, before Mem0 imports its LLM\n",
    "from litellm import utils as _lu\n",
    "_orig = _lu.supports_function_calling\n",
    "\n",
    "WHITELIST = {\n",
    "    \"openrouter/qwen/qwen3-32b\",\n",
    "    \"openrouter/qwen/qwen3-235b-a22b-thinking-2507\",\n",
    "}\n",
    "\n",
    "def patched_supports(model: str) -> bool:\n",
    "    if model in WHITELIST:\n",
    "        return True\n",
    "    return _orig(model)\n",
    "\n",
    "_lu.supports_function_calling = patched_supports\n",
    "\n",
    "import litellm\n",
    "from litellm import model_cost\n",
    "\n",
    "for m in [\n",
    "    \"openrouter/qwen/qwen3-32b\",\n",
    "    \"openrouter/qwen/qwen3-235b-a22b-thinking-2507\",\n",
    "]:\n",
    "    if m not in model_cost:\n",
    "        model_cost[m] = {\n",
    "            \"input_cost_per_token\": 0.0,   # or your real price if you care\n",
    "            \"output_cost_per_token\": 0.0,\n",
    "            \"supports_function_calling\": True,  # <-- makes the check pass\n",
    "            \"max_input_tokens\": 131072,        # a safe default\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd600aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message(content='', role='assistant', tool_calls=[ChatCompletionMessageToolCall(index=0, function=Function(arguments='{\"text\": \"hi\"}', name='echo'), id='f97022ec7', type='function')], function_call=None, provider_specific_fields={'refusal': None, 'reasoning': None})\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "\n",
    "tools = [{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"echo\",\n",
    "    \"description\": \"echo back a string\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\"text\": {\"type\": \"string\"}},\n",
    "      \"required\": [\"text\"]\n",
    "    }\n",
    "  }\n",
    "}]\n",
    "\n",
    "r = completion(\n",
    "    model=\"openrouter/qwen/qwen3-235b-a22b-thinking-2507\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"call echo('hi')\"}],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "print(r.choices[0].message)  # look for tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a906da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
