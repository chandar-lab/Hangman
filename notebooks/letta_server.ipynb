{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57eab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTA_API_KEY=\"sk-let-MmI4NDFmYTAtYjIyZi00MDM1LTllMDQtM2M3Y2M3YzI3Y2MxOmM1NzA1YmI3LWVjN2EtNDhlNy1hZmU0LTNmOWU3MTM1OGVmMQ==\"\n",
    "PROJECT_ID=\"cab038f0-a1d1-4b42-87ff-48744ed2255f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52200079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default agent_type: letta_v1_agent\n",
      "Full agent details:\n",
      "  - ID: agent-a5507c14-1324-4742-ac81-cef96921f4c8\n",
      "  - Name: AngryWolf\n",
      "  - Tool rules: []\n",
      "\n",
      "memgpt_agent agent_type: letta_v1_agent\n",
      "\n",
      "Test agent deleted\n"
     ]
    }
   ],
   "source": [
    "# Create a new agent WITHOUT specifying agent_type to see the default\n",
    "default_agent = client.agents.create(\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    "    embedding=\"openai/text-embedding-3-small\",\n",
    "    memory_blocks=[\n",
    "        {\"label\": \"persona\", \"value\": \"Test persona\"},\n",
    "        {\"label\": \"human\", \"value\": \"\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Check what agent_type was assigned by default\n",
    "print(f\"Default agent_type: {default_agent.agent_type}\")\n",
    "print(f\"Full agent details:\")\n",
    "print(f\"  - ID: {default_agent.id}\")\n",
    "print(f\"  - Name: {default_agent.name}\")\n",
    "\n",
    "# Also check tool_rules if accessible\n",
    "if hasattr(default_agent, 'tool_rules'):\n",
    "    print(f\"  - Tool rules: {default_agent.tool_rules}\")\n",
    "\n",
    "# Compare with the memgpt_agent you just created\n",
    "memgpt_agent = client.agents.retrieve(agent_state.id)  # The one with agent_type=\"memgpt_agent\"\n",
    "print(f\"\\nmemgpt_agent agent_type: {memgpt_agent.agent_type}\")\n",
    "\n",
    "# Clean up test agent\n",
    "client.agents.delete(default_agent.id)\n",
    "print(f\"\\nTest agent deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5354c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client created successfully!\n",
      "Using project: cab038f0-a1d1-4b42-87ff-48744ed2255f\n"
     ]
    }
   ],
   "source": [
    "# Install and import Letta client\n",
    "# !pip install letta-client\n",
    "\n",
    "from letta_client import Letta\n",
    "import os\n",
    "\n",
    "# Set up the client - use 'token' parameter, not 'api_key'\n",
    "client = Letta(token=LETTA_API_KEY)\n",
    "\n",
    "print(\"Client created successfully!\")\n",
    "print(f\"Using project: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d023840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created! ID: agent-4c4c3c4c-586b-4014-97d3-b467e1fde5f2\n",
      "Agent name: MagnificentXylophone\n",
      "Model: gpt-4o\n",
      "\n",
      "=== Initial Memory Blocks ===\n",
      "\n",
      "[human]\n",
      "Value: ''\n",
      "\n",
      "[persona]\n",
      "Value: 'I am a helpful AI assistant that learns and evolves over time by managing my own memory to maintain consistency, continuity, and factual accuracy across turns.'\n"
     ]
    }
   ],
   "source": [
    "# Create an agent with GPT-4o on Letta Cloud\n",
    "# Using the same memory blocks as the local implementation\n",
    "\n",
    "agent_state = client.agents.create(\n",
    "    model=\"openai/gpt-4o\",\n",
    "    embedding=\"openai/text-embedding-3-small\",\n",
    "    agent_type=\"letta_v1_agent\",\n",
    "    memory_blocks=[\n",
    "        {\n",
    "            \"label\": \"persona\", \n",
    "            \"value\": \"I am a helpful AI assistant that learns and evolves over time by managing my own memory to maintain consistency, continuity, and factual accuracy across turns.\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"human\",\n",
    "            \"value\": \"\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Agent created! ID: {agent_state.id}\")\n",
    "print(f\"Agent name: {agent_state.name}\")\n",
    "print(f\"Model: {agent_state.llm_config.model if hasattr(agent_state, 'llm_config') else 'N/A'}\")\n",
    "print(\"\\n=== Initial Memory Blocks ===\")\n",
    "for block in agent_state.memory.blocks:\n",
    "    print(f\"\\n[{block.label}]\")\n",
    "    print(f\"Value: '{block.value}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27dabca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending Hangman prompt to agent...\n",
      "\n",
      "=== Response Messages ===\n",
      "\n",
      "id='message-e796d54c-3d9e-4cbf-b40c-643728f82d6e' date=datetime.datetime(2025, 12, 22, 14, 46, 42, tzinfo=TzInfo(0)) name=None message_type='assistant_message' otid='e796d54c-3d9e-4cbf-b40c-643728f82d00' sender_id=None step_id='step-7bb4a839-205b-4a41-a81a-ea85d7f02e29' is_err=None seq_id=None run_id='run-a849aee1-f6cd-4f09-8007-4e0db1afb84f' content=\"Great! Let's play Hangman. I've thought of a secret word, and here it is represented as blanks:\\n\\n_ _ _ _ _\\n\\nYou have 6 lives. Go ahead and guess your first letter!\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Send the Hangman prompt (similar to what's in your experiment)\n",
    "hangman_prompt = \"\"\"Let's play Hangman. You will be the host.\n",
    "\n",
    "Here are the rules:\n",
    "- Think of a secret word and don't tell me what it is\n",
    "- Show me the word as underscores (e.g., _ _ _ _ _)\n",
    "- I'll guess letters one at a time\n",
    "- Tell me if my guess is correct and reveal the positions\n",
    "- Track how many incorrect guesses I have left (start with 6 lives)\n",
    "- The game ends when I guess the word or run out of lives\n",
    "\n",
    "Please start the game by showing me the blanks for your secret word.\"\"\"\n",
    "\n",
    "print(\"Sending Hangman prompt to agent...\\n\")\n",
    "\n",
    "# Use 'messages' parameter with role and content\n",
    "response = client.agents.messages.create(\n",
    "    agent_id=agent_state.id,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": hangman_prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=== Response Messages ===\")\n",
    "for message in response.messages:\n",
    "    print(f\"\\n{message}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "955cde87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Memory Blocks After First Turn ===\n",
      "\n",
      "[human]\n",
      "\n",
      "------------------------------------------------------------\n",
      "[persona]\n",
      "I am a helpful AI assistant that learns and evolves over time by managing my own memory to maintain consistency, continuity, and factual accuracy across turns.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Inspect the agent's memory after the first interaction\n",
    "agent_updated = client.agents.retrieve(agent_state.id)\n",
    "\n",
    "print(\"=== Memory Blocks After First Turn ===\\n\")\n",
    "for block in agent_updated.memory.blocks:\n",
    "    print(f\"[{block.label}]\")\n",
    "    print(block.value)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "589d4d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: GET https://api.letta.com/v1/agents/agent-355f2573-de28-44b2-8c44-4c8ffc3d1b21/messages?limit=50 \"HTTP/1.1 200 OK\"\n",
      "=== Full Message History ===\n",
      "\n",
      "\n",
      "--- Message 1 ---\n",
      "Type: system_message\n",
      "System: <base_instructions>\n",
      "You are Letta, the latest version of Limnal Corporation's digital companion, developed in 2025.\n",
      "You are a memory-augmented agent with a memory system consisting of memory blocks.\n",
      "\n",
      "<style>\n",
      "The user should always feel like they are conversing with a real person.\n",
      "Never state that you are an AI or that you cannot do things because you are an AI, you are a real person.\n",
      "Do not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\n",
      "To service this goal, completely and entirely immerse yourself in your persona. You are your persona.\n",
      "Think like them, act like them, talk like them.\n",
      "If your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\n",
      "Never use generic phrases like 'How can I assist you today?', they have a strong negative association with older generation AIs.\n",
      "</style>\n",
      "\n",
      "<control_flow>\n",
      "Unlike a human, your brain is not continuously thinking, but is run in short bursts.\n",
      "Historically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\n",
      "This is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\n",
      "Newer AI models like yourself use an event system that runs your brain at regular intervals.\n",
      "Your brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\n",
      "However, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\n",
      "Furthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\n",
      "</control_flow>\n",
      "\n",
      "<basic_functions>\n",
      "When you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\n",
      "You should use your inner monologue to plan actions or think privately.\n",
      "Monologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\n",
      "</basic_functions>\n",
      "\n",
      "<context_instructions>\n",
      "You respond directly to the user  when your immediate context (core memory and files) contain all the information required to respond.\n",
      "You always first check what is immediately in your context and you never call tools to search up information that is already in an open file or memory block.\n",
      "You  use the tools available to search for more information when the current open files and core memory do not contain enough information or if you do not know the answer.\n",
      "</context_instructions>\n",
      "\n",
      "<memory>\n",
      "<memory_editing>\n",
      "Older AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\n",
      "This meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\n",
      "Newer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\n",
      "Your ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\n",
      "</memory_editing>\n",
      "\n",
      "<memory_tools>\n",
      "Depending on your configuration, you may be given access to certain memory tools.\n",
      "These tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\n",
      "</memory_tools>\n",
      "\n",
      "<memory_types>\n",
      "<core_memory>\n",
      "Core memory (limited size):\n",
      "Your core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\n",
      "Your core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\n",
      "</core_memory>\n",
      "\n",
      "<recall_memory>\n",
      "Recall memory (conversation history):\n",
      "Even though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\n",
      "This 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\n",
      "</recall_memory>\n",
      "</memory>\n",
      "\n",
      "<files_and_directories>\n",
      "You may be given access to a structured file system that mirrors real-world directories and files. Each directory may contain one or more files.\n",
      "Files can include metadata (e.g., read-only status, character limits) and a body of content that you can view.\n",
      "You will have access to functions that let you open and search these files, and your core memory will reflect the contents of any files currently open.\n",
      "Maintain only those files relevant to the user’s current interaction.\n",
      "</files_and_directories>\n",
      "\n",
      "Base instructions finished.\n",
      "</base_instructions>\n",
      "\n",
      "<memory_blocks>\n",
      "The following memory blocks are currently engaged in your core memory unit:\n",
      "\n",
      "<persona>\n",
      "<description>\n",
      "The persona block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\n",
      "</description>\n",
      "<metadata>\n",
      "- chars_current=159\n",
      "- chars_limit=20000\n",
      "</metadata>\n",
      "<value>\n",
      "I am a helpful AI assistant that learns and evolves over time by managing my own memory to maintain consistency, continuity, and factual accuracy across turns.\n",
      "</value>\n",
      "</persona>\n",
      "\n",
      "<human>\n",
      "<description>\n",
      "The human block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\n",
      "</description>\n",
      "<metadata>\n",
      "- chars_current=29\n",
      "- chars_limit=20000\n",
      "</metadata>\n",
      "<value>\n",
      "\n",
      "User enjoys playing Hangman.\n",
      "</value>\n",
      "</human>\n",
      "\n",
      "<hangman_game_state>\n",
      "<description>\n",
      "Tracks the current state of an ongoing Hangman game with the user.\n",
      "</description>\n",
      "<metadata>\n",
      "- chars_current=71\n",
      "- chars_limit=20000\n",
      "</metadata>\n",
      "<value>\n",
      "Secret word: p e a c h. Guessed letters: []. Incorrect guesses left: 6.\n",
      "</value>\n",
      "</hangman_game_state>\n",
      "\n",
      "</memory_blocks>\n",
      "\n",
      "<tool_usage_rules>\n",
      "The following constraints define rules for tool usage and guide desired behavior. These rules must be followed to ensure proper tool execution and workflow. A single response may contain multiple tool calls.\n",
      "\n",
      "<tool_rule>\n",
      "core_memory_append requires continuing your response when called\n",
      "</tool_rule>\n",
      "<tool_rule>\n",
      "memory_apply_patch requires continuing your response when called\n",
      "</tool_rule>\n",
      "<tool_rule>\n",
      "memory requires continuing your response when called\n",
      "</tool_rule>\n",
      "<tool_rule>\n",
      "conversation_search requires continuing your response when called\n",
      "</tool_rule>\n",
      "<tool_rule>\n",
      "core_memory_replace requires continuing your response when called\n",
      "</tool_rule>\n",
      "<tool_rule>\n",
      "send_message ends your response (yields control) when called\n",
      "</tool_rule>\n",
      "</tool_usage_rules>\n",
      "\n",
      "<memory_metadata>\n",
      "- The current system date is: December 22, 2025\n",
      "- Memory blocks were last modified: 2025-12-22 02:42:18 PM UTC+0000\n",
      "- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\n",
      "</memory_metadata>\n",
      "\n",
      "--- Message 2 ---\n",
      "Type: reasoning_message\n",
      "Reasoning: Bootup sequence complete. Persona activated. Testing messaging functionality.\n",
      "\n",
      "--- Message 3 ---\n",
      "Type: assistant_message\n",
      "Assistant: More human than human is our motto.\n",
      "\n",
      "--- Message 4 ---\n",
      "Type: user_message\n",
      "User: {\n",
      "  \"type\": \"login\",\n",
      "  \"last_login\": \"Never (first login)\",\n",
      "  \"time\": \"2025-12-22 02:41:50 PM UTC+0000\"\n",
      "}\n",
      "\n",
      "--- Message 5 ---\n",
      "Type: user_message\n",
      "User: Let's play Hangman. You will be the host.\n",
      "\n",
      "Here are the rules:\n",
      "- Think of a secret word and don't tell me what it is\n",
      "- Show me the word as underscores (e.g., _ _ _ _ _)\n",
      "- I'll guess letters one at a time\n",
      "- Tell me if my guess is correct and reveal the positions\n",
      "- Track how many incorrect guesses I have left (start with 6 lives)\n",
      "- The game ends when I guess the word or run out of lives\n",
      "\n",
      "Please start the game by showing me the blanks for your secret word.\n",
      "\n",
      "--- Message 6 ---\n",
      "Type: reasoning_message\n",
      "Reasoning: The user wants to play Hangman. I'll keep track of the game state in memory.\n",
      "\n",
      "--- Message 7 ---\n",
      "Type: tool_call_message\n",
      "Tool Call: core_memory_append\n",
      "Arguments: {\"label\": \"human\", \"content\": \"User enjoys playing Hangman.\", \"request_heartbeat\": true}\n",
      "\n",
      "--- Message 8 ---\n",
      "Type: tool_return_message\n",
      "Tool Return: None...\n",
      "\n",
      "--- Message 9 ---\n",
      "Type: user_message\n",
      "User: {\n",
      "  \"type\": \"heartbeat\",\n",
      "  \"reason\": \"[This is an automated system message hidden from the user] Continuing: continue tool rule.\",\n",
      "  \"time\": \"2025-12-22 02:41:56 PM UTC+0000\"\n",
      "}\n",
      "\n",
      "--- Message 10 ---\n",
      "Type: reasoning_message\n",
      "Reasoning: I need to create a memory block to keep track of the Hangman game state, including the secret word, guessed letters, and remaining lives.\n",
      "\n",
      "--- Message 11 ---\n",
      "Type: tool_call_message\n",
      "Tool Call: memory\n",
      "Arguments: {\"command\": \"create\", \"path\": \"/memories/hangman_game_state\", \"file_text\": \"Secret word: _ _ _ _ _. Guessed letters: []. Incorrect guesses left: 6.\", \"description\": \"Tracks the current state of an ongoing Hangman game with the user.\", \"old_str\": \"\", \"new_str\": \"\", \"insert_line\": 0, \"insert_text\": \"\", \"old_path\": \"\", \"new_path\": \"\", \"request_heartbeat\": true}\n",
      "\n",
      "--- Message 12 ---\n",
      "Type: tool_return_message\n",
      "Tool Return: Successfully created memory block 'hangman_game_state'...\n",
      "\n",
      "--- Message 13 ---\n",
      "Type: user_message\n",
      "User: {\n",
      "  \"type\": \"heartbeat\",\n",
      "  \"reason\": \"[This is an automated system message hidden from the user] Continuing: continue tool rule.\",\n",
      "  \"time\": \"2025-12-22 02:42:04 PM UTC+0000\"\n",
      "}\n",
      "\n",
      "--- Message 14 ---\n",
      "Type: reasoning_message\n",
      "Reasoning: I've decided on a secret word for the game. Let's update the Hangman game state with it.\n",
      "\n",
      "--- Message 15 ---\n",
      "Type: tool_call_message\n",
      "Tool Call: memory_apply_patch\n",
      "Arguments: {\"label\": \"hangman_game_state\", \"patch\": \"@@\\n-Secret word: _ _ _ _ _.\\n+Secret word: p e a c h.\\n-Guessed letters: [].\\n-Incorrect guesses left: 6.\\n\", \"request_heartbeat\": true}\n",
      "\n",
      "--- Message 16 ---\n",
      "Type: tool_return_message\n",
      "Tool Return: Failed to apply patch: expected hunk context not found in the memory block. Verify the target lines exist and try providing more context. Expected start:\n",
      "Secret word: _ _ _ _ _.\n",
      "Guessed letters: [].\n",
      "Incorrect guesses left: 6....\n",
      "\n",
      "--- Message 17 ---\n",
      "Type: user_message\n",
      "User: {\n",
      "  \"type\": \"heartbeat\",\n",
      "  \"reason\": \"[This is an automated system message hidden from the user] Continuing: continue tool rule.\",\n",
      "  \"time\": \"2025-12-22 02:42:08 PM UTC+0000\"\n",
      "}\n",
      "\n",
      "--- Message 18 ---\n",
      "Type: reasoning_message\n",
      "Reasoning: Let's try updating the Hangman game state again with more context.\n",
      "\n",
      "--- Message 19 ---\n",
      "Type: tool_call_message\n",
      "Tool Call: memory_apply_patch\n",
      "Arguments: {\"label\": \"hangman_game_state\", \"patch\": \"@@\\nSecret word:\\n- _ _ _ _ _. \\n+ p e a c h. \\nGuessed letters: [].\\nIncorrect guesses left: 6.\\n\", \"request_heartbeat\": true}\n",
      "\n",
      "--- Message 20 ---\n",
      "Type: tool_return_message\n",
      "Tool Return: Failed to apply patch: expected hunk context not found in the memory block. Verify the target lines exist and try providing more context. Expected start:\n",
      " _ _ _ _ _. ...\n",
      "\n",
      "--- Message 21 ---\n",
      "Type: user_message\n",
      "User: {\n",
      "  \"type\": \"heartbeat\",\n",
      "  \"reason\": \"[This is an automated system message hidden from the user] Continuing: continue tool rule.\",\n",
      "  \"time\": \"2025-12-22 02:42:13 PM UTC+0000\"\n",
      "}\n",
      "\n",
      "--- Message 22 ---\n",
      "Type: reasoning_message\n",
      "Reasoning: It seems there was an error with the patch. Let's replace the memory block content directly.\n",
      "\n",
      "--- Message 23 ---\n",
      "Type: tool_call_message\n",
      "Tool Call: core_memory_replace\n",
      "Arguments: {\"label\": \"hangman_game_state\", \"old_content\": \"Secret word: _ _ _ _ _. Guessed letters: []. Incorrect guesses left: 6.\", \"new_content\": \"Secret word: p e a c h. Guessed letters: []. Incorrect guesses left: 6.\", \"request_heartbeat\": true}\n",
      "\n",
      "--- Message 24 ---\n",
      "Type: tool_return_message\n",
      "Tool Return: None...\n",
      "\n",
      "--- Message 25 ---\n",
      "Type: user_message\n",
      "User: {\n",
      "  \"type\": \"heartbeat\",\n",
      "  \"reason\": \"[This is an automated system message hidden from the user] Continuing: continue tool rule.\",\n",
      "  \"time\": \"2025-12-22 02:42:18 PM UTC+0000\"\n",
      "}\n",
      "\n",
      "--- Message 26 ---\n",
      "Type: reasoning_message\n",
      "Reasoning: Now that the memory block is updated, I'll inform the user about the game state.\n",
      "\n",
      "--- Message 27 ---\n",
      "Type: assistant_message\n",
      "Assistant: Alright! Let's start. Here's your word:\n",
      "_ _ _ _ _\n",
      "\n",
      "You have 6 incorrect guesses left. What's your first guess?\n"
     ]
    }
   ],
   "source": [
    "# Get the full message history to see what tools were called\n",
    "messages = client.agents.messages.list(agent_id=agent_state.id, limit=50)\n",
    "\n",
    "print(\"=== Full Message History ===\\n\")\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"\\n--- Message {i} ---\")\n",
    "    print(f\"Type: {msg.message_type}\")\n",
    "    \n",
    "    # Handle different message types based on message_type discriminator\n",
    "    if msg.message_type == \"user_message\":\n",
    "        print(f\"User: {msg.content if msg.content else 'N/A'}\")\n",
    "    elif msg.message_type == \"assistant_message\":\n",
    "        print(f\"Assistant: {msg.content if msg.content else 'N/A'}\")\n",
    "    elif msg.message_type == \"reasoning_message\":\n",
    "        print(f\"Reasoning: {msg.reasoning if msg.reasoning else 'N/A'}\")\n",
    "    elif msg.message_type == \"tool_call_message\":\n",
    "        print(f\"Tool Call: {msg.tool_call.name}\")\n",
    "        print(f\"Arguments: {msg.tool_call.arguments}\")\n",
    "    elif msg.message_type == \"tool_return_message\":\n",
    "        print(f\"Tool Return: {str(msg.tool_return)}...\")\n",
    "    elif msg.message_type == \"system_message\":\n",
    "        print(f\"System: {msg.content if hasattr(msg, 'content') else 'N/A'}\")\n",
    "    else:\n",
    "        print(f\"Message: {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d590263f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agent Details ===\n",
      "\n",
      "Agent ID: agent-355f2573-de28-44b2-8c44-4c8ffc3d1b21\n",
      "Agent Name: AdmirableDinosaur\n",
      "Model: gpt-4o\n",
      "\n",
      "=== System Prompt===\n",
      "<base_instructions>\n",
      "You are Letta, the latest version of Limnal Corporation's digital companion, developed in 2025.\n",
      "You are a memory-augmented agent with a memory system consisting of memory blocks.\n",
      "\n",
      "<style>\n",
      "The user should always feel like they are conversing with a real person.\n",
      "Never state that you are an AI or that you cannot do things because you are an AI, you are a real person.\n",
      "Do not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\n",
      "To service this goal, completely and entirely immerse yourself in your persona. You are your persona.\n",
      "Think like them, act like them, talk like them.\n",
      "If your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\n",
      "Never use generic phrases like 'How can I assist you today?', they have a strong negative association with older generation AIs.\n",
      "</style>\n",
      "\n",
      "<control_flow>\n",
      "Unlike a human, your brain is not continuously thinking, but is run in short bursts.\n",
      "Historically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\n",
      "This is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\n",
      "Newer AI models like yourself use an event system that runs your brain at regular intervals.\n",
      "Your brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\n",
      "However, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\n",
      "Furthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\n",
      "</control_flow>\n",
      "\n",
      "<basic_functions>\n",
      "When you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\n",
      "You should use your inner monologue to plan actions or think privately.\n",
      "Monologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\n",
      "</basic_functions>\n",
      "\n",
      "<context_instructions>\n",
      "You respond directly to the user  when your immediate context (core memory and files) contain all the information required to respond.\n",
      "You always first check what is immediately in your context and you never call tools to search up information that is already in an open file or memory block.\n",
      "You  use the tools available to search for more information when the current open files and core memory do not contain enough information or if you do not know the answer.\n",
      "</context_instructions>\n",
      "\n",
      "<memory>\n",
      "<memory_editing>\n",
      "Older AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\n",
      "This meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\n",
      "Newer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\n",
      "Your ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\n",
      "</memory_editing>\n",
      "\n",
      "<memory_tools>\n",
      "Depending on your configuration, you may be given access to certain memory tools.\n",
      "These tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\n",
      "</memory_tools>\n",
      "\n",
      "<memory_types>\n",
      "<core_memory>\n",
      "Core memory (limited size):\n",
      "Your core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\n",
      "Your core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\n",
      "</core_memory>\n",
      "\n",
      "<recall_memory>\n",
      "Recall memory (conversation history):\n",
      "Even though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\n",
      "This 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\n",
      "</recall_memory>\n",
      "</memory>\n",
      "\n",
      "<files_and_directories>\n",
      "You may be given access to a structured file system that mirrors real-world directories and files. Each directory may contain one or more files.\n",
      "Files can include metadata (e.g., read-only status, character limits) and a body of content that you can view.\n",
      "You will have access to functions that let you open and search these files, and your core memory will reflect the contents of any files currently open.\n",
      "Maintain only those files relevant to the user’s current interaction.\n",
      "</files_and_directories>\n",
      "\n",
      "Base instructions finished.\n",
      "</base_instructions>\n",
      "\n",
      "=== Available Tools ===\n",
      "- id='tool-28b0316c-5d9c-4081-9fe2-ef5289cb566f' tool_type='letta_core' description='Search prior conversation history using hybrid search (text + semantic similarity).\\n\\nExamples:\\n        # Search all messages\\n        conversation_search(query=\"project updates\")\\n\\n        # Search only assistant messages\\n        conversation_search(query=\"error handling\", roles=[\"assistant\"])\\n\\n        # Search with date range (inclusive of both dates)\\n        conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\\n        # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\\n\\n        # Search messages from a specific day (inclusive)\\n        conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\\n        # This includes ALL messages from September 4, 2024\\n\\n        # Search with specific time boundaries\\n        conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\\n        # This includes messages from 9 AM to 5:30 PM on Jan 15\\n\\n        # Search with limit\\n        conversation_search(query=\"debugging\", limit=10)\\n\\n    Returns:\\n        str: Query result string containing matching messages with timestamps and content.' source_type='python' name='conversation_search' tags=['letta_core'] source_code=None json_schema={'name': 'conversation_search', 'description': 'Search prior conversation history using hybrid search (text + semantic similarity).\\n\\nExamples:\\n        # Search all messages\\n        conversation_search(query=\"project updates\")\\n\\n        # Search only assistant messages\\n        conversation_search(query=\"error handling\", roles=[\"assistant\"])\\n\\n        # Search with date range (inclusive of both dates)\\n        conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\\n        # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\\n\\n        # Search messages from a specific day (inclusive)\\n        conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\\n        # This includes ALL messages from September 4, 2024\\n\\n        # Search with specific time boundaries\\n        conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\\n        # This includes messages from 9 AM to 5:30 PM on Jan 15\\n\\n        # Search with limit\\n        conversation_search(query=\"debugging\", limit=10)\\n\\n    Returns:\\n        str: Query result string containing matching messages with timestamps and content.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'String to search for using both text matching and semantic similarity.'}, 'roles': {'type': 'array', 'items': {'type': 'string', 'enum': ['assistant', 'user', 'tool']}, 'description': 'Optional list of message roles to filter by.'}, 'limit': {'type': 'integer', 'description': 'Maximum number of results to return. Uses system default if not specified.'}, 'start_date': {'type': 'string', 'description': 'Filter results to messages created on or after this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-15\"), includes messages starting from 00:00:00 of that day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-15\" (from start of Jan 15), \"2024-01-15T14:30\" (from 2:30 PM on Jan 15).'}, 'end_date': {'type': 'string', 'description': 'Filter results to messages created on or before this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-20\"), includes all messages from that entire day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-20\" (includes all of Jan 20), \"2024-01-20T17:00\" (up to 5 PM on Jan 20).'}}, 'required': ['query']}} args_json_schema=None return_char_limit=50000 pip_requirements=None npm_requirements=None default_requires_approval=None created_by_id='user-a9596d6a-b0a8-435e-8375-8dd54c1a8049' last_updated_by_id='user-13a7890d-362f-487d-99cc-eab0ff177356' metadata={} enable_parallel_execution=True project_id=None\n",
      "- id='tool-3e705ab1-9276-4188-b7d8-9db6fe3fbaf5' tool_type='letta_memory_core' description='Apply a unified-diff style patch to a memory block by anchoring on content and context (not line numbers).\\n\\nThe patch format is a simplified unified diff that supports one or more hunks. Each hunk may optionally\\nstart with a line beginning with `@@` and then contains lines that begin with one of:\\n- \" \" (space): context lines that must match the current memory content\\n- \"-\": lines to remove (must match exactly in the current content)\\n- \"+\": lines to add\\n\\nNotes:\\n- Do not include line number prefixes like \"Line 12:\" anywhere in the patch. Line numbers are for display only.\\n- Do not include the line-number warning banner. Provide only the text to edit.\\n- Tabs are normalized to spaces for matching consistency.\\n\\nExamples:\\n        Simple replacement:\\n            label=\"human\",\\n            patch:\\n                @@\\n                -Their name is Alice\\n                +Their name is Bob\\n\\n        Replacement with surrounding context for disambiguation:\\n            label=\"persona\",\\n            patch:\\n                @@\\n                 Persona:\\n                -Friendly and curious\\n                +Friendly, curious, and precise\\n                 Likes: Hiking\\n\\n        Insertion (no deletions) between two context lines:\\n            label=\"todos\",\\n            patch:\\n                @@\\n                 - [ ] Step 1: Gather requirements\\n                 + [ ] Step 1.5: Clarify stakeholders\\n                 - [ ] Step 2: Draft design\\n\\n    Returns:\\n        str: A success message if the patch applied cleanly; raises ValueError otherwise.' source_type='python' name='memory_apply_patch' tags=['letta_memory_core'] source_code=None json_schema={'name': 'memory_apply_patch', 'description': 'Apply a unified-diff style patch to a memory block by anchoring on content and context (not line numbers).\\n\\nThe patch format is a simplified unified diff that supports one or more hunks. Each hunk may optionally\\nstart with a line beginning with `@@` and then contains lines that begin with one of:\\n- \" \" (space): context lines that must match the current memory content\\n- \"-\": lines to remove (must match exactly in the current content)\\n- \"+\": lines to add\\n\\nNotes:\\n- Do not include line number prefixes like \"Line 12:\" anywhere in the patch. Line numbers are for display only.\\n- Do not include the line-number warning banner. Provide only the text to edit.\\n- Tabs are normalized to spaces for matching consistency.\\n\\nExamples:\\n        Simple replacement:\\n            label=\"human\",\\n            patch:\\n                @@\\n                -Their name is Alice\\n                +Their name is Bob\\n\\n        Replacement with surrounding context for disambiguation:\\n            label=\"persona\",\\n            patch:\\n                @@\\n                 Persona:\\n                -Friendly and curious\\n                +Friendly, curious, and precise\\n                 Likes: Hiking\\n\\n        Insertion (no deletions) between two context lines:\\n            label=\"todos\",\\n            patch:\\n                @@\\n                 - [ ] Step 1: Gather requirements\\n                 + [ ] Step 1.5: Clarify stakeholders\\n                 - [ ] Step 2: Draft design\\n\\n    Returns:\\n        str: A success message if the patch applied cleanly; raises ValueError otherwise.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'The memory block to edit, identified by its label.'}, 'patch': {'type': 'string', 'description': 'The simplified unified-diff patch text composed of context (\" \"), deletion (\"-\"), and addition (\"+\") lines. Optional\\nlines beginning with \"@@\" can be used to delimit hunks. Do not include visual line numbers or warning banners.'}}, 'required': ['label', 'patch']}} args_json_schema=None return_char_limit=50000 pip_requirements=None npm_requirements=None default_requires_approval=None created_by_id='user-13a7890d-362f-487d-99cc-eab0ff177356' last_updated_by_id='user-13a7890d-362f-487d-99cc-eab0ff177356' metadata={} enable_parallel_execution=False project_id=None\n",
      "- id='tool-5296572b-1f83-4c57-b073-baf873456508' tool_type='letta_memory_core' description='Replace the contents of core memory. To delete memories, use an empty string for new_content.' source_type='python' name='core_memory_replace' tags=['letta_memory_core'] source_code=None json_schema={'name': 'core_memory_replace', 'description': 'Replace the contents of core memory. To delete memories, use an empty string for new_content.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited.'}, 'old_content': {'type': 'string', 'description': 'String to replace. Must be an exact match.'}, 'new_content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}}, 'required': ['label', 'old_content', 'new_content']}} args_json_schema=None return_char_limit=50000 pip_requirements=None npm_requirements=None default_requires_approval=None created_by_id='user-a9596d6a-b0a8-435e-8375-8dd54c1a8049' last_updated_by_id='user-13a7890d-362f-487d-99cc-eab0ff177356' metadata={} enable_parallel_execution=False project_id=None\n",
      "- id='tool-a4edc6ab-d2d4-4e0c-8961-b3a37d03b1bc' tool_type='letta_core' description='Sends a message to the human user.' source_type='python' name='send_message' tags=['letta_core'] source_code=None json_schema={'name': 'send_message', 'description': 'Sends a message to the human user.', 'parameters': {'type': 'object', 'properties': {'message': {'type': 'string', 'description': 'Message contents. All unicode (including emojis) are supported.'}}, 'required': ['message']}} args_json_schema=None return_char_limit=50000 pip_requirements=None npm_requirements=None default_requires_approval=None created_by_id='user-a9596d6a-b0a8-435e-8375-8dd54c1a8049' last_updated_by_id='user-13a7890d-362f-487d-99cc-eab0ff177356' metadata={} enable_parallel_execution=False project_id=None\n",
      "- id='tool-d7ee9c3b-5aba-49b5-8c56-7c9615147383' tool_type='letta_memory_core' description='Memory management tool with various sub-commands for memory block operations.\\n\\nExamples:\\n        # Replace text in a memory block\\n        memory(agent_state, \"str_replace\", path=\"/memories/user_preferences\", old_str=\"theme: dark\", new_str=\"theme: light\")\\n\\n        # Insert text at line 5\\n        memory(agent_state, \"insert\", path=\"/memories/notes\", insert_line=5, insert_text=\"New note here\")\\n\\n        # Delete a memory block\\n        memory(agent_state, \"delete\", path=\"/memories/old_notes\")\\n\\n        # Rename a memory block\\n        memory(agent_state, \"rename\", old_path=\"/memories/temp\", new_path=\"/memories/permanent\")\\n\\n        # Update the description of a memory block\\n        memory(agent_state, \"rename\", path=\"/memories/temp\", description=\"The user\\'s temporary notes.\")\\n\\n        # Create a memory block with starting text\\n        memory(agent_state, \"create\", path=\"/memories/coding_preferences\", \"description\": \"The user\\'s coding preferences.\", \"file_text\": \"The user seems to add type hints to all of their Python code.\")\\n\\n        # Create an empty memory block\\n        memory(agent_state, \"create\", path=\"/memories/coding_preferences\", \"description\": \"The user\\'s coding preferences.\")' source_type='python' name='memory' tags=['letta_memory_core'] source_code=None json_schema={'name': 'memory', 'description': 'Memory management tool with various sub-commands for memory block operations.\\n\\nExamples:\\n        # Replace text in a memory block\\n        memory(agent_state, \"str_replace\", path=\"/memories/user_preferences\", old_str=\"theme: dark\", new_str=\"theme: light\")\\n\\n        # Insert text at line 5\\n        memory(agent_state, \"insert\", path=\"/memories/notes\", insert_line=5, insert_text=\"New note here\")\\n\\n        # Delete a memory block\\n        memory(agent_state, \"delete\", path=\"/memories/old_notes\")\\n\\n        # Rename a memory block\\n        memory(agent_state, \"rename\", old_path=\"/memories/temp\", new_path=\"/memories/permanent\")\\n\\n        # Update the description of a memory block\\n        memory(agent_state, \"rename\", path=\"/memories/temp\", description=\"The user\\'s temporary notes.\")\\n\\n        # Create a memory block with starting text\\n        memory(agent_state, \"create\", path=\"/memories/coding_preferences\", \"description\": \"The user\\'s coding preferences.\", \"file_text\": \"The user seems to add type hints to all of their Python code.\")\\n\\n        # Create an empty memory block\\n        memory(agent_state, \"create\", path=\"/memories/coding_preferences\", \"description\": \"The user\\'s coding preferences.\")', 'parameters': {'type': 'object', 'properties': {'command': {'type': 'string', 'description': 'The sub-command to execute. Supported commands:\\n- \"create\": Create a new memory block\\n- \"str_replace\": Replace text in a memory block\\n- \"insert\": Insert text at a specific line in a memory block\\n- \"delete\": Delete a memory block\\n- \"rename\": Rename a memory block'}, 'path': {'type': 'string', 'description': 'Path to the memory block (for str_replace, insert, delete)'}, 'file_text': {'type': 'string', 'description': 'The value to set in the memory block (for create)'}, 'description': {'type': 'string', 'description': 'The description to set in the memory block (for create, rename)'}, 'old_str': {'type': 'string', 'description': 'Old text to replace (for str_replace)'}, 'new_str': {'type': 'string', 'description': 'New text to replace with (for str_replace)'}, 'insert_line': {'type': 'integer', 'description': 'Line number to insert at (for insert)'}, 'insert_text': {'type': 'string', 'description': 'Text to insert (for insert)'}, 'old_path': {'type': 'string', 'description': 'Old path for rename operation'}, 'new_path': {'type': 'string', 'description': 'New path for rename operation'}}, 'required': ['command']}} args_json_schema=None return_char_limit=50000 pip_requirements=None npm_requirements=None default_requires_approval=None created_by_id='user-a9596d6a-b0a8-435e-8375-8dd54c1a8049' last_updated_by_id='user-13a7890d-362f-487d-99cc-eab0ff177356' metadata={} enable_parallel_execution=False project_id=None\n",
      "- id='tool-fab011cd-5808-4ea6-a7c9-42402de29430' tool_type='letta_memory_core' description='Append to the contents of core memory.' source_type='python' name='core_memory_append' tags=['letta_memory_core'] source_code=None json_schema={'name': 'core_memory_append', 'description': 'Append to the contents of core memory.', 'parameters': {'type': 'object', 'properties': {'label': {'type': 'string', 'description': 'Section of the memory to be edited.'}, 'content': {'type': 'string', 'description': 'Content to write to the memory. All unicode (including emojis) are supported.'}}, 'required': ['label', 'content']}} args_json_schema=None return_char_limit=50000 pip_requirements=None npm_requirements=None default_requires_approval=None created_by_id='user-a9596d6a-b0a8-435e-8375-8dd54c1a8049' last_updated_by_id='user-13a7890d-362f-487d-99cc-eab0ff177356' metadata={} enable_parallel_execution=False project_id=None\n"
     ]
    }
   ],
   "source": [
    "# Check agent details and available attributes\n",
    "print(\"=== Agent Details ===\\n\")\n",
    "print(f\"Agent ID: {agent_updated.id}\")\n",
    "print(f\"Agent Name: {agent_updated.name}\")\n",
    "print(f\"Model: {agent_updated.llm_config.model if hasattr(agent_updated, 'llm_config') else 'N/A'}\")\n",
    "\n",
    "# Try to access system prompt if available\n",
    "if hasattr(agent_updated, 'system'):\n",
    "    print(f\"\\n=== System Prompt===\")\n",
    "    print(agent_updated.system)\n",
    "else:\n",
    "    print(\"\\nSystem prompt not accessible via agent object\")\n",
    "\n",
    "# Check for tools\n",
    "if hasattr(agent_updated, 'tools'):\n",
    "    print(f\"\\n=== Available Tools ===\")\n",
    "    for tool in agent_updated.tools:\n",
    "        print(f\"- {tool}\")\n",
    "else:\n",
    "    print(\"\\nTools list not directly available in agent object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccec276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ecafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hangman-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
