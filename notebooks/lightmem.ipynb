{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3daace55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_compressor:llmlingua-2\n",
      "pre_compressor:llmlingua_config={'model_name': 'microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank', 'device_map': 'cuda', 'use_llmlingua2': True} llmlingua2_config={'max_batch_size': 50, 'max_force_token': 100} compress_config={'instruction': '', 'rate': 0.8, 'target_token': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:14 - LightMemory - INFO - Initializing LightMemory with provided configuration\n",
      "2025-11-17 11:27:14 - LightMemory - INFO - Initializing pre-compressor\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "2025-11-17 11:27:36 - LightMemory - INFO - Initializing topic segmenter\n",
      "2025-11-17 11:27:36 - LightMemory - INFO - Initializing memory manager\n",
      "2025-11-17 11:27:37 - LightMemory - INFO - Initializing text embedder\n",
      "2025-11-17 11:27:38 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2025-11-17 11:27:39 - LightMemory - INFO - Initializing embedding retriever\n",
      "2025-11-17 11:27:39 - LightMemory - INFO - LightMemory initialization completed successfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Start at root directory or anywhere\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "from lightmem.memory.lightmem import LightMemory\n",
    "\n",
    "LOGS_ROOT = \"./logs\"\n",
    "RUN_TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_LOG_DIR = os.path.join(LOGS_ROOT, RUN_TIMESTAMP)\n",
    "os.makedirs(RUN_LOG_DIR, exist_ok=True)\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/home/mila/b/baldelld/scratch/\"\n",
    "os.environ[\"OPENROUTER_API_BASE\"] = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "load_dotenv()\n",
    "# CRITICAL: Remove OPENROUTER_API_KEY to avoid the buggy branch\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if \"OPENROUTER_API_KEY\" in os.environ:\n",
    "    del os.environ[\"OPENROUTER_API_KEY\"]\n",
    "\n",
    "# Now set OPENAI keys instead\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# Rest of your code...\n",
    "os.environ[\"HF_HOME\"] = \"/home/mila/b/baldelld/scratch/\"\n",
    "\n",
    "API_KEY = api_key  # Use the saved key\n",
    "API_BASE_URL = 'https://openrouter.ai/api/v1'\n",
    "LLM_MODEL = 'openai/gpt-oss-20b'\n",
    "EMBEDDING_MODEL_PATH='sentence-transformers/all-MiniLM-L6-v2'\n",
    "LLMLINGUA_MODEL_PATH='microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank'\n",
    "\n",
    "config_dict = {\n",
    "    \"pre_compress\": True,\n",
    "    \"pre_compressor\": {\n",
    "        \"model_name\": \"llmlingua-2\",\n",
    "        \"configs\": {\n",
    "            \"llmlingua_config\": {\n",
    "                \"model_name\": LLMLINGUA_MODEL_PATH,\n",
    "                \"device_map\": \"cuda\",\n",
    "                \"use_llmlingua2\": True,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"topic_segment\": True,\n",
    "    \"precomp_topic_shared\": True,\n",
    "    \"topic_segmenter\": {\n",
    "        \"model_name\": \"llmlingua-2\",\n",
    "    },\n",
    "    \"messages_use\": \"user_only\",\n",
    "    \"metadata_generate\": True,\n",
    "    \"text_summary\": True,\n",
    "    \"memory_manager\": {\n",
    "        \"model_name\": 'openai', # such as 'openai' or 'ollama' ...\n",
    "        \"configs\": {\n",
    "            \"model\": LLM_MODEL,\n",
    "            \"api_key\": API_KEY,\n",
    "            \"max_tokens\": 16000,\n",
    "            # \"openrouter_base_url\": API_BASE_URL # API model specific, such as 'openai_base_url' or 'deepseek_base_url' ...\n",
    "        }\n",
    "    },\n",
    "    \"extract_threshold\": 0.1,\n",
    "    \"index_strategy\": \"embedding\",\n",
    "    \"text_embedder\": {\n",
    "        \"model_name\": \"huggingface\",\n",
    "        \"configs\": {\n",
    "            \"model\": EMBEDDING_MODEL_PATH,\n",
    "            \"embedding_dims\": 384,\n",
    "            \"model_kwargs\": {\"device\": \"cuda\"},\n",
    "        },\n",
    "    },\n",
    "    \"retrieve_strategy\": \"embedding\",\n",
    "    \"embedding_retriever\": {\n",
    "        \"model_name\": \"qdrant\",\n",
    "        \"configs\": {\n",
    "            \"collection_name\": \"my_long_term_chat\",\n",
    "            \"embedding_model_dims\": 384,\n",
    "            \"path\": \"./my_long_term_chat\", \n",
    "        }\n",
    "    },\n",
    "    \"update\": \"offline\",\n",
    "    \"logging\": {\n",
    "        \"level\": \"DEBUG\",\n",
    "        \"file_enabled\": True,\n",
    "        \"log_dir\": RUN_LOG_DIR,\n",
    "    }\n",
    "}\n",
    "\n",
    "lightmem = LightMemory.from_config(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b1b5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 10:29:29 - LightMemory - INFO - ========== START add_memory_20251117_102929_137443 ==========\n",
      "2025-11-17 10:29:29 - LightMemory - INFO - force_segment=True, force_extract=True\n",
      "2025-11-17 10:29:29 - LightMemory - INFO - [add_memory_20251117_102929_137443] Target compression rate: 0.8\n",
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "2025-11-17 10:29:29 - LightMemory - INFO - [add_memory_20251117_102929_137443] Generated 1 segments\n",
      "2025-11-17 10:29:29 - LightMemory - INFO - [add_memory_20251117_102929_137443] Extraction triggered 1 times, extract_list length: 1\n",
      "2025-11-17 10:29:29 - LightMemory - INFO - [add_memory_20251117_102929_137443] Assigned timestamps to 1 items\n",
      "2025-11-17 10:29:29 - LightMemory - INFO - [add_memory_20251117_102929_137443] Starting metadata generation\n",
      "2025-11-17 10:29:32 - LightMemory - INFO - [add_memory_20251117_102929_137443] Metadata generation completed with 1 API calls\n",
      "2025-11-17 10:29:32 - LightMemory - INFO - [add_memory_20251117_102929_137443] Extracted 1 memory entries\n",
      "2025-11-17 10:29:32 - LightMemory - INFO - [add_memory_20251117_102929_137443] Created 2 MemoryEntry objects\n",
      "2025-11-17 10:29:32 - LightMemory - INFO - ========== START offline_update_20251117_102932_437376 ==========\n",
      "2025-11-17 10:29:32 - LightMemory - INFO - [offline_update_20251117_102932_437376] Received 2 memory entries\n",
      "2025-11-17 10:29:32 - LightMemory - INFO - [offline_update_20251117_102932_437376] construct_update_queue_trigger=False, offline_update_trigger=False\n",
      "2025-11-17 10:29:32 - LightMemory - INFO - [offline_update_20251117_102932_437376] Starting embedding and insertion to vector database\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027b6ee328084a28a062a406980e7487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 10:29:32 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection my_long_term_chat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b5fcbc429841f584f8b450a699599d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 10:29:32 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection my_long_term_chat\n",
      "2025-11-17 10:29:32 - LightMemory - INFO - [offline_update_20251117_102932_437376] Successfully inserted 2 entries to vector database\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Add Memory\n",
    "session = {\n",
    "\"timestamp\": \"2025-01-10\",\n",
    "\"turns\": [\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": \"My favorite ice cream flavor is pistachio, and my dog's name is Rex.\"}, \n",
    "        {\"role\": \"assistant\", \"content\": \"Got it. Pistachio is a great choice.\"}], \n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "for turn_messages in session[\"turns\"]:\n",
    "    timestamp = session[\"timestamp\"]\n",
    "    for msg in turn_messages:\n",
    "        msg[\"time_stamp\"] = timestamp\n",
    "        \n",
    "    store_result = lightmem.add_memory(\n",
    "        messages=turn_messages,\n",
    "        force_segment=True,\n",
    "        force_extract=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d54fe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 10:29:51 - LightMemory - INFO - ========== START construct_queue_20251117_102951_861595 ==========\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [construct_queue_20251117_102951_861595] Parameters: top_k=20, keep_top_n=10, max_workers=8\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [construct_queue_20251117_102951_861595] Retrieved 2 entries from vector database\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [construct_queue_20251117_102951_861595] Starting parallel queue construction with 8 workers\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [construct_queue_20251117_102951_861595] Queue construction completed: 2 updated, 0 skipped, nonempty_queues=2, empty_queues=0\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - ========== END construct_queue_20251117_102951_861595 ==========\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - ========== START offline_update_all_20251117_102951_929253 ==========\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [offline_update_all_20251117_102951_929253] Parameters: score_threshold=0.8, max_workers=5\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [offline_update_all_20251117_102951_929253] Retrieved 2 entries from vector database\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [offline_update_all_20251117_102951_929253] Starting parallel offline update with 5 workers\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [offline_update_all_20251117_102951_929253] Offline update completed:\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [offline_update_all_20251117_102951_929253]   - Processed: 0 entries\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [offline_update_all_20251117_102951_929253]   - Updated: 0 entries\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [offline_update_all_20251117_102951_929253]   - Deleted: 0 entries\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - [offline_update_all_20251117_102951_929253]   - Skipped (no candidates): 2 entries\n",
      "2025-11-17 10:29:51 - LightMemory - INFO - ========== END offline_update_all_20251117_102951_929253 ==========\n"
     ]
    }
   ],
   "source": [
    "lightmem.construct_update_queue_all_entries()\n",
    "lightmem.offline_update_all_entries(score_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "991161cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:06:51 - LightMemory - INFO - ========== START retrieve_20251117_110651_203111 ==========\n",
      "2025-11-17 11:06:51 - LightMemory - INFO - [retrieve_20251117_110651_203111] Query: What is the name of my dog?\n",
      "2025-11-17 11:06:51 - LightMemory - INFO - [retrieve_20251117_110651_203111] Parameters: limit=5, filters=None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8917887f45fe469b8bcef129396c5e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:06:51 - LightMemory - INFO - [retrieve_20251117_110651_203111] Searching vector database\n",
      "2025-11-17 11:06:51 - LightMemory - INFO - [retrieve_20251117_110651_203111] Found 2 results\n",
      "2025-11-17 11:06:51 - LightMemory - INFO - [retrieve_20251117_110651_203111] Formatted 2 results into output string\n",
      "2025-11-17 11:06:51 - LightMemory - INFO - ========== END retrieve_20251117_110651_203111 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-10T00:00:00.000 Fri User's dog is named Rex.\n",
      "2025-01-10T00:00:00.000 Fri User's favorite ice cream flavor is pistachio.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the name of my dog?\"\n",
    "related_memories = lightmem.retrieve(question, limit=5)\n",
    "print(related_memories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def9cf3d",
   "metadata": {},
   "source": [
    "## Test Forking Logic (SCT-style branching)\n",
    "\n",
    "We'll simulate a conversation that forks:\n",
    "1. **Main conversation**: Add 3 turns about travel preferences\n",
    "2. **Fork point**: Clone memories to a branch\n",
    "3. **Branch A**: Continue with \"Paris\" hypothesis\n",
    "4. **Branch B**: Continue with \"Tokyo\" hypothesis\n",
    "5. **Verify**: Each branch has pre-fork memories + its own post-fork memories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963d347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:39 - LightMemory - INFO - Initializing LightMemory with provided configuration\n",
      "2025-11-17 11:27:39 - LightMemory - INFO - Initializing pre-compressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_compressor:llmlingua-2\n",
      "pre_compressor:llmlingua_config={'model_name': 'microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank', 'device_map': 'cuda', 'use_llmlingua2': True} llmlingua2_config={'max_batch_size': 50, 'max_force_token': 100} compress_config={'instruction': '', 'rate': 0.8, 'target_token': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:39 - LightMemory - INFO - Initializing topic segmenter\n",
      "2025-11-17 11:27:39 - LightMemory - INFO - Initializing memory manager\n",
      "2025-11-17 11:27:39 - LightMemory - INFO - Initializing text embedder\n",
      "2025-11-17 11:27:39 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2025-11-17 11:27:40 - LightMemory - INFO - Initializing embedding retriever\n",
      "2025-11-17 11:27:40 - LightMemory - INFO - LightMemory initialization completed successfully\n",
      "2025-11-17 11:27:40 - LightMemory - INFO - ========== START add_memory_20251117_112740_201190 ==========\n",
      "2025-11-17 11:27:40 - LightMemory - INFO - force_segment=True, force_extract=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MAIN CONVERSATION: Pre-fork turns\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:40 - LightMemory - INFO - [add_memory_20251117_112740_201190] Target compression rate: 0.8\n",
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "2025-11-17 11:27:40 - LightMemory - INFO - [add_memory_20251117_112740_201190] Generated 1 segments\n",
      "2025-11-17 11:27:40 - LightMemory - INFO - [add_memory_20251117_112740_201190] Extraction triggered 1 times, extract_list length: 1\n",
      "2025-11-17 11:27:40 - LightMemory - INFO - [add_memory_20251117_112740_201190] Assigned timestamps to 1 items\n",
      "2025-11-17 11:27:40 - LightMemory - INFO - [add_memory_20251117_112740_201190] Starting metadata generation\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [add_memory_20251117_112740_201190] Metadata generation completed with 1 API calls\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [add_memory_20251117_112740_201190] Extracted 1 memory entries\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [add_memory_20251117_112740_201190] Created 2 MemoryEntry objects\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - ========== START offline_update_20251117_112744_467712 ==========\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [offline_update_20251117_112744_467712] Received 2 memory entries\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [offline_update_20251117_112744_467712] construct_update_queue_trigger=False, offline_update_trigger=False\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [offline_update_20251117_112744_467712] Starting embedding and insertion to vector database\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7071c4cee1423ebc9e0f121e423ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:44 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_main\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a19a2c05cd4c0196418ee0b7d5b254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:44 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_main\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [offline_update_20251117_112744_467712] Successfully inserted 2 entries to vector database\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - ========== START add_memory_20251117_112744_576648 ==========\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - force_segment=True, force_extract=True\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [add_memory_20251117_112744_576648] Target compression rate: 0.8\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [add_memory_20251117_112744_576648] Generated 1 segments\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [add_memory_20251117_112744_576648] Extraction triggered 1 times, extract_list length: 1\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [add_memory_20251117_112744_576648] Assigned timestamps to 1 items\n",
      "2025-11-17 11:27:44 - LightMemory - INFO - [add_memory_20251117_112744_576648] Starting metadata generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added turn 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:45 - LightMemory - INFO - [add_memory_20251117_112744_576648] Metadata generation completed with 1 API calls\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [add_memory_20251117_112744_576648] Extracted 1 memory entries\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [add_memory_20251117_112744_576648] Created 1 MemoryEntry objects\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - ========== START offline_update_20251117_112745_435979 ==========\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [offline_update_20251117_112745_435979] Received 1 memory entries\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [offline_update_20251117_112745_435979] construct_update_queue_trigger=False, offline_update_trigger=False\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [offline_update_20251117_112745_435979] Starting embedding and insertion to vector database\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad45f731361e446ab518a88b8804b58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:45 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_main\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [offline_update_20251117_112745_435979] Successfully inserted 1 entries to vector database\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - ========== START add_memory_20251117_112745_452308 ==========\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - force_segment=True, force_extract=True\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [add_memory_20251117_112745_452308] Target compression rate: 0.8\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [add_memory_20251117_112745_452308] Generated 1 segments\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [add_memory_20251117_112745_452308] Extraction triggered 1 times, extract_list length: 1\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [add_memory_20251117_112745_452308] Assigned timestamps to 1 items\n",
      "2025-11-17 11:27:45 - LightMemory - INFO - [add_memory_20251117_112745_452308] Starting metadata generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added turn 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:46 - LightMemory - INFO - [add_memory_20251117_112745_452308] Metadata generation completed with 1 API calls\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - [add_memory_20251117_112745_452308] Extracted 1 memory entries\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - [add_memory_20251117_112745_452308] Created 1 MemoryEntry objects\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - ========== START offline_update_20251117_112746_625234 ==========\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - [offline_update_20251117_112746_625234] Received 1 memory entries\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - [offline_update_20251117_112746_625234] construct_update_queue_trigger=False, offline_update_trigger=False\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - [offline_update_20251117_112746_625234] Starting embedding and insertion to vector database\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d42ac3ff0042389994257706c3055e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:46 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_main\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - [offline_update_20251117_112746_625234] Successfully inserted 1 entries to vector database\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - ========== START retrieve_20251117_112746_642148 ==========\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - [retrieve_20251117_112746_642148] Query: What are my travel preferences?\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - [retrieve_20251117_112746_642148] Parameters: limit=5, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added turn 3\n",
      "\n",
      "============================================================\n",
      "RETRIEVAL at fork point:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c161dd98a2d436a9ab9c51d51b639cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:46 - LightMemory - INFO - [retrieve_20251117_112746_642148] Searching vector database\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - [retrieve_20251117_112746_642148] Found 4 results\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - [retrieve_20251117_112746_642148] Formatted 4 results into output string\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - ========== END retrieve_20251117_112746_642148 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are my travel preferences?\n",
      "Retrieved memories:\n",
      "2025-01-11T00:00:00.000 Sat User prefers cities with good public transportation.\n",
      "2025-01-12T00:00:00.000 Sun User is planning a trip for spring 2025.\n",
      "2025-01-10T00:00:00.000 Fri User loves visiting museums.\n",
      "2025-01-10T00:00:00.000 Fri User loves trying local cuisine.\n",
      "\n",
      "Total memories stored: 4\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:46 - LightMemory - INFO - Initializing LightMemory with provided configuration\n",
      "2025-11-17 11:27:46 - LightMemory - INFO - Initializing pre-compressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FORKING: Create Branch A (Paris) and Branch B (Tokyo)\n",
      "============================================================\n",
      "pre_compressor:llmlingua-2\n",
      "pre_compressor:llmlingua_config={'model_name': 'microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank', 'device_map': 'cuda', 'use_llmlingua2': True} llmlingua2_config={'max_batch_size': 50, 'max_force_token': 100} compress_config={'instruction': '', 'rate': 0.8, 'target_token': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:47 - LightMemory - INFO - Initializing topic segmenter\n",
      "2025-11-17 11:27:47 - LightMemory - INFO - Initializing memory manager\n",
      "2025-11-17 11:27:47 - LightMemory - INFO - Initializing text embedder\n",
      "2025-11-17 11:27:47 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2025-11-17 11:27:47 - LightMemory - INFO - Initializing embedding retriever\n",
      "2025-11-17 11:27:47 - LightMemory - INFO - LightMemory initialization completed successfully\n",
      "2025-11-17 11:27:47 - LightMemory - INFO - Initializing LightMemory with provided configuration\n",
      "2025-11-17 11:27:47 - LightMemory - INFO - Initializing pre-compressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_compressor:llmlingua-2\n",
      "pre_compressor:llmlingua_config={'model_name': 'microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank', 'device_map': 'cuda', 'use_llmlingua2': True} llmlingua2_config={'max_batch_size': 50, 'max_force_token': 100} compress_config={'instruction': '', 'rate': 0.8, 'target_token': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:48 - LightMemory - INFO - Initializing topic segmenter\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - Initializing memory manager\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - Initializing text embedder\n",
      "2025-11-17 11:27:48 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - Initializing embedding retriever\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - LightMemory initialization completed successfully\n",
      "2025-11-17 11:27:48 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_branch_a\n",
      "2025-11-17 11:27:48 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_branch_b\n",
      "2025-11-17 11:27:48 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_branch_a\n",
      "2025-11-17 11:27:48 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_branch_b\n",
      "2025-11-17 11:27:48 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_branch_a\n",
      "2025-11-17 11:27:48 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_branch_b\n",
      "2025-11-17 11:27:48 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_branch_a\n",
      "2025-11-17 11:27:48 - lightmem.factory.retriever.embeddingretriever.qdrant - INFO - Inserting 1 vectors into collection fork_test_branch_b\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - ========== START add_memory_20251117_112748_924243 ==========\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - force_segment=True, force_extract=True\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - [add_memory_20251117_112748_924243] Target compression rate: 0.8\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - [add_memory_20251117_112748_924243] Generated 1 segments\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - [add_memory_20251117_112748_924243] Extraction triggered 1 times, extract_list length: 1\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - [add_memory_20251117_112748_924243] Assigned timestamps to 1 items\n",
      "2025-11-17 11:27:48 - LightMemory - INFO - [add_memory_20251117_112748_924243] Starting metadata generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cloning pre-fork memories to branches...\n",
      "Found 4 memories in main to clone\n",
      "✓ Branch A initialized with 4 memories\n",
      "✓ Branch B initialized with 4 memories\n",
      "\n",
      "------------------------------------------------------------\n",
      "Branch A: Testing hypothesis 'Paris'\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:49 - LightMemory - INFO - [add_memory_20251117_112748_924243] Metadata generation completed with 1 API calls\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [add_memory_20251117_112748_924243] Extracted 1 memory entries\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [add_memory_20251117_112748_924243] Created 0 MemoryEntry objects\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - ========== START offline_update_20251117_112749_818952 ==========\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [offline_update_20251117_112749_818952] Received 0 memory entries\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [offline_update_20251117_112749_818952] construct_update_queue_trigger=False, offline_update_trigger=False\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [offline_update_20251117_112749_818952] Starting embedding and insertion to vector database\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [offline_update_20251117_112749_818952] Successfully inserted 0 entries to vector database\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - ========== START add_memory_20251117_112749_821136 ==========\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - force_segment=True, force_extract=True\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [add_memory_20251117_112749_821136] Target compression rate: 0.8\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [add_memory_20251117_112749_821136] Generated 1 segments\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [add_memory_20251117_112749_821136] Extraction triggered 1 times, extract_list length: 1\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [add_memory_20251117_112749_821136] Assigned timestamps to 1 items\n",
      "2025-11-17 11:27:49 - LightMemory - INFO - [add_memory_20251117_112749_821136] Starting metadata generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added Paris hypothesis to Branch A\n",
      "\n",
      "------------------------------------------------------------\n",
      "Branch B: Testing hypothesis 'Tokyo'\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:50 - LightMemory - INFO - [add_memory_20251117_112749_821136] Metadata generation completed with 1 API calls\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [add_memory_20251117_112749_821136] Extracted 1 memory entries\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [add_memory_20251117_112749_821136] Created 0 MemoryEntry objects\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== START offline_update_20251117_112750_813998 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [offline_update_20251117_112750_813998] Received 0 memory entries\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [offline_update_20251117_112750_813998] construct_update_queue_trigger=False, offline_update_trigger=False\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [offline_update_20251117_112750_813998] Starting embedding and insertion to vector database\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [offline_update_20251117_112750_813998] Successfully inserted 0 entries to vector database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added Tokyo hypothesis to Branch B\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02101706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== START retrieve_20251117_112750_851614 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_851614] Query: What are my travel preferences?\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_851614] Parameters: limit=3, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VERIFICATION: Test retrieval in each branch\n",
      "============================================================\n",
      "\n",
      "[Main] Retrieve: What are my travel preferences?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812755c57f4e4852a979b48f477d7967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_851614] Searching vector database\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_851614] Found 3 results\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_851614] Formatted 3 results into output string\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== END retrieve_20251117_112750_851614 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== START retrieve_20251117_112750_865372 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_865372] Query: What are my travel preferences?\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_865372] Parameters: limit=3, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11T00:00:00.000 Sat User prefers cities with good public transportation.\n",
      "2025-01-12T00:00:00.000 Sun User is planning a trip for spring 2025.\n",
      "2025-01-10T00:00:00.000 Fri User loves visiting museums.\n",
      "Main collection size: 4 memories\n",
      "\n",
      "------------------------------------------------------------\n",
      "[Branch A] Retrieve: What are my travel preferences?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499c344244184c3d98b0d0880bdc03cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_865372] Searching vector database\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_865372] Found 3 results\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_865372] Formatted 3 results into output string\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== END retrieve_20251117_112750_865372 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== START retrieve_20251117_112750_877608 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_877608] Query: What are my travel preferences?\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_877608] Parameters: limit=3, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11T00:00:00.000 Sat User prefers cities with good public transportation.\n",
      "2025-01-12T00:00:00.000 Sun User is planning a trip for spring 2025.\n",
      "2025-01-10T00:00:00.000 Fri User loves visiting museums.\n",
      "Branch A collection size: 4 memories\n",
      "\n",
      "------------------------------------------------------------\n",
      "[Branch B] Retrieve: What are my travel preferences?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2a2286d52341338edff46ea3fab6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_877608] Searching vector database\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_877608] Found 3 results\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_877608] Formatted 3 results into output string\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== END retrieve_20251117_112750_877608 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== START retrieve_20251117_112750_890262 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_890262] Query: Paris destination\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_890262] Parameters: limit=3, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11T00:00:00.000 Sat User prefers cities with good public transportation.\n",
      "2025-01-12T00:00:00.000 Sun User is planning a trip for spring 2025.\n",
      "2025-01-10T00:00:00.000 Fri User loves visiting museums.\n",
      "Branch B collection size: 4 memories\n",
      "\n",
      "============================================================\n",
      "ISOLATION TEST: Branch-specific memories\n",
      "============================================================\n",
      "\n",
      "[Branch A] Query: 'Paris destination'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e14bb514a74640a1e3e64531202d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_890262] Searching vector database\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_890262] Found 3 results\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_890262] Formatted 3 results into output string\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== END retrieve_20251117_112750_890262 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== START retrieve_20251117_112750_902492 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_902492] Query: Paris destination\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_902492] Parameters: limit=3, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11T00:00:00.000 Sat User prefers cities with good public transportation.\n",
      "2025-01-12T00:00:00.000 Sun User is planning a trip for spring 2025.\n",
      "2025-01-10T00:00:00.000 Fri User loves visiting museums.\n",
      "  → Should mention Paris: True\n",
      "\n",
      "[Branch B] Query: 'Paris destination'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ddafbba057402290a25f4295a75a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_902492] Searching vector database\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_902492] Found 3 results\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_902492] Formatted 3 results into output string\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== END retrieve_20251117_112750_902492 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== START retrieve_20251117_112750_914506 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_914506] Query: Tokyo destination\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_914506] Parameters: limit=3, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11T00:00:00.000 Sat User prefers cities with good public transportation.\n",
      "2025-01-12T00:00:00.000 Sun User is planning a trip for spring 2025.\n",
      "2025-01-10T00:00:00.000 Fri User loves visiting museums.\n",
      "  → Should NOT mention Paris specifically: True\n",
      "\n",
      "[Branch A] Query: 'Tokyo destination'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51eee31d09f46c6ad5683bd710e4750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_914506] Searching vector database\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_914506] Found 3 results\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_914506] Formatted 3 results into output string\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== END retrieve_20251117_112750_914506 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== START retrieve_20251117_112750_927049 ==========\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_927049] Query: Tokyo destination\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_927049] Parameters: limit=3, filters=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11T00:00:00.000 Sat User prefers cities with good public transportation.\n",
      "2025-01-12T00:00:00.000 Sun User is planning a trip for spring 2025.\n",
      "2025-01-10T00:00:00.000 Fri User loves visiting museums.\n",
      "  → Should NOT mention Tokyo specifically: True\n",
      "\n",
      "[Branch B] Query: 'Tokyo destination'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de84e939eea6423aa88878be8b2072ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_927049] Searching vector database\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_927049] Found 3 results\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - [retrieve_20251117_112750_927049] Formatted 3 results into output string\n",
      "2025-11-17 11:27:50 - LightMemory - INFO - ========== END retrieve_20251117_112750_927049 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11T00:00:00.000 Sat User prefers cities with good public transportation.\n",
      "2025-01-12T00:00:00.000 Sun User is planning a trip for spring 2025.\n",
      "2025-01-10T00:00:00.000 Fri User loves visiting museums.\n",
      "  → Should mention Tokyo: False\n",
      "\n",
      "============================================================\n",
      "✅ FORK TEST COMPLETE\n",
      "============================================================\n",
      "Summary:\n",
      "  - Main has pre-fork memories only\n",
      "  - Branch A has pre-fork + Paris hypothesis\n",
      "  - Branch B has pre-fork + Tokyo hypothesis\n",
      "  - Branches are isolated (Paris ∉ Branch B, Tokyo ∉ Branch A)\n"
     ]
    }
   ],
   "source": [
    "### Cell 3: Verify fork isolation and memory access\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICATION: Test retrieval in each branch\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Query about travel preferences (should retrieve pre-fork memories)\n",
    "query_prefork = \"What are my travel preferences?\"\n",
    "\n",
    "print(\"\\n[Main] Retrieve:\", query_prefork)\n",
    "main_retrieved = lightmem_main.retrieve(query_prefork, limit=3)\n",
    "print(main_retrieved)\n",
    "print(f\"Main collection size: {len(lightmem_main.embedding_retriever.get_all())} memories\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"[Branch A] Retrieve:\", query_prefork)\n",
    "branch_a_retrieved = lightmem_branch_a.retrieve(query_prefork, limit=3)\n",
    "print(branch_a_retrieved)\n",
    "print(f\"Branch A collection size: {len(lightmem_branch_a.embedding_retriever.get_all())} memories\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"[Branch B] Retrieve:\", query_prefork)\n",
    "branch_b_retrieved = lightmem_branch_b.retrieve(query_prefork, limit=3)\n",
    "print(branch_b_retrieved)\n",
    "print(f\"Branch B collection size: {len(lightmem_branch_b.embedding_retriever.get_all())} memories\")\n",
    "\n",
    "# Query branch-specific memories (should only appear in respective branch)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ISOLATION TEST: Branch-specific memories\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query_paris = \"Paris destination\"\n",
    "print(f\"\\n[Branch A] Query: '{query_paris}'\")\n",
    "paris_in_a = lightmem_branch_a.retrieve(query_paris, limit=3)\n",
    "print(paris_in_a)\n",
    "print(f\"  → Should mention Paris: {'Paris' in paris_in_a or 'museums' in paris_in_a}\")\n",
    "\n",
    "print(f\"\\n[Branch B] Query: '{query_paris}'\")\n",
    "paris_in_b = lightmem_branch_b.retrieve(query_paris, limit=3)\n",
    "print(paris_in_b)\n",
    "print(f\"  → Should NOT mention Paris specifically: {'Paris' not in paris_in_b}\")\n",
    "\n",
    "query_tokyo = \"Tokyo destination\"\n",
    "print(f\"\\n[Branch A] Query: '{query_tokyo}'\")\n",
    "tokyo_in_a = lightmem_branch_a.retrieve(query_tokyo, limit=3)\n",
    "print(tokyo_in_a)\n",
    "print(f\"  → Should NOT mention Tokyo specifically: {'Tokyo' not in tokyo_in_a}\")\n",
    "\n",
    "print(f\"\\n[Branch B] Query: '{query_tokyo}'\")\n",
    "tokyo_in_b = lightmem_branch_b.retrieve(query_tokyo, limit=3)\n",
    "print(tokyo_in_b)\n",
    "print(f\"  → Should mention Tokyo: {'Tokyo' in tokyo_in_b or 'food' in tokyo_in_b}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✅ FORK TEST COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Summary:\")\n",
    "print(f\"  - Main has pre-fork memories only\")\n",
    "print(f\"  - Branch A has pre-fork + Paris hypothesis\")\n",
    "print(f\"  - Branch B has pre-fork + Tokyo hypothesis\")\n",
    "print(f\"  - Branches are isolated (Paris ∉ Branch B, Tokyo ∉ Branch A)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43af2f3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
