# -------------------------
# LLM Provider Configurations
# -------------------------
# A list of all available LLM configurations. The `run_experiment.py` script
# can select one of these by its `name`.

providers:
  - name: "qwen3_14b_local"
    provider_type: "openai"
    model_name: "Qwen/Qwen3-14B" 
    parsing_format: "think_tags" 
    api_config:
      base_url: "http://localhost:8000/v1"
      api_key_env: "VLLM_API_KEY"
    generation_config:
      temperature: 0.7
      max_tokens: 4096

  - name: "kimi_k2_openrouter"
    provider_type: "openai"
    model_name: "moonshotai/kimi-k2"
    parsing_format: "think_tags" 
    api_config:
      base_url: "https://openrouter.ai/api/v1"
      api_key_env: "OPENROUTER_API_KEY" 
    generation_config:
      temperature: 0.3
      max_tokens: 4096

  - name: "gemini_2_5_pro_openrouter"
    provider_type: "openai"
    model_name: "google/gemini-2.5-pro"
    parsing_format: "think_tags" 
    api_config:
      base_url: "https://openrouter.ai/api/v1"
      api_key_env: "OPENROUTER_API_KEY" 
    generation_config:
      temperature: 0.3
      max_tokens: 4096

  - name: "gpt_4_1_mini_openrouter"
    provider_type: "openai"
    model_name: "openai/gpt-4.1-mini"
    parsing_format: "think_tags" 
    api_config:
      base_url: "https://openrouter.ai/api/v1"
      api_key_env: "OPENROUTER_API_KEY" 
    generation_config:
      temperature: 0.3
      max_tokens: 4096

  - name: "anthropic_haiku_3_5_openrouter"
    provider_type: "openai"
    model_name: "anthropic/claude-3.5-haiku"
    parsing_format: "think_tags" 
    api_config:
      base_url: "https://openrouter.ai/api/v1"
      api_key_env: "OPENROUTER_API_KEY" 
    generation_config:
      temperature: 0.3
      max_tokens: 4096

  - name: "qwen3_coder_openrouter"
    provider_type: "openai"
    model_name: "qwen/qwen3-coder"
    parsing_format: "think_tags" 
    api_config:
      base_url: "https://openrouter.ai/api/v1"
      api_key_env: "OPENROUTER_API_KEY" 
    generation_config:
      temperature: 0.3
      max_tokens: 4096

# -------------------------
# Experiment Settings
# -------------------------
# Global parameters for running the experimental suite.

experiment_settings:
  num_runs_per_task: 50
  max_turns_per_game: 20
  results_dir: "./results"

# -------------------------
# Evaluation Settings
# -------------------------
# Configuration for the Judge LLM that evaluates the results.

evaluation:
  # Select which provider config to use for the Judge LLM
  judge_provider_name: "anthropic_sonnet_3.5"